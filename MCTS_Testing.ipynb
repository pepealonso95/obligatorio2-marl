{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f05a30ea",
   "metadata": {},
   "source": [
    "# Monte Carlo Tree Search (MCTS) Testing and Optimization\n",
    "\n",
    "Este notebook implementa y eval√∫a el algoritmo MCTS en diferentes juegos.\n",
    "\n",
    "**Nota importante:** MCTS no se \"entrena\" como otros algoritmos de ML. Es un algoritmo de b√∫squeda que construye un √°rbol desde cero en cada jugada. Lo que haremos es:\n",
    "- Probar compatibilidad con diferentes juegos\n",
    "- Evaluar rendimiento con diferentes configuraciones\n",
    "- Comparar contra otros agentes\n",
    "- Analizar el impacto de par√°metros como n√∫mero de simulaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64ede5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCTS GPU integrado listo\n"
     ]
    }
   ],
   "source": [
    "# Importar librer√≠as y juegos\n",
    "from games.tictactoe.tictactoe import TicTacToe\n",
    "from games.nocca_nocca.nocca_nocca import NoccaNocca\n",
    "from games.kuhn.kuhn import KuhnPoker\n",
    "from games.leduc.leduc import LeducPoker\n",
    "from agents.mcts_t import MonteCarloTreeSearch\n",
    "from agents.agent_random import RandomAgent\n",
    "from agents.minimax import MiniMax\n",
    "import numpy as np\n",
    "\n",
    "# Forzar recarga de m√≥dulos para aplicar cambios GPU\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "if 'agents.mcts_t' in sys.modules:\n",
    "    importlib.reload(sys.modules['agents.mcts_t'])\n",
    "\n",
    "# Reimportar la clase actualizada\n",
    "from agents.mcts_t import MonteCarloTreeSearch\n",
    "\n",
    "print(\"MCTS GPU integrado listo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfd651a",
   "metadata": {},
   "source": [
    "## Optimizaci√≥n GPU Integrada\n",
    "\n",
    "**Cambios implementados**: MCTS ahora incluye aceleraci√≥n GPU integrada en la clase principal:\n",
    "\n",
    "1. **Detecci√≥n autom√°tica** de PyTorch MPS/CUDA\n",
    "2. **Tensores GPU** para recompensas acumuladas  \n",
    "3. **Rollouts vectorizados** para m√∫ltiples simulaciones\n",
    "4. **Fallback autom√°tico** a CPU si GPU no est√° disponible\n",
    "5. **Compatibilidad total** con c√≥digo existente\n",
    "\n",
    "**Beneficios para MacBook M4**:\n",
    "- Aprovechamiento de MPS (Metal Performance Shaders)\n",
    "- Operaciones vectorizadas optimizadas\n",
    "- Mejor rendimiento en rollouts m√∫ltiples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d146a2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Verificando configuraci√≥n GPU...\n",
      "‚úÖ PyTorch disponible: 2.7.1\n",
      "   MPS (Apple Silicon) disponible: True\n",
      "   CUDA disponible: False\n",
      "\n",
      "üìã Configuraci√≥n: {'episodes_test': 3, 'episodes_eval': 100, 'simulations_fast': 10, 'simulations_eval': 25, 'rollouts': 3}\n",
      "\n",
      "üß™ Creando agente MCTS de prueba...\n",
      "üîß MCTS usando: MPS (Apple Silicon)\n",
      "üìä Info del agente: {'device': 'mps', 'gpu_enabled': True, 'torch_available': True, 'simulations': 10, 'rollouts': 3}\n",
      "\n",
      "‚úÖ Configuraci√≥n GPU completada!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Verificar configuraci√≥n GPU y crear agente de prueba\n",
    "import torch\n",
    "import time\n",
    "\n",
    "print(\"üîç Verificando configuraci√≥n GPU...\")\n",
    "\n",
    "# Verificar disponibilidad de PyTorch y MPS\n",
    "try:\n",
    "    pytorch_available = True\n",
    "    print(f\"‚úÖ PyTorch disponible: {torch.__version__}\")\n",
    "    print(f\"   MPS (Apple Silicon) disponible: {torch.backends.mps.is_available()}\")\n",
    "    print(f\"   CUDA disponible: {torch.cuda.is_available()}\")\n",
    "except ImportError:\n",
    "    pytorch_available = False\n",
    "    print(\"‚ö†Ô∏è  PyTorch no est√° instalado - usando CPU\")\n",
    "\n",
    "# Configuraci√≥n optimizada para MacBook M4\n",
    "FAST_CONFIG = {\n",
    "    'episodes_test': 3,        # Reducido para testing r√°pido\n",
    "    'episodes_eval': 100,      # Para evaluaci√≥n\n",
    "    'simulations_fast': 10,    # Para testing\n",
    "    'simulations_eval': 25,    # Para evaluaci√≥n\n",
    "    'rollouts': 3              # Reducido para velocidad\n",
    "}\n",
    "\n",
    "print(f\"\\nüìã Configuraci√≥n: {FAST_CONFIG}\")\n",
    "\n",
    "# Crear agente de prueba para verificar GPU\n",
    "test_game = TicTacToe()\n",
    "test_game.reset()\n",
    "print(\"\\nüß™ Creando agente MCTS de prueba...\")\n",
    "test_agent = MonteCarloTreeSearch(test_game, test_game.agents[0], simulations=10, rollouts=3)\n",
    "\n",
    "# Mostrar informaci√≥n de rendimiento si est√° disponible\n",
    "if hasattr(test_agent, 'get_performance_info'):\n",
    "    print(\"üìä Info del agente:\", test_agent.get_performance_info())\n",
    "else:\n",
    "    print(\"üìä Agente: Versi√≥n est√°ndar\")\n",
    "\n",
    "# Funci√≥n para medir tiempo de ejecuci√≥n\n",
    "def time_execution(func, *args, **kwargs):\n",
    "    start_time = time.time()\n",
    "    result = func(*args, **kwargs)\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"‚è±Ô∏è  Tiempo total: {elapsed:.1f}s\")\n",
    "    return result, elapsed\n",
    "\n",
    "print(\"\\n‚úÖ Configuraci√≥n GPU completada!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74f65806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Informaci√≥n de agentes optimizados:\n",
      "üîß MiniMax usando: MPS (Apple Silicon)\n",
      "\n",
      "üìä MCTS:\n",
      "   {'device': 'mps', 'gpu_enabled': True, 'torch_available': True, 'simulations': 10, 'rollouts': 3}\n",
      "\n",
      "üìä MiniMax:\n",
      "   {'device': 'mps', 'gpu_enabled': True, 'torch_available': True, 'cache_size': 0}\n",
      "\n",
      "üéØ Los algoritmos est√°n usando las versiones optimizadas GPU integradas\n",
      "   - No se necesitan clases separadas\n",
      "   - Funcionan exactamente igual que las originales\n",
      "   - GPU se activa autom√°ticamente si est√° disponible\n",
      "==================================================\n",
      "GPU: True, Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Funci√≥n para mostrar informaci√≥n de los agentes GPU\n",
    "def show_agent_info():\n",
    "    \"\"\"Muestra informaci√≥n sobre las capacidades GPU de los agentes\"\"\"\n",
    "    print(\"üîç Informaci√≥n de agentes optimizados:\")\n",
    "    \n",
    "    # Crear agentes temporales para mostrar info\n",
    "    temp_game = TicTacToe()\n",
    "    temp_game.reset()\n",
    "    \n",
    "    mcts_agent = MonteCarloTreeSearch(temp_game, temp_game.agents[0], simulations=10, rollouts=3)\n",
    "    minimax_agent = MiniMax(temp_game, temp_game.agents[1], depth=3)\n",
    "    \n",
    "    print(\"\\nüìä MCTS:\")\n",
    "    if hasattr(mcts_agent, 'get_performance_info'):\n",
    "        print(f\"   {mcts_agent.get_performance_info()}\")\n",
    "    else:\n",
    "        print(\"   Versi√≥n est√°ndar (CPU)\")\n",
    "    \n",
    "    print(\"\\nüìä MiniMax:\")\n",
    "    if hasattr(minimax_agent, 'get_performance_info'):\n",
    "        print(f\"   {minimax_agent.get_performance_info()}\")\n",
    "    else:\n",
    "        print(\"   Versi√≥n est√°ndar (CPU)\")\n",
    "    \n",
    "    return mcts_agent, minimax_agent\n",
    "\n",
    "# Mostrar informaci√≥n de los agentes\n",
    "mcts_sample, minimax_sample = show_agent_info()\n",
    "\n",
    "print(\"\\nüéØ Los algoritmos est√°n usando las versiones optimizadas GPU integradas\")\n",
    "print(\"   - No se necesitan clases separadas\")\n",
    "print(\"   - Funcionan exactamente igual que las originales\")\n",
    "print(\"   - GPU se activa autom√°ticamente si est√° disponible\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Verificar que MCTS tiene GPU integrado\n",
    "test_game = TicTacToe()\n",
    "test_agent = MonteCarloTreeSearch(test_game, test_game.agents[0], simulations=10, rollouts=3)\n",
    "\n",
    "# Mostrar informaci√≥n de GPU\n",
    "if hasattr(test_agent, 'get_performance_info'):\n",
    "    info = test_agent.get_performance_info()\n",
    "    print(f\"GPU: {info['gpu_enabled']}, Device: {info['device']}\")\n",
    "else:\n",
    "    print(\"Versi√≥n est√°ndar (CPU)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048863e5",
   "metadata": {},
   "source": [
    "## 1. Pruebas r√°pidas (10 episodios)\n",
    "\n",
    "Primero probamos que los agentes funcionen correctamente con pocos episodios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9b1e424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent_compatibility(game, agent_class, episodes=None, simulations=None):\n",
    "    \"\"\"Prueba la compatibilidad de un agente con un juego\"\"\"\n",
    "    # Usar configuraci√≥n optimizada si no se especifica\n",
    "    episodes = episodes or FAST_CONFIG['episodes_test']\n",
    "    simulations = simulations or FAST_CONFIG['simulations_fast']\n",
    "    \n",
    "    results = []\n",
    "    start_time = time.time()\n",
    "    errors = 0\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        game.reset()\n",
    "        agents = {}\n",
    "        for agent_id in game.agents:\n",
    "            agents[agent_id] = agent_class(game=game, agent=agent_id, \n",
    "                                         simulations=simulations, \n",
    "                                         rollouts=FAST_CONFIG['rollouts'])\n",
    "        \n",
    "        step_count = 0\n",
    "        while not game.game_over() and step_count < 200:\n",
    "            try:\n",
    "                action = agents[game.agent_selection].action()\n",
    "                game.step(action)\n",
    "                step_count += 1\n",
    "            except Exception as e:\n",
    "                errors += 1\n",
    "                break\n",
    "        \n",
    "        episode_results = {agent: game.reward(agent) for agent in game.agents}\n",
    "        results.append(episode_results)\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"Episodes: {episodes}, Time: {total_time:.1f}s, Errors: {errors}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "578ace61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 3, Time: 0.6s, Errors: 0\n",
      "‚è±Ô∏è  Tiempo total: 0.6s\n"
     ]
    }
   ],
   "source": [
    "# Test TicTacToe\n",
    "tictactoe_game = TicTacToe()\n",
    "tictactoe_results, time_taken = time_execution(\n",
    "    test_agent_compatibility, \n",
    "    tictactoe_game, \n",
    "    MonteCarloTreeSearch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81a15ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 3, Time: 34.2s, Errors: 0\n",
      "‚è±Ô∏è  Tiempo total: 34.2s\n"
     ]
    }
   ],
   "source": [
    "# Test Nocca-Nocca\n",
    "nocca_game = NoccaNocca(max_steps=100, initial_player=0, seed=1)\n",
    "nocca_results, time_taken = time_execution(\n",
    "    test_agent_compatibility, \n",
    "    nocca_game, \n",
    "    MonteCarloTreeSearch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88cd33af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 3, Time: 0.1s, Errors: 0\n",
      "‚è±Ô∏è  Tiempo total: 0.1s\n"
     ]
    }
   ],
   "source": [
    "# Test Kuhn Poker\n",
    "kuhn_game = KuhnPoker()\n",
    "kuhn_results, time_taken = time_execution(\n",
    "    test_agent_compatibility, \n",
    "    kuhn_game, \n",
    "    MonteCarloTreeSearch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eec0cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 3, Time: 0.1s, Errors: 0\n",
      "‚è±Ô∏è  Tiempo total: 0.1s\n"
     ]
    }
   ],
   "source": [
    "# Test Leduc Poker\n",
    "leduc_game = LeducPoker()\n",
    "leduc_results, time_taken = time_execution(\n",
    "    test_agent_compatibility, \n",
    "    leduc_game, \n",
    "    MonteCarloTreeSearch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd99b70",
   "metadata": {},
   "source": [
    "## 2. Evaluaci√≥n de rendimiento (2000 partidas)\n",
    "\n",
    "Ahora evaluamos el rendimiento de MCTS jugando muchas partidas. \n",
    "\n",
    "**Importante:** MCTS no aprende entre partidas - cada juego empieza desde cero. Esta evaluaci√≥n nos ayuda a entender qu√© tan bien funciona el algoritmo en cada juego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "698615ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def evaluate_mcts_performance(game, episodes=None, simulations=None):\n",
    "    \"\"\"Eval√∫a el rendimiento de MCTS durante muchas partidas\"\"\"\n",
    "    episodes = episodes or FAST_CONFIG['episodes_eval']\n",
    "    simulations = simulations or FAST_CONFIG['simulations_eval']\n",
    "    \n",
    "    win_counts = {agent: 0 for agent in game.agents}\n",
    "    draw_count = 0\n",
    "    start_time = time.time()\n",
    "    errors = 0\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        game.reset()\n",
    "        agents = {}\n",
    "        for agent_id in game.agents:\n",
    "            agents[agent_id] = MonteCarloTreeSearch(game=game, agent=agent_id, \n",
    "                                                  simulations=simulations,\n",
    "                                                  rollouts=FAST_CONFIG['rollouts'])\n",
    "        \n",
    "        step_count = 0\n",
    "        try:\n",
    "            while not game.game_over() and step_count < 200:\n",
    "                action = agents[game.agent_selection].action()\n",
    "                game.step(action)\n",
    "                step_count += 1\n",
    "        except Exception:\n",
    "            errors += 1\n",
    "            continue\n",
    "        \n",
    "        rewards = {agent: game.reward(agent) for agent in game.agents}\n",
    "        winner = max(rewards, key=rewards.get) if max(rewards.values()) > 0 else None\n",
    "        \n",
    "        if winner:\n",
    "            win_counts[winner] += 1\n",
    "        else:\n",
    "            draw_count += 1\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"Episodes: {episodes}, Time: {total_time:.1f}s, Wins: {win_counts}, Draws: {draw_count}, Errors: {errors}\")\n",
    "    return win_counts, draw_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99cebad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 100, Time: 33.3s, Wins: {'X': 71, 'O': 15}, Draws: 14, Errors: 0\n",
      "‚è±Ô∏è  Tiempo total: 33.3s\n"
     ]
    }
   ],
   "source": [
    "# Evaluar rendimiento en TicTacToe (usando par√°metros optimizados M4)\n",
    "tictactoe_performance, eval_time = time_execution(\n",
    "    evaluate_mcts_performance, \n",
    "    TicTacToe(), \n",
    "    episodes=FAST_CONFIG['episodes_eval'], \n",
    "    simulations=FAST_CONFIG['simulations_eval']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16a6baf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Evaluar rendimiento en Nocca-Nocca (M4 optimizado)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m nocca_performance = \u001b[43mevaluate_mcts_performance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mNoccaNocca\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepisodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFAST_CONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mepisodes_eval\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43msimulations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFAST_CONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msimulations_eval\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mevaluate_mcts_performance\u001b[39m\u001b[34m(game, episodes, simulations)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m game.game_over() \u001b[38;5;129;01mand\u001b[39;00m step_count < \u001b[32m200\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m         action = \u001b[43magents\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgame\u001b[49m\u001b[43m.\u001b[49m\u001b[43magent_selection\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m         game.step(action)\n\u001b[32m     26\u001b[39m         step_count += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/Master/obli2-marl/agents/mcts_t.py:79\u001b[39m, in \u001b[36mMonteCarloTreeSearch.action\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34maction\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> ActionType:\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     a, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmcts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/Master/obli2-marl/agents/mcts_t.py:89\u001b[39m, in \u001b[36mMonteCarloTreeSearch.mcts\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.simulations):\n\u001b[32m     88\u001b[39m     node = root\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m     node.game = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgame\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m     node = \u001b[38;5;28mself\u001b[39m.select_node(node=node)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28mself\u001b[39m.expand_node(node)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/Master/obli2-marl/games/nocca_nocca/nocca_nocca.py:121\u001b[39m, in \u001b[36mNoccaNocca.clone\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mclone\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/Master/obli2-marl/base/game.py:40\u001b[39m, in \u001b[36mAlternatingGame.clone\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mclone\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     game = \u001b[43mcopy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m game\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/copy.py:162\u001b[39m, in \u001b[36mdeepcopy\u001b[39m\u001b[34m(x, memo, _nil)\u001b[39m\n\u001b[32m    160\u001b[39m                 y = x\n\u001b[32m    161\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m                 y = \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/copy.py:259\u001b[39m, in \u001b[36m_reconstruct\u001b[39m\u001b[34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    258\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[32m--> \u001b[39m\u001b[32m259\u001b[39m         state = \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[33m'\u001b[39m\u001b[33m__setstate__\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    261\u001b[39m         y.__setstate__(state)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/copy.py:136\u001b[39m, in \u001b[36mdeepcopy\u001b[39m\u001b[34m(x, memo, _nil)\u001b[39m\n\u001b[32m    134\u001b[39m copier = _deepcopy_dispatch.get(\u001b[38;5;28mcls\u001b[39m)\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     y = \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/copy.py:221\u001b[39m, in \u001b[36m_deepcopy_dict\u001b[39m\u001b[34m(x, memo, deepcopy)\u001b[39m\n\u001b[32m    219\u001b[39m memo[\u001b[38;5;28mid\u001b[39m(x)] = y\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x.items():\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     y[deepcopy(key, memo)] = \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/copy.py:136\u001b[39m, in \u001b[36mdeepcopy\u001b[39m\u001b[34m(x, memo, _nil)\u001b[39m\n\u001b[32m    134\u001b[39m copier = _deepcopy_dispatch.get(\u001b[38;5;28mcls\u001b[39m)\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     y = \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/copy.py:221\u001b[39m, in \u001b[36m_deepcopy_dict\u001b[39m\u001b[34m(x, memo, deepcopy)\u001b[39m\n\u001b[32m    219\u001b[39m memo[\u001b[38;5;28mid\u001b[39m(x)] = y\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x.items():\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     y[deepcopy(key, memo)] = \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/copy.py:136\u001b[39m, in \u001b[36mdeepcopy\u001b[39m\u001b[34m(x, memo, _nil)\u001b[39m\n\u001b[32m    134\u001b[39m copier = _deepcopy_dispatch.get(\u001b[38;5;28mcls\u001b[39m)\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     y = \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/copy.py:201\u001b[39m, in \u001b[36m_deepcopy_tuple\u001b[39m\u001b[34m(x, memo, deepcopy)\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m_deepcopy_tuple\u001b[39m(x, memo, deepcopy=deepcopy):\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m     y = [deepcopy(a, memo) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[32m    202\u001b[39m     \u001b[38;5;66;03m# We're not going to put the tuple in the memo, but it's still important we\u001b[39;00m\n\u001b[32m    203\u001b[39m     \u001b[38;5;66;03m# check for it, in case the tuple contains recursive mutable structures.\u001b[39;00m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Evaluar rendimiento en Nocca-Nocca (M4 optimizado)\n",
    "nocca_performance = evaluate_mcts_performance(\n",
    "    NoccaNocca(max_steps=100, seed=1), \n",
    "    episodes=FAST_CONFIG['episodes_eval'], \n",
    "    simulations=FAST_CONFIG['simulations_eval']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ce69aa",
   "metadata": {},
   "source": [
    "Tuve que re-testear mcts para chequear que funcione correctamente en leduc, y nocca nocca demoraba demasiado, asi que lo saltee para esta ultima ejecucion, pero en la notebook de evaluacion final se puede ver que funciona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bb176f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 100, Time: 5.9s, Wins: {'agent_0': 50, 'agent_1': 50}, Draws: 0, Errors: 0\n"
     ]
    }
   ],
   "source": [
    "# Evaluar rendimiento en Kuhn Poker (M4 optimizado)\n",
    "kuhn_performance = evaluate_mcts_performance(\n",
    "    KuhnPoker(), \n",
    "    episodes=FAST_CONFIG['episodes_eval'], \n",
    "    simulations=FAST_CONFIG['simulations_eval']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb132bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 100, Time: 161.4s, Wins: {'agent_0': 23, 'agent_1': 46}, Draws: 31, Errors: 0\n"
     ]
    }
   ],
   "source": [
    "# Evaluar rendimiento en Leduc Poker (M4 optimizado)\n",
    "leduc_performance = evaluate_mcts_performance(\n",
    "    LeducPoker(), \n",
    "    episodes=FAST_CONFIG['episodes_eval'], \n",
    "    simulations=FAST_CONFIG['simulations_eval']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9a6b69",
   "metadata": {},
   "source": [
    "## 3. Optimizaci√≥n de par√°metros\n",
    "\n",
    "MCTS tiene par√°metros importantes que afectan su rendimiento:\n",
    "- **N√∫mero de simulaciones**: M√°s simulaciones = mejor calidad de decisi√≥n pero m√°s tiempo\n",
    "- **N√∫mero de rollouts**: Afecta la calidad de la evaluaci√≥n de nodos\n",
    "- **Constante UCB**: Controla exploraci√≥n vs explotaci√≥n\n",
    "\n",
    "Probemos diferentes configuraciones para encontrar un buen balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29f0695f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultra_Fast: Time=0.4s, Wins={'X': 7, 'O': 2}, Draws=0, Errors=0\n",
      "Fast: Time=0.9s, Wins={'X': 7, 'O': 1}, Draws=1, Errors=0\n",
      "Fast: Time=0.9s, Wins={'X': 7, 'O': 1}, Draws=1, Errors=0\n",
      "Balanced: Time=7.7s, Wins={'X': 9, 'O': 0}, Draws=0, Errors=0\n",
      "Balanced: Time=7.7s, Wins={'X': 9, 'O': 0}, Draws=0, Errors=0\n",
      "Quality: Time=21.3s, Wins={'X': 0, 'O': 0}, Draws=9, Errors=0\n",
      "Quality: Time=21.3s, Wins={'X': 0, 'O': 0}, Draws=9, Errors=0\n"
     ]
    }
   ],
   "source": [
    "def test_mcts_configurations(game, configs, episodes=None):\n",
    "    \"\"\"Prueba diferentes configuraciones de MCTS para encontrar la √≥ptima\"\"\"\n",
    "    episodes = episodes or FAST_CONFIG['episodes_test'] * 3\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for config_name, params in configs.items():\n",
    "        win_counts = {agent: 0 for agent in game.agents}\n",
    "        draw_count = 0\n",
    "        errors = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for episode in range(episodes):\n",
    "            game.reset()\n",
    "            agents = {}\n",
    "            for agent_id in game.agents:\n",
    "                agents[agent_id] = MonteCarloTreeSearch(game=game, agent=agent_id, **params)\n",
    "            \n",
    "            step_count = 0\n",
    "            try:\n",
    "                while not game.game_over() and step_count < 200:\n",
    "                    action = agents[game.agent_selection].action()\n",
    "                    game.step(action)\n",
    "                    step_count += 1\n",
    "            except Exception:\n",
    "                errors += 1\n",
    "                continue\n",
    "            \n",
    "            rewards = {agent: game.reward(agent) for agent in game.agents}\n",
    "            winner = max(rewards, key=rewards.get) if max(rewards.values()) > 0 else None\n",
    "            \n",
    "            if winner:\n",
    "                win_counts[winner] += 1\n",
    "            else:\n",
    "                draw_count += 1\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        results[config_name] = {'wins': win_counts, 'draws': draw_count, 'time': elapsed, 'errors': errors}\n",
    "        print(f\"{config_name}: Time={elapsed:.1f}s, Wins={win_counts}, Draws={draw_count}, Errors={errors}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Configuraciones para M4\n",
    "mcts_configs = {\n",
    "    'Ultra_Fast': {'simulations': 5, 'rollouts': 2},\n",
    "    'Fast': {'simulations': 10, 'rollouts': 3},\n",
    "    'Balanced': {'simulations': 25, 'rollouts': 5},\n",
    "    'Quality': {'simulations': 50, 'rollouts': 8}\n",
    "}\n",
    "\n",
    "# Probar en TicTacToe\n",
    "tictactoe_configs = test_mcts_configurations(TicTacToe(), mcts_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77d239e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_agents(game, agent1_class, agent2_class, episodes=None, **kwargs):\n",
    "    \"\"\"Eval√∫a dos agentes uno contra el otro\"\"\"\n",
    "    episodes = episodes or FAST_CONFIG['episodes_test'] * 5\n",
    "    \n",
    "    def get_agent_kwargs(agent_class, all_kwargs):\n",
    "        \"\"\"Filtra los kwargs apropiados para cada tipo de agente\"\"\"\n",
    "        if agent_class.__name__ == 'RandomAgent':\n",
    "            # RandomAgent solo necesita game y agent\n",
    "            return {}\n",
    "        elif agent_class.__name__ == 'MonteCarloTreeSearch':\n",
    "            # MCTS necesita simulations y rollouts\n",
    "            return {k: v for k, v in all_kwargs.items() if k in ['simulations', 'rollouts']}\n",
    "        elif agent_class.__name__ == 'MiniMax':\n",
    "            # MiniMax necesita depth\n",
    "            return {k: v for k, v in all_kwargs.items() if k in ['depth']}\n",
    "        else:\n",
    "            # Para otros agentes, pasar todos los kwargs\n",
    "            return all_kwargs\n",
    "    \n",
    "    agent1_wins = 0\n",
    "    agent2_wins = 0\n",
    "    draws = 0\n",
    "    errors = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        game.reset()\n",
    "        \n",
    "        # Obtener kwargs apropiados para cada agente\n",
    "        agent1_kwargs = get_agent_kwargs(agent1_class, kwargs)\n",
    "        agent2_kwargs = get_agent_kwargs(agent2_class, kwargs)\n",
    "        \n",
    "        # Alternar qu√© agente juega primero\n",
    "        if episode % 2 == 0:\n",
    "            agents = {\n",
    "                game.agents[0]: agent1_class(game=game, agent=game.agents[0], **agent1_kwargs),\n",
    "                game.agents[1]: agent2_class(game=game, agent=game.agents[1], **agent2_kwargs)\n",
    "            }\n",
    "        else:\n",
    "            agents = {\n",
    "                game.agents[0]: agent2_class(game=game, agent=game.agents[0], **agent2_kwargs),\n",
    "                game.agents[1]: agent1_class(game=game, agent=game.agents[1], **agent1_kwargs)\n",
    "            }\n",
    "        \n",
    "        step_count = 0\n",
    "        try:\n",
    "            while not game.game_over() and step_count < 200:\n",
    "                action = agents[game.agent_selection].action()\n",
    "                game.step(action)\n",
    "                step_count += 1\n",
    "        except Exception:\n",
    "            errors += 1\n",
    "            continue\n",
    "        \n",
    "        # Determinar ganador\n",
    "        rewards = {agent: game.reward(agent) for agent in game.agents}\n",
    "        \n",
    "        if episode % 2 == 0:  # agent1 jug√≥ primero\n",
    "            if rewards[game.agents[0]] > rewards[game.agents[1]]:\n",
    "                agent1_wins += 1\n",
    "            elif rewards[game.agents[1]] > rewards[game.agents[0]]:\n",
    "                agent2_wins += 1\n",
    "            else:\n",
    "                draws += 1\n",
    "        else:  # agent2 jug√≥ primero\n",
    "            if rewards[game.agents[0]] > rewards[game.agents[1]]:\n",
    "                agent2_wins += 1\n",
    "            elif rewards[game.agents[1]] > rewards[game.agents[0]]:\n",
    "                agent1_wins += 1\n",
    "            else:\n",
    "                draws += 1\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"{agent1_class.__name__} {agent1_wins} - {agent2_wins} {agent2_class.__name__} | Empates: {draws} | Errores: {errors}\")\n",
    "    return agent1_wins, agent2_wins, draws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "957e4579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MonteCarloTreeSearch 14 - 1 RandomAgent | Empates: 0 | Errores: 0\n"
     ]
    }
   ],
   "source": [
    "# MCTS vs Random en TicTacToe (M4 optimizado)\n",
    "mcts_vs_random_ttt = evaluate_agents(\n",
    "    TicTacToe(), \n",
    "    MonteCarloTreeSearch, \n",
    "    RandomAgent, \n",
    "    simulations=FAST_CONFIG['simulations_eval'],\n",
    "    rollouts=FAST_CONFIG['rollouts']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80bbaa8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MonteCarloTreeSearch 3 - 4 MiniMax | Empates: 8 | Errores: 0\n"
     ]
    }
   ],
   "source": [
    "# MCTS vs MiniMax en TicTacToe (M4 optimizado)\n",
    "mcts_vs_minimax_ttt = evaluate_agents(\n",
    "    TicTacToe(), \n",
    "    MonteCarloTreeSearch, \n",
    "    MiniMax, \n",
    "    simulations=FAST_CONFIG['simulations_eval'],\n",
    "    rollouts=FAST_CONFIG['rollouts'],\n",
    "    depth=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86c96e9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# MCTS vs Random en Nocca-Nocca (M4 optimizado)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m mcts_vs_random_nocca = \u001b[43mevaluate_agents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mNoccaNocca\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mMonteCarloTreeSearch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mRandomAgent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43msimulations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFAST_CONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msimulations_fast\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrollouts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFAST_CONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrollouts\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mevaluate_agents\u001b[39m\u001b[34m(game, agent1_class, agent2_class, episodes, **kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m game.game_over() \u001b[38;5;129;01mand\u001b[39;00m step_count < \u001b[32m200\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m         action = \u001b[43magents\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgame\u001b[49m\u001b[43m.\u001b[49m\u001b[43magent_selection\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m         game.step(action)\n\u001b[32m     50\u001b[39m         step_count += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/Master/obli2-marl/agents/mcts_t.py:79\u001b[39m, in \u001b[36mMonteCarloTreeSearch.action\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34maction\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> ActionType:\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     a, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmcts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/Master/obli2-marl/agents/mcts_t.py:95\u001b[39m, in \u001b[36mMonteCarloTreeSearch.mcts\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     91\u001b[39m     node = \u001b[38;5;28mself\u001b[39m.select_node(node=node)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28mself\u001b[39m.expand_node(node)\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     rewards = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrollout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m     \u001b[38;5;28mself\u001b[39m.backprop(node, rewards)\n\u001b[32m     99\u001b[39m action, value = \u001b[38;5;28mself\u001b[39m.action_selection(root)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/Master/obli2-marl/agents/mcts_t.py:126\u001b[39m, in \u001b[36mMonteCarloTreeSearch.rollout\u001b[39m\u001b[34m(self, node)\u001b[39m\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._rollout_gpu_optimized(node)\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_rollout_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/Master/obli2-marl/agents/mcts_t.py:134\u001b[39m, in \u001b[36mMonteCarloTreeSearch._rollout_standard\u001b[39m\u001b[34m(self, node)\u001b[39m\n\u001b[32m    132\u001b[39m game_copy = node.game.clone()\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m game_copy.game_over():\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     available_actions = \u001b[43mgame_copy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mavailable_actions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m available_actions:\n\u001b[32m    136\u001b[39m         action = np.random.choice(available_actions)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/Master/obli2-marl/games/nocca_nocca/nocca_nocca.py:45\u001b[39m, in \u001b[36mNoccaNocca.available_actions\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mavailable_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[ActionType]:\n\u001b[32m     44\u001b[39m     player = \u001b[38;5;28mself\u001b[39m.agent_name_mapping[\u001b[38;5;28mself\u001b[39m.agent_selection]\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     board_actions = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mboard\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlegal_moves\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplayer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mplayer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m     actions = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mself\u001b[39m.board_action_dict[x], board_actions))\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m actions\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/Master/obli2-marl/games/nocca_nocca/board.py:110\u001b[39m, in \u001b[36mBoard.legal_moves\u001b[39m\u001b[34m(self, player)\u001b[39m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m move \u001b[38;5;129;01min\u001b[39;00m MOVES:\n\u001b[32m    109\u001b[39m     action = (square[\u001b[32m0\u001b[39m], square[\u001b[32m1\u001b[39m], move)\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     is_legal_move, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mis_legal_move\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_legal_move:\n\u001b[32m    112\u001b[39m         legal_moves.append(action)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/Master/obli2-marl/games/nocca_nocca/board.py:125\u001b[39m, in \u001b[36mBoard.is_legal_move\u001b[39m\u001b[34m(self, player, action)\u001b[39m\n\u001b[32m    123\u001b[39m opponent_squares = np.argwhere(stack == Board._opponent(player)).tolist()\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m player_squares != []:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     max_pos = \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mplayer_squares\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(h > max_pos \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m opponent_squares):\n\u001b[32m    127\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m    128\u001b[39m             \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    129\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPlayer pieces in position (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) are blocked by an opponent piece\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    130\u001b[39m         )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# MCTS vs Random en Nocca-Nocca (M4 optimizado)\n",
    "mcts_vs_random_nocca = evaluate_agents(\n",
    "    NoccaNocca(max_steps=50, seed=1), \n",
    "    MonteCarloTreeSearch, \n",
    "    RandomAgent, \n",
    "    simulations=FAST_CONFIG['simulations_fast'],\n",
    "    rollouts=FAST_CONFIG['rollouts']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1e6ca6",
   "metadata": {},
   "source": [
    "Aca tambien lo corte para la ultima ejecucion, pero me quede con el ultimo resultado y esta acontinuacion:\n",
    "\n",
    "MonteCarloTreeSearch 7 - 2 RandomAgent | Empates: 6 | Errores: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cba6b58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MonteCarloTreeSearch 14 - 1 RandomAgent | Empates: 0 | Errores: 0\n"
     ]
    }
   ],
   "source": [
    "# MCTS vs Random en Leduc Poker (M4 optimizado)\n",
    "mcts_vs_random_leduc = evaluate_agents(\n",
    "    LeducPoker(), \n",
    "    MonteCarloTreeSearch, \n",
    "    RandomAgent, \n",
    "    simulations=FAST_CONFIG['simulations_fast'],\n",
    "    rollouts=FAST_CONFIG['rollouts']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27142771",
   "metadata": {},
   "source": [
    "## 5. An√°lisis de resultados\n",
    "\n",
    "Resumen de resultados y an√°lisis de performance de MCTS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "debfe114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MCTS PERFORMANCE ANALYSIS ===\n",
      "Config: {'episodes_test': 3, 'episodes_eval': 100, 'simulations_fast': 10, 'simulations_eval': 25, 'rollouts': 3}\n",
      "TicTacToe: 3 episodes\n",
      "Nocca-Nocca: 3 episodes\n",
      "Kuhn Poker: 3 episodes\n",
      "Leduc Poker: 3 episodes\n",
      "TicTacToe perf: ({'X': 71, 'O': 15}, 14)\n",
      "Kuhn Poker perf: ({'agent_0': 50, 'agent_1': 50}, 0)\n",
      "Leduc Poker perf: ({'agent_0': 23, 'agent_1': 46}, 31)\n",
      "Ultra_Fast: Time=0.4s, Wins={'X': 7, 'O': 2}\n",
      "Fast: Time=0.9s, Wins={'X': 7, 'O': 1}\n",
      "Balanced: Time=7.7s, Wins={'X': 9, 'O': 0}\n",
      "Quality: Time=21.3s, Wins={'X': 0, 'O': 0}\n",
      "MCTS vs Random (TicTacToe): (14, 1, 0)\n",
      "MCTS vs MiniMax (TicTacToe): (3, 4, 8)\n",
      "MCTS vs Random (Leduc Poker): (14, 1, 0)\n"
     ]
    }
   ],
   "source": [
    "print(\"=== MCTS PERFORMANCE ANALYSIS ===\")\n",
    "print(f\"Config: {FAST_CONFIG}\")\n",
    "print(f\"TicTacToe: {len(tictactoe_results)} episodes\")\n",
    "print(f\"Nocca-Nocca: {len(nocca_results)} episodes\") \n",
    "print(f\"Kuhn Poker: {len(kuhn_results)} episodes\")\n",
    "print(f\"Leduc Poker: {len(leduc_results)} episodes\")\n",
    "\n",
    "if 'tictactoe_performance' in locals():\n",
    "    print(f\"TicTacToe perf: {tictactoe_performance}\")\n",
    "if 'nocca_performance' in locals():\n",
    "    print(f\"Nocca-Nocca perf: {nocca_performance}\")\n",
    "if 'kuhn_performance' in locals():\n",
    "    print(f\"Kuhn Poker perf: {kuhn_performance}\")\n",
    "if 'leduc_performance' in locals():\n",
    "    print(f\"Leduc Poker perf: {leduc_performance}\")\n",
    "\n",
    "if 'tictactoe_configs' in locals():\n",
    "    for config, results in tictactoe_configs.items():\n",
    "        print(f\"{config}: Time={results['time']:.1f}s, Wins={results['wins']}\")\n",
    "\n",
    "if 'mcts_vs_random_ttt' in locals():\n",
    "    print(f\"MCTS vs Random (TicTacToe): {mcts_vs_random_ttt}\")\n",
    "if 'mcts_vs_minimax_ttt' in locals():\n",
    "    print(f\"MCTS vs MiniMax (TicTacToe): {mcts_vs_minimax_ttt}\")\n",
    "if 'mcts_vs_random_nocca' in locals():\n",
    "    print(f\"MCTS vs Random (Nocca-Nocca): {mcts_vs_random_nocca}\")\n",
    "if 'mcts_vs_random_leduc' in locals():\n",
    "    print(f\"MCTS vs Random (Leduc Poker): {mcts_vs_random_leduc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d894b8",
   "metadata": {},
   "source": [
    "## An√°lisis de Resultados\n",
    "\n",
    "**Configuraci√≥n utilizada:** `episodes_test=3`, `episodes_eval=100`, `simulations_fast=10`, `simulations_eval=25`, `rollouts=3`.\n",
    "\n",
    "### 1. Desempe√±o de MCTS en cada juego (evaluaci√≥n)\n",
    "\n",
    "- **TicTacToe:** X gan√≥ 76 partidas (76%), O gan√≥ 15 partidas (15%), 9 empates (9%).\n",
    "- **Nocca-Nocca:** White gan√≥ 98 partidas (98%), Black gan√≥ 2 partidas (2%), 0 empates.\n",
    "- **Kuhn Poker:** Ventaja ligera de `agent_0` con 52 victorias (52%) vs `agent_1` con 48 victorias (48%), 0 empates.\n",
    "- **Leduc Poker:** [Resultados se mostrar√°n despu√©s de ejecutar las celdas correspondientes]\n",
    "\n",
    "### 2. Optimizaci√≥n de par√°metros\n",
    "\n",
    "- **Ultra_Fast** `(simulations=5, rollouts=2)`: Tiempo=0.4s, X=3 (50%), O=3 (50%).\n",
    "- **Fast** `(simulations=10, rollouts=3)`: Tiempo=1.0s, X=5 (71%), O=2 (29%).\n",
    "- **Balanced** `(simulations=25, rollouts=5)`: Tiempo=7.9s, X=9 (100%), O=0 (0%).\n",
    "- **Quality** `(simulations=50, rollouts=8)`: Tiempo=23.3s, X=0, O=0 (posible timeout o empates).\n",
    "\n",
    "### 3. Comparativa con otros agentes en TicTacToe, Nocca-Nocca y Leduc Poker\n",
    "\n",
    "- **MCTS vs Random (TicTacToe):** MCTS gan√≥ 13 partidas (87%), Random 2 (13%), 0 empates.\n",
    "- **MCTS vs MiniMax (TicTacToe):** MiniMax domina con 9 victorias vs 0 de MCTS y 6 empates.\n",
    "- **MCTS vs Random (Nocca-Nocca):** MCTS gan√≥ 7 (54%), Random 2 (15%), 6 empates (31%).\n",
    "- **MCTS vs Random (Leduc Poker):** [Resultados se mostrar√°n despu√©s de ejecutar las celdas correspondientes]\n",
    "\n",
    "**Conclusiones:**\n",
    "\n",
    "- MCTS con configuraciones moderadas (e.g., Fast o Balanced) ofrece un buen compromiso entre velocidad y rendimiento en TicTacToe.\n",
    "- Para juegos determin√≠sticos con un espacio de estados reducido (TicTacToe), los algoritmos cl√°sicos como Minimax pueden superar a MCTS en profundidad limitada.\n",
    "- En juegos con mayor aleatoriedad o complejidad (Kuhn Poker, Nocca-Nocca, Leduc Poker), MCTS muestra un comportamiento estable comparado con agentes aleatorios.\n",
    "- Leduc Poker, siendo m√°s complejo que Kuhn Poker, deber√≠a proporcionar un mejor benchmark para evaluar las capacidades de MCTS en juegos de informaci√≥n imperfecta."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0f451b4",
   "metadata": {},
   "source": [
    "# Evaluación Comparativa Final de Algoritmos MARL\n",
    "\n",
    "## Mi Análisis Completo de Tres Algoritmos\n",
    "\n",
    "En este trabajo comparé tres algoritmos fundamentales de aprendizaje multi-agente aplicándolos a cuatro juegos diferentes. Mi objetivo fue entender cuándo usar cada uno y por qué algunos funcionan mejor que otros según el tipo de problema.\n",
    "\n",
    "### Los Algoritmos que Analicé\n",
    "\n",
    "1. **Minimax** - El algoritmo clásico para juegos de información perfecta\n",
    "2. **MCTS (Monte Carlo Tree Search)** - Método estocástico basado en simulaciones\n",
    "3. **CFR (Counterfactual Regret Minimization)** - Especializado en información imperfecta\n",
    "\n",
    "### Los Juegos que Usé\n",
    "\n",
    "1. **TicTacToe** - Información perfecta, espacio de estados pequeño\n",
    "2. **Nocca-Nocca** - Información perfecta, espacio de estados complejo  \n",
    "3. **Kuhn Poker (2P y 3P)** - Información imperfecta, complejidad moderada\n",
    "4. **Leduc Poker** - Información imperfecta, complejidad alta\n",
    "\n",
    "### Mi Metodología\n",
    "\n",
    "Para cada algoritmo medí:\n",
    "- Tasa de victoria contra agente aleatorio\n",
    "- Tiempo promedio de ejecución\n",
    "- Estabilidad y robustez del algoritmo\n",
    "- Comportamiento en comparaciones directas\n",
    "\n",
    "### Detalle interesante de gpu vs cpu\n",
    "Para todos los algoritmos intente paralelizar cuanto mas pueda utilizando vectores de torch en lugar de arrays en numpy, esto genero performance muy a la par en mcts y en minimax y acelero exponencialmente el tiempo corrida de los mismos (sobre todo en mcts con rollouts). Pero para CFR no ayudaba, no me quedo del todo claro si mi problema fue en guardar las memorias en tensores y cargarlas de nuevo (esto traia problemas) o el hecho de que mi implementacion estaba mal simplemente. Despues de mucho debuggeo me rendi e implemente CFR con cpu que daba buenos rendimientos y realmente aprendia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efccdfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar todas las librerías y módulos necesarios\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importar juegos\n",
    "from games.tictactoe.tictactoe import TicTacToe\n",
    "from games.nocca_nocca.nocca_nocca import NoccaNocca\n",
    "from games.kuhn.kuhn import KuhnPoker\n",
    "from games.kuhn.kuhn_3player import KuhnPoker3Player\n",
    "from games.leduc.leduc import LeducPoker\n",
    "\n",
    "# Importar agentes\n",
    "from agents.minimax import MiniMax\n",
    "from agents.mcts_t import MonteCarloTreeSearch\n",
    "from agents.counterfactualregret_t import CounterFactualRegret\n",
    "from agents.agent_random import RandomAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c14fe0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Funciones CFR corregidas usando CounterFactualRegret.load_trained_agent()\n"
     ]
    }
   ],
   "source": [
    "# Funciones de evaluación estándar para todos los algoritmos\n",
    "\n",
    "def evaluar_agente_vs_random(game, agent_class, agent_params, episodes=20):\n",
    "    \"\"\"Evalúa cualquier agente vs Random con métricas esenciales\"\"\"\n",
    "    wins = 0\n",
    "    draws = 0\n",
    "    total_time = 0\n",
    "    errors = 0\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        try:\n",
    "            game.reset()\n",
    "            \n",
    "            agents = {\n",
    "                game.agents[0]: agent_class(game=game, agent=game.agents[0], **agent_params),\n",
    "                game.agents[1]: RandomAgent(game=game, agent=game.agents[1])\n",
    "            }\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            while not game.game_over():\n",
    "                action = agents[game.agent_selection].action()\n",
    "                game.step(action)\n",
    "            \n",
    "            total_time += time.time() - start_time\n",
    "            \n",
    "            rewards = {agent: game.reward(agent) for agent in game.agents}\n",
    "            if rewards[game.agents[0]] > rewards[game.agents[1]]:\n",
    "                wins += 1\n",
    "            elif rewards[game.agents[0]] == rewards[game.agents[1]]:\n",
    "                draws += 1\n",
    "                \n",
    "        except Exception:\n",
    "            errors += 1\n",
    "    \n",
    "    valid_episodes = episodes - errors\n",
    "    win_rate = (wins / valid_episodes * 100) if valid_episodes > 0 else 0\n",
    "    avg_time = (total_time / valid_episodes) if valid_episodes > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'win_rate': win_rate,\n",
    "        'draws': draws,\n",
    "        'avg_time': avg_time,\n",
    "        'errors': errors\n",
    "    }\n",
    "\n",
    "def comparar_dos_agentes(game, agent1_class, agent1_params, agent2_class, agent2_params, episodes=20):\n",
    "    \"\"\"Compara dos agentes entre sí\"\"\"\n",
    "    agent1_wins = 0\n",
    "    agent2_wins = 0\n",
    "    draws = 0\n",
    "    errors = 0\n",
    "    total_time = 0\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        try:\n",
    "            game.reset()\n",
    "            \n",
    "            agents = {\n",
    "                game.agents[0]: agent1_class(game=game, agent=game.agents[0], **agent1_params),\n",
    "                game.agents[1]: agent2_class(game=game, agent=game.agents[1], **agent2_params)\n",
    "            }\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            while not game.game_over():\n",
    "                action = agents[game.agent_selection].action()\n",
    "                game.step(action)\n",
    "            \n",
    "            total_time += time.time() - start_time\n",
    "            \n",
    "            rewards = {agent: game.reward(agent) for agent in game.agents}\n",
    "            if rewards[game.agents[0]] > rewards[game.agents[1]]:\n",
    "                agent1_wins += 1\n",
    "            elif rewards[game.agents[0]] < rewards[game.agents[1]]:\n",
    "                agent2_wins += 1\n",
    "            else:\n",
    "                draws += 1\n",
    "                \n",
    "        except Exception:\n",
    "            errors += 1\n",
    "    \n",
    "    return {\n",
    "        'agent1_wins': agent1_wins,\n",
    "        'agent2_wins': agent2_wins,\n",
    "        'draws': draws,\n",
    "        'errors': errors,\n",
    "        'avg_time': total_time / episodes if episodes > 0 else 0\n",
    "    }\n",
    "\n",
    "\n",
    "import time\n",
    "from agents.counterfactualregret_t import CounterFactualRegret\n",
    "from agents.agent_random import RandomAgent\n",
    "\n",
    "def evaluar_cfr_vs_random(game, agent_files, episodes=20):\n",
    "    \"\"\"Evalúa agentes CFR vs Random usando el método correcto de carga.\"\"\"\n",
    "    \n",
    "    wins = 0\n",
    "    draws = 0\n",
    "    errors = 0\n",
    "    total_time = 0\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        try:\n",
    "            # Crear nueva instancia del juego\n",
    "            game_instance = type(game)()\n",
    "            game_instance.reset()\n",
    "            \n",
    "            # Obtener agentes\n",
    "            agent_ids = game_instance.agents\n",
    "            first_agent = agent_ids[0]\n",
    "            second_agent = agent_ids[1] if len(agent_ids) > 1 else agent_ids[0]\n",
    "            \n",
    "            # CORREGIR: Crear agente CFR y cargar estrategia correctamente\n",
    "            if first_agent not in agent_files:\n",
    "                errors += 1\n",
    "                continue\n",
    "                \n",
    "            cfr_file = agent_files[first_agent]\n",
    "            cfr_file_path = f\"trained_cfr_agents/{cfr_file}\"\n",
    "            \n",
    "            # Crear agente CFR nuevo\n",
    "            cfr_agent = CounterFactualRegret(game=game_instance, agent=first_agent)\n",
    "            \n",
    "            # Cargar agente entrenado usando método estático\n",
    "            loaded_agent = CounterFactualRegret.load_trained_agent(cfr_file_path, game_instance, first_agent)\n",
    "            \n",
    "            # Verificar que se cargó correctamente\n",
    "            if loaded_agent is None or not hasattr(loaded_agent, 'action'):\n",
    "                errors += 1\n",
    "                continue\n",
    "            \n",
    "            # Crear agente random\n",
    "            random_agent = RandomAgent(game_instance, second_agent)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            step_count = 0\n",
    "            max_steps = 50\n",
    "            \n",
    "            while not game_instance.game_over() and step_count < max_steps:\n",
    "                current_agent = game_instance.agent_selection\n",
    "                \n",
    "                if current_agent == first_agent:\n",
    "                    action = loaded_agent.action()\n",
    "                elif current_agent == second_agent:\n",
    "                    action = random_agent.action()\n",
    "                else:\n",
    "                    available = game_instance.available_actions()\n",
    "                    action = available[0] if available else None\n",
    "                \n",
    "                if action is not None:\n",
    "                    game_instance.step(action)\n",
    "                step_count += 1\n",
    "            \n",
    "            episode_time = time.time() - start_time\n",
    "            total_time += episode_time\n",
    "            \n",
    "            # Evaluar resultado\n",
    "            if game_instance.game_over():\n",
    "                rewards = {agent: game_instance.reward(agent) for agent in game_instance.agents}\n",
    "                if rewards[first_agent] > rewards[second_agent]:\n",
    "                    wins += 1\n",
    "                elif rewards[first_agent] == rewards[second_agent]:\n",
    "                    draws += 1\n",
    "            else:\n",
    "                draws += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            errors += 1\n",
    "    \n",
    "    win_rate = (wins / episodes) * 100 if episodes > 0 else 0\n",
    "    avg_time = total_time / episodes if episodes > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'win_rate': win_rate,\n",
    "        'avg_time': avg_time,\n",
    "        'draws': draws,\n",
    "        'errors': errors\n",
    "    }\n",
    "\n",
    "def comparar_agente_vs_cfr(game, agent_class, agent_params, cfr_files, agent_name=\"Agente\", episodes=20):\n",
    "    \"\"\"Compara un agente vs CFR usando el método correcto de carga.\"\"\"\n",
    "    \n",
    "    wins = 0\n",
    "    draws = 0\n",
    "    errors = 0\n",
    "    total_time = 0\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        try:\n",
    "            # Crear nueva instancia del juego\n",
    "            game_instance = type(game)()\n",
    "            game_instance.reset()\n",
    "            \n",
    "            # Obtener agentes\n",
    "            agent_ids = game_instance.agents\n",
    "            first_agent = agent_ids[0]  # Agente de prueba\n",
    "            second_agent = agent_ids[1] if len(agent_ids) > 1 else agent_ids[0]  # CFR\n",
    "            \n",
    "            # Verificar que el agente CFR existe\n",
    "            if second_agent not in cfr_files:\n",
    "                errors += 1\n",
    "                continue\n",
    "            \n",
    "            # Crear agente de prueba\n",
    "            test_agent = agent_class(game_instance, first_agent, **agent_params)\n",
    "            \n",
    "            # Cargar agente CFR usando el método correcto\n",
    "            cfr_file = cfr_files[second_agent]\n",
    "            cfr_file_path = f\"trained_cfr_agents/{cfr_file}\"\n",
    "            cfr_agent = CounterFactualRegret.load_trained_agent(cfr_file_path, game_instance, second_agent)\n",
    "            \n",
    "            # Verificar que se cargó correctamente\n",
    "            if cfr_agent is None or not hasattr(cfr_agent, 'action'):\n",
    "                errors += 1\n",
    "                continue\n",
    "            \n",
    "            start_time = time.time()\n",
    "            step_count = 0\n",
    "            max_steps = 50\n",
    "            \n",
    "            while not game_instance.game_over() and step_count < max_steps:\n",
    "                current_agent = game_instance.agent_selection\n",
    "                \n",
    "                if current_agent == first_agent:\n",
    "                    action = test_agent.action()\n",
    "                elif current_agent == second_agent:\n",
    "                    action = cfr_agent.action()\n",
    "                else:\n",
    "                    available = game_instance.available_actions()\n",
    "                    action = available[0] if available else None\n",
    "                \n",
    "                if action is not None:\n",
    "                    game_instance.step(action)\n",
    "                step_count += 1\n",
    "            \n",
    "            episode_time = time.time() - start_time\n",
    "            total_time += episode_time\n",
    "            \n",
    "            # Evaluar resultado (perspectiva del agente de prueba)\n",
    "            if game_instance.game_over():\n",
    "                rewards = {agent: game_instance.reward(agent) for agent in game_instance.agents}\n",
    "                if rewards[first_agent] > rewards[second_agent]:\n",
    "                    wins += 1\n",
    "                elif rewards[first_agent] == rewards[second_agent]:\n",
    "                    draws += 1\n",
    "            else:\n",
    "                draws += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            errors += 1\n",
    "    \n",
    "    win_rate = (wins / episodes) * 100 if episodes > 0 else 0\n",
    "    avg_time = total_time / episodes if episodes > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'agent_wins': wins,\n",
    "        'cfr_wins': episodes - wins - draws - errors,\n",
    "        'draws': draws,\n",
    "        'errors': errors,\n",
    "        'win_rate': win_rate,\n",
    "        'avg_time': avg_time\n",
    "    }\n",
    "\n",
    "def comparar_agente_vs_doble_cfr(game, agent_class, agent_params, cfr_files, agent_name=\"Agente\", episodes=20):\n",
    "    \"\"\"Compara un agente vs múltiples CFR (para juegos de 3+ jugadores).\"\"\"\n",
    "    \n",
    "    # Para juegos de 2 jugadores, usar función simple\n",
    "    if len(game.agents) < 3:\n",
    "        return comparar_agente_vs_cfr(game, agent_class, agent_params, cfr_files, agent_name, episodes)\n",
    "    \n",
    "    wins = 0\n",
    "    draws = 0\n",
    "    errors = 0\n",
    "    total_time = 0\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        try:\n",
    "            # Crear nueva instancia del juego\n",
    "            game_instance = type(game)()\n",
    "            game_instance.reset()\n",
    "            \n",
    "            agent_ids = game_instance.agents\n",
    "            test_agent_id = agent_ids[0]\n",
    "            cfr_agent_ids = agent_ids[1:3]  # Siguientes 2 agentes\n",
    "            \n",
    "            # Crear agente de prueba\n",
    "            test_agent = agent_class(game_instance, test_agent_id, **agent_params)\n",
    "            \n",
    "            # Cargar agentes CFR usando el método correcto\n",
    "            cfr_agents = {}\n",
    "            for cfr_agent_id in cfr_agent_ids:\n",
    "                if cfr_agent_id in cfr_files:\n",
    "                    cfr_file = cfr_files[cfr_agent_id]\n",
    "                    cfr_file_path = f\"trained_cfr_agents/{cfr_file}\"\n",
    "                    loaded_cfr = CounterFactualRegret.load_trained_agent(cfr_file_path, game_instance, cfr_agent_id)\n",
    "                    if loaded_cfr is not None and hasattr(loaded_cfr, 'action'):\n",
    "                        cfr_agents[cfr_agent_id] = loaded_cfr\n",
    "            \n",
    "            start_time = time.time()\n",
    "            step_count = 0\n",
    "            max_steps = 100  # Más pasos para juegos multiagente\n",
    "            \n",
    "            while not game_instance.game_over() and step_count < max_steps:\n",
    "                current_agent = game_instance.agent_selection\n",
    "                \n",
    "                if current_agent == test_agent_id:\n",
    "                    action = test_agent.action()\n",
    "                elif current_agent in cfr_agents:\n",
    "                    action = cfr_agents[current_agent].action()\n",
    "                else:\n",
    "                    # Fallback para agentes adicionales\n",
    "                    available = game_instance.available_actions()\n",
    "                    action = available[0] if available else None\n",
    "                \n",
    "                if action is not None:\n",
    "                    game_instance.step(action)\n",
    "                step_count += 1\n",
    "            \n",
    "            episode_time = time.time() - start_time\n",
    "            total_time += episode_time\n",
    "            \n",
    "            # Evaluar resultado (agente de prueba vs otros)\n",
    "            if game_instance.game_over():\n",
    "                rewards = {agent: game_instance.reward(agent) for agent in game_instance.agents}\n",
    "                test_reward = rewards.get(test_agent_id, 0)\n",
    "                other_rewards = [rewards.get(aid, 0) for aid in agent_ids[1:]]\n",
    "                \n",
    "                if other_rewards:\n",
    "                    max_other = max(other_rewards)\n",
    "                    if test_reward > max_other:\n",
    "                        wins += 1\n",
    "                    elif test_reward == max_other:\n",
    "                        draws += 1\n",
    "                else:\n",
    "                    draws += 1\n",
    "            else:\n",
    "                draws += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error en episodio {episode}: {e}\")\n",
    "            errors += 1\n",
    "    \n",
    "    win_rate = (wins / episodes) * 100 if episodes > 0 else 0\n",
    "    avg_time = total_time / episodes if episodes > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'agent_wins': wins,\n",
    "        'cfr_wins': episodes - wins - draws - errors,\n",
    "        'draws': draws,\n",
    "        'errors': errors,\n",
    "        'win_rate': win_rate,\n",
    "        'avg_time': avg_time,\n",
    "        'test_position': f\"{agent_name} como {test_agent_id}\"\n",
    "    }\n",
    "\n",
    "print(\"✅ Funciones CFR corregidas usando CounterFactualRegret.load_trained_agent()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67e72f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de parámetros óptimos por algoritmo y juego\n",
    "\n",
    "# Parámetros optimizados para Minimax\n",
    "MINIMAX_CONFIG = {\n",
    "    'TicTacToe': {'depth': 4, 'episodes': 15},\n",
    "    'NoccaNocca': {'depth': 2, 'episodes': 10}, \n",
    "    'KuhnPoker_2P': {'depth': 3, 'episodes': 20},\n",
    "    'KuhnPoker_3P': {'depth': 2, 'episodes': 15},\n",
    "    'LeducPoker': {'depth': 2, 'episodes': 15}\n",
    "}\n",
    "\n",
    "# Parámetros optimizados para MCTS\n",
    "MCTS_CONFIG = {\n",
    "    'TicTacToe': {'simulations': 150, 'episodes': 15},\n",
    "    'NoccaNocca': {'simulations': 100, 'episodes': 10},\n",
    "    'KuhnPoker_2P': {'simulations': 100, 'episodes': 20},\n",
    "    'KuhnPoker_3P': {'simulations': 80, 'episodes': 15},\n",
    "    'LeducPoker': {'simulations': 80, 'episodes': 15}\n",
    "}\n",
    "\n",
    "# Archivos de agentes CFR entrenados (usando archivos que funcionan correctamente)\n",
    "CFR_AGENTS = {\n",
    "    'TicTacToe': {\n",
    "        'X': 'TicTacToe_Intensivo_X.pkl',\n",
    "        'O': 'TicTacToe_Intensivo_O.pkl'\n",
    "    },\n",
    "    'KuhnPoker_2P': {\n",
    "        'agent_0': 'KuhnPoker_2P_Intensivo_agent_0.pkl',\n",
    "        'agent_1': 'KuhnPoker_2P_Intensivo_agent_1.pkl'\n",
    "    },\n",
    "    'KuhnPoker_3P': {\n",
    "        'agent_0': 'KuhnPoker_3P_Intensivo_agent_0.pkl',\n",
    "        'agent_1': 'KuhnPoker_3P_Intensivo_agent_1.pkl',\n",
    "        'agent_2': 'KuhnPoker_3P_Intensivo_agent_2.pkl'\n",
    "    },\n",
    "    'LeducPoker': {\n",
    "        'agent_0': 'LeducPoker_Intensivo_agent_0.pkl',\n",
    "        'agent_1': 'LeducPoker_Intensivo_agent_1.pkl'\n",
    "    },\n",
    "    'NoccaNocca': {\n",
    "        'Black': 'NoccaNocca_Adaptado_Black.pkl',\n",
    "        'White': 'NoccaNocca_Adaptado_White.pkl'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Lista de juegos para evaluación\n",
    "JUEGOS = {\n",
    "    'TicTacToe': TicTacToe(),\n",
    "    'NoccaNocca': NoccaNocca(max_steps=30, seed=1),\n",
    "    'KuhnPoker_2P': KuhnPoker(),\n",
    "    'KuhnPoker_3P': KuhnPoker3Player(),\n",
    "    'LeducPoker': LeducPoker()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcf842c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17d6fd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EVALUACIÓN EN TICTACTOE ===\n",
      "\n",
      "1. Minimax vs Random:\n",
      "🔧 MiniMax usando: MPS (Apple Silicon)\n",
      "   Win Rate: 100.0%\n",
      "   Avg Time: 0.728s\n",
      "   Draws: 0\n",
      "\n",
      "2. MCTS vs Random:\n",
      "🔧 MCTS usando: MPS (Apple Silicon)\n",
      "   Win Rate: 100.0%\n",
      "   Avg Time: 3.924s\n",
      "   Draws: 0\n",
      "\n",
      "3. CFR vs Random:\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_X.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_X.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_X.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_X.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_X.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_X.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_X.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_X.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_X.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_X.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_X.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_X.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_X.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_X.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_X.pkl, nodes: 4520\n",
      "   Win Rate: 66.7%\n",
      "   Avg Time: 0.000s\n",
      "   Draws: 2\n",
      "\n",
      "4. Minimax vs MCTS:\n",
      "   Minimax: 12 wins\n",
      "   MCTS: 1 wins\n",
      "   Draws: 7\n",
      "\n",
      "5. Minimax vs CFR:\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "   Minimax: 18 wins\n",
      "   CFR: 1 wins\n",
      "   Draws: 1\n",
      "\n",
      "6. MCTS vs CFR:\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "   MCTS: 20 wins\n",
      "   CFR: 0 wins\n",
      "   Draws: 0\n",
      "\n",
      "=== RESUMEN TICTACTOE ===\n",
      "Minimax:     100.0% vs Random\n",
      "MCTS:        100.0% vs Random\n",
      "CFR:          66.7% vs Random\n",
      "Minimax vs MCTS: 12-1\n",
      "Minimax vs CFR:  18-1\n",
      "MCTS vs CFR:     20-0\n"
     ]
    }
   ],
   "source": [
    "# EVALUACIÓN COMPLETA EN TICTACTOE\n",
    "print(\"=== EVALUACIÓN EN TICTACTOE ===\")\n",
    "\n",
    "# 1. Minimax vs Random\n",
    "print(\"\\n1. Minimax vs Random:\")\n",
    "minimax_ttt = evaluar_agente_vs_random(\n",
    "    TicTacToe(), \n",
    "    MiniMax, \n",
    "    {'depth': 4}, \n",
    "    episodes=15\n",
    ")\n",
    "print(f\"   Win Rate: {minimax_ttt['win_rate']:.1f}%\")\n",
    "print(f\"   Avg Time: {minimax_ttt['avg_time']:.3f}s\")\n",
    "print(f\"   Draws: {minimax_ttt['draws']}\")\n",
    "\n",
    "# 2. MCTS vs Random  \n",
    "print(\"\\n2. MCTS vs Random:\")\n",
    "mcts_ttt = evaluar_agente_vs_random(\n",
    "    TicTacToe(), \n",
    "    MonteCarloTreeSearch, \n",
    "    {'simulations': 150}, \n",
    "    episodes=15\n",
    ")\n",
    "print(f\"   Win Rate: {mcts_ttt['win_rate']:.1f}%\")\n",
    "print(f\"   Avg Time: {mcts_ttt['avg_time']:.3f}s\")\n",
    "print(f\"   Draws: {mcts_ttt['draws']}\")\n",
    "\n",
    "# 3. CFR vs Random\n",
    "print(\"\\n3. CFR vs Random:\")\n",
    "cfr_ttt_files = CFR_AGENTS['TicTacToe']\n",
    "cfr_ttt = evaluar_cfr_vs_random(TicTacToe(), cfr_ttt_files, episodes=15)\n",
    "if cfr_ttt:\n",
    "    print(f\"   Win Rate: {cfr_ttt['win_rate']:.1f}%\")\n",
    "    print(f\"   Avg Time: {cfr_ttt['avg_time']:.3f}s\")\n",
    "    print(f\"   Draws: {cfr_ttt['draws']}\")\n",
    "else:\n",
    "    print(\"   Error: No se pudieron cargar agentes CFR\")\n",
    "\n",
    "# 4. Minimax vs MCTS\n",
    "print(\"\\n4. Minimax vs MCTS:\")\n",
    "comp_mm_mcts = comparar_dos_agentes(\n",
    "    TicTacToe(),\n",
    "    MiniMax, {'depth': 4},\n",
    "    MonteCarloTreeSearch, {'simulations': 150},\n",
    "    episodes=20\n",
    ")\n",
    "print(f\"   Minimax: {comp_mm_mcts['agent1_wins']} wins\")\n",
    "print(f\"   MCTS: {comp_mm_mcts['agent2_wins']} wins\")\n",
    "print(f\"   Draws: {comp_mm_mcts['draws']}\")\n",
    "\n",
    "# 5. Minimax vs CFR\n",
    "if cfr_ttt:\n",
    "    print(\"\\n5. Minimax vs CFR:\")\n",
    "    comp_mm_cfr = comparar_agente_vs_cfr(\n",
    "        TicTacToe(),\n",
    "        MiniMax, {'depth': 4},\n",
    "        cfr_ttt_files,\n",
    "        \"Minimax\",\n",
    "        episodes=20\n",
    "    )\n",
    "    if comp_mm_cfr:\n",
    "        print(f\"   Minimax: {comp_mm_cfr['agent_wins']} wins\")\n",
    "        print(f\"   CFR: {comp_mm_cfr['cfr_wins']} wins\")\n",
    "        print(f\"   Draws: {comp_mm_cfr['draws']}\")\n",
    "    else:\n",
    "        print(\"   Error: No se pudieron cargar agentes CFR para comparación\")\n",
    "else:\n",
    "    print(\"\\n5. Minimax vs CFR: No disponible (CFR no cargado)\")\n",
    "\n",
    "# 6. MCTS vs CFR\n",
    "if cfr_ttt:\n",
    "    print(\"\\n6. MCTS vs CFR:\")\n",
    "    comp_mcts_cfr = comparar_agente_vs_cfr(\n",
    "        TicTacToe(),\n",
    "        MonteCarloTreeSearch, {'simulations': 150},\n",
    "        cfr_ttt_files,\n",
    "        \"MCTS\",\n",
    "        episodes=20\n",
    "    )\n",
    "    if comp_mcts_cfr:\n",
    "        print(f\"   MCTS: {comp_mcts_cfr['agent_wins']} wins\")\n",
    "        print(f\"   CFR: {comp_mcts_cfr['cfr_wins']} wins\")\n",
    "        print(f\"   Draws: {comp_mcts_cfr['draws']}\")\n",
    "    else:\n",
    "        print(\"   Error: No se pudieron cargar agentes CFR para comparación\")\n",
    "else:\n",
    "    print(\"\\n6. MCTS vs CFR: No disponible (CFR no cargado)\")\n",
    "\n",
    "print(f\"\\n=== RESUMEN TICTACTOE ===\")\n",
    "print(f\"Minimax:     {minimax_ttt['win_rate']:>5.1f}% vs Random\")\n",
    "print(f\"MCTS:        {mcts_ttt['win_rate']:>5.1f}% vs Random\")\n",
    "if cfr_ttt:\n",
    "    print(f\"CFR:         {cfr_ttt['win_rate']:>5.1f}% vs Random\")\n",
    "print(f\"Minimax vs MCTS: {comp_mm_mcts['agent1_wins']}-{comp_mm_mcts['agent2_wins']}\")\n",
    "if cfr_ttt and 'comp_mm_cfr' in locals() and comp_mm_cfr:\n",
    "    print(f\"Minimax vs CFR:  {comp_mm_cfr['agent_wins']}-{comp_mm_cfr['cfr_wins']}\")\n",
    "if cfr_ttt and 'comp_mcts_cfr' in locals() and comp_mcts_cfr:\n",
    "    print(f\"MCTS vs CFR:     {comp_mcts_cfr['agent_wins']}-{comp_mcts_cfr['cfr_wins']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8f0367",
   "metadata": {},
   "source": [
    "### Análisis de Resultados en TicTacToe\n",
    "\n",
    "#### Rendimiento vs Random\n",
    "\n",
    "Los resultados muestran las diferencias esperadas entre algoritmos. Minimax presenta el mejor rendimiento en términos de tasa de victoria y eficiencia temporal, confirmando su idoneidad para juegos de información perfecta simples.\n",
    "\n",
    "MCTS logra un rendimiento competente pero inferior a Minimax tanto en efectividad como en velocidad. Su enfoque estocástico introduce overhead innecesario para un problema que puede resolverse determinísticamente.\n",
    "\n",
    "CFR funciona después del entrenamiento pero representa una aplicación inadecuada de complejidad para este tipo de problema específico.\n",
    "\n",
    "#### Comparaciones Directas\n",
    "\n",
    "La comparación directa entre Minimax y MCTS confirma la superioridad del enfoque determinístico para este dominio. La diferencia en rendimiento justifica la selección de Minimax como algoritmo óptimo para TicTacToe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eecca3",
   "metadata": {},
   "source": [
    "## 2. Kuhn Poker - Información Imperfecta\n",
    "\n",
    "### Características del Juego\n",
    "\n",
    "Kuhn Poker introduce información imperfecta al ocultar las cartas de los oponentes. Este cambio fundamental altera completamente las estrategias óptimas y la aplicabilidad de cada algoritmo.\n",
    "\n",
    "### Hipótesis\n",
    "\n",
    "Esperaba que CFR dominara en este contexto debido a su diseño específico para información imperfecta. Minimax debería tener limitaciones significativas por su incapacidad de manejar incertidumbre de manera óptima, mientras que MCTS debería ocupar una posición intermedia.\n",
    "\n",
    "### Variantes Evaluadas\n",
    "\n",
    "- **Kuhn 2 jugadores**: La versión estándar\n",
    "- **Kuhn 3 jugadores**: Mayor complejidad y incertidumbre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1c02570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EVALUACIÓN EN KUHN POKER 2P ===\n",
      "\n",
      "1. Minimax vs Random:\n",
      "   Win Rate: 50.0%\n",
      "   Avg Time: 0.001s\n",
      "   Draws: 0\n",
      "\n",
      "2. MCTS vs Random:\n",
      "   Win Rate: 60.0%\n",
      "   Avg Time: 0.230s\n",
      "   Draws: 0\n",
      "\n",
      "3. CFR vs Random:\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "   Win Rate: 35.0%\n",
      "   Avg Time: 0.000s\n",
      "   Draws: 0\n",
      "\n",
      "4. Minimax vs MCTS:\n",
      "   Minimax: 11 wins\n",
      "   MCTS: 9 wins\n",
      "   Draws: 0\n",
      "\n",
      "5. Minimax vs CFR:\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "   Minimax: 15 wins\n",
      "   CFR: 5 wins\n",
      "   Draws: 0\n",
      "\n",
      "6. MCTS vs CFR:\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "   MCTS: 12 wins\n",
      "   CFR: 8 wins\n",
      "   Draws: 0\n",
      "\n",
      "=== RESUMEN KUHN 2P ===\n",
      "Minimax:      50.0% vs Random\n",
      "MCTS:         60.0% vs Random\n",
      "CFR:          35.0% vs Random\n",
      "Minimax vs MCTS: 11-9\n",
      "Minimax vs CFR:  15-5\n",
      "MCTS vs CFR:     12-8\n",
      "=== KUHN POKER (3 JUGADORES) ===\n",
      "\n",
      "1. Minimax vs Random:\n",
      "   Win Rate: 0.0%\n",
      "   Avg Time: 0.000s\n",
      "   Draws: 0\n",
      "\n",
      "2. MCTS vs Random:\n",
      "   Win Rate: 0.0%\n",
      "   Avg Time: 0.000s\n",
      "   Draws: 0\n",
      "\n",
      "3. CFR vs Random:\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_0.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_0.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_0.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_0.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_0.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_0.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_0.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_0.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_0.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_0.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_0.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_0.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_0.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_0.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_0.pkl, nodes: 153\n",
      "   Win Rate: 73.3%\n",
      "   Avg Time: 0.000s\n",
      "   Draws: 0\n",
      "\n",
      "4. Minimax vs MCTS:\n",
      "   Minimax: 0 wins\n",
      "   MCTS: 0 wins\n",
      "   Draws: 0\n",
      "\n",
      "5. Minimax vs CFR:\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "   Minimax (player_0): 7 wins\n",
      "   CFR (player_1&2): 8 wins\n",
      "   Draws: 0\n",
      "   Configuración: Minimax como agent_0\n",
      "\n",
      "6. MCTS vs CFR:\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "   MCTS (player_0): 5 wins\n",
      "   CFR (player_1&2): 10 wins\n",
      "   Draws: 0\n",
      "   Configuración: MCTS como agent_0\n",
      "\n",
      "=== RESUMEN KUHN 3P ===\n",
      "Minimax:       0.0% vs Random\n",
      "MCTS:          0.0% vs Random\n",
      "CFR:          73.3% vs Random\n",
      "Minimax vs MCTS: 0-0\n",
      "Minimax vs CFR: 7-8 (MM en player_0)\n",
      "MCTS vs CFR: 5-10 (MCTS en player_0)\n"
     ]
    }
   ],
   "source": [
    "# EVALUACIÓN COMPLETA EN KUHN POKER 2 JUGADORES\n",
    "print(\"=== EVALUACIÓN EN KUHN POKER 2P ===\")\n",
    "\n",
    "# 1. Minimax vs Random\n",
    "print(\"\\n1. Minimax vs Random:\")\n",
    "minimax_kuhn2p = evaluar_agente_vs_random(\n",
    "    KuhnPoker(), \n",
    "    MiniMax, \n",
    "    {'depth': 3}, \n",
    "    episodes=20\n",
    ")\n",
    "print(f\"   Win Rate: {minimax_kuhn2p['win_rate']:.1f}%\")\n",
    "print(f\"   Avg Time: {minimax_kuhn2p['avg_time']:.3f}s\")\n",
    "print(f\"   Draws: {minimax_kuhn2p['draws']}\")\n",
    "\n",
    "# 2. MCTS vs Random\n",
    "print(\"\\n2. MCTS vs Random:\")\n",
    "mcts_kuhn2p = evaluar_agente_vs_random(\n",
    "    KuhnPoker(), \n",
    "    MonteCarloTreeSearch, \n",
    "    {'simulations': 100}, \n",
    "    episodes=20\n",
    ")\n",
    "print(f\"   Win Rate: {mcts_kuhn2p['win_rate']:.1f}%\")\n",
    "print(f\"   Avg Time: {mcts_kuhn2p['avg_time']:.3f}s\")\n",
    "print(f\"   Draws: {mcts_kuhn2p['draws']}\")\n",
    "\n",
    "# 3. CFR vs Random\n",
    "print(\"\\n3. CFR vs Random:\")\n",
    "cfr_kuhn2p_files = CFR_AGENTS['KuhnPoker_2P']\n",
    "cfr_kuhn2p = evaluar_cfr_vs_random(KuhnPoker(), cfr_kuhn2p_files, episodes=20)\n",
    "if cfr_kuhn2p:\n",
    "    print(f\"   Win Rate: {cfr_kuhn2p['win_rate']:.1f}%\")\n",
    "    print(f\"   Avg Time: {cfr_kuhn2p['avg_time']:.3f}s\")\n",
    "    print(f\"   Draws: {cfr_kuhn2p['draws']}\")\n",
    "else:\n",
    "    print(\"   Error: No se pudieron cargar agentes CFR\")\n",
    "\n",
    "# 4. Minimax vs MCTS\n",
    "print(\"\\n4. Minimax vs MCTS:\")\n",
    "comp_mm_mcts_k2p = comparar_dos_agentes(\n",
    "    KuhnPoker(),\n",
    "    MiniMax, {'depth': 3},\n",
    "    MonteCarloTreeSearch, {'simulations': 100},\n",
    "    episodes=20\n",
    ")\n",
    "print(f\"   Minimax: {comp_mm_mcts_k2p['agent1_wins']} wins\")\n",
    "print(f\"   MCTS: {comp_mm_mcts_k2p['agent2_wins']} wins\")\n",
    "print(f\"   Draws: {comp_mm_mcts_k2p['draws']}\")\n",
    "\n",
    "# 5. Minimax vs CFR\n",
    "if cfr_kuhn2p:\n",
    "    print(\"\\n5. Minimax vs CFR:\")\n",
    "    comp_mm_cfr_k2p = comparar_agente_vs_cfr(\n",
    "        KuhnPoker(),\n",
    "        MiniMax, {'depth': 3},\n",
    "        cfr_kuhn2p_files,\n",
    "        \"Minimax\",\n",
    "        episodes=20\n",
    "    )\n",
    "    if comp_mm_cfr_k2p:\n",
    "        print(f\"   Minimax: {comp_mm_cfr_k2p['agent_wins']} wins\")\n",
    "        print(f\"   CFR: {comp_mm_cfr_k2p['cfr_wins']} wins\")\n",
    "        print(f\"   Draws: {comp_mm_cfr_k2p['draws']}\")\n",
    "    else:\n",
    "        print(\"   Error: No se pudieron cargar agentes CFR para comparación\")\n",
    "else:\n",
    "    print(\"\\n5. Minimax vs CFR: No disponible (CFR no cargado)\")\n",
    "\n",
    "# 6. MCTS vs CFR\n",
    "if cfr_kuhn2p:\n",
    "    print(\"\\n6. MCTS vs CFR:\")\n",
    "    comp_mcts_cfr_k2p = comparar_agente_vs_cfr(\n",
    "        KuhnPoker(),\n",
    "        MonteCarloTreeSearch, {'simulations': 100},\n",
    "        cfr_kuhn2p_files,\n",
    "        \"MCTS\",\n",
    "        episodes=20\n",
    "    )\n",
    "    if comp_mcts_cfr_k2p:\n",
    "        print(f\"   MCTS: {comp_mcts_cfr_k2p['agent_wins']} wins\")\n",
    "        print(f\"   CFR: {comp_mcts_cfr_k2p['cfr_wins']} wins\")\n",
    "        print(f\"   Draws: {comp_mcts_cfr_k2p['draws']}\")\n",
    "    else:\n",
    "        print(\"   Error: No se pudieron cargar agentes CFR para comparación\")\n",
    "else:\n",
    "    print(\"\\n6. MCTS vs CFR: No disponible (CFR no cargado)\")\n",
    "\n",
    "print(f\"\\n=== RESUMEN KUHN 2P ===\")\n",
    "print(f\"Minimax:     {minimax_kuhn2p['win_rate']:>5.1f}% vs Random\")\n",
    "print(f\"MCTS:        {mcts_kuhn2p['win_rate']:>5.1f}% vs Random\")\n",
    "if cfr_kuhn2p:\n",
    "    print(f\"CFR:         {cfr_kuhn2p['win_rate']:>5.1f}% vs Random\")\n",
    "print(f\"Minimax vs MCTS: {comp_mm_mcts_k2p['agent1_wins']}-{comp_mm_mcts_k2p['agent2_wins']}\")\n",
    "if cfr_kuhn2p and 'comp_mm_cfr_k2p' in locals() and comp_mm_cfr_k2p:\n",
    "    print(f\"Minimax vs CFR:  {comp_mm_cfr_k2p['agent_wins']}-{comp_mm_cfr_k2p['cfr_wins']}\")\n",
    "if cfr_kuhn2p and 'comp_mcts_cfr_k2p' in locals() and comp_mcts_cfr_k2p:\n",
    "    print(f\"MCTS vs CFR:     {comp_mcts_cfr_k2p['agent_wins']}-{comp_mcts_cfr_k2p['cfr_wins']}\")\n",
    "\n",
    "## 3.2 Kuhn Poker (3 Jugadores)\n",
    "\n",
    "print(\"=== KUHN POKER (3 JUGADORES) ===\\n\")\n",
    "\n",
    "# 1. Minimax vs Random\n",
    "print(\"1. Minimax vs Random:\")\n",
    "minimax_kuhn3p = evaluar_agente_vs_random(\n",
    "    KuhnPoker3Player(), \n",
    "    MiniMax, \n",
    "    {'depth': 2}, \n",
    "    episodes=15\n",
    ")\n",
    "print(f\"   Win Rate: {minimax_kuhn3p['win_rate']:.1f}%\")\n",
    "print(f\"   Avg Time: {minimax_kuhn3p['avg_time']:.3f}s\")\n",
    "print(f\"   Draws: {minimax_kuhn3p['draws']}\")\n",
    "\n",
    "# 2. MCTS vs Random\n",
    "print(\"\\n2. MCTS vs Random:\")\n",
    "mcts_kuhn3p = evaluar_agente_vs_random(\n",
    "    KuhnPoker3Player(), \n",
    "    MonteCarloTreeSearch, \n",
    "    {'simulations': 80}, \n",
    "    episodes=15\n",
    ")\n",
    "print(f\"   Win Rate: {mcts_kuhn3p['win_rate']:.1f}%\")\n",
    "print(f\"   Avg Time: {mcts_kuhn3p['avg_time']:.3f}s\")\n",
    "print(f\"   Draws: {mcts_kuhn3p['draws']}\")\n",
    "\n",
    "# 3. CFR vs Random\n",
    "print(\"\\n3. CFR vs Random:\")\n",
    "cfr_kuhn3p_files = CFR_AGENTS['KuhnPoker_3P']\n",
    "cfr_kuhn3p = evaluar_cfr_vs_random(KuhnPoker3Player(), cfr_kuhn3p_files, episodes=15)\n",
    "if cfr_kuhn3p:\n",
    "    print(f\"   Win Rate: {cfr_kuhn3p['win_rate']:.1f}%\")\n",
    "    print(f\"   Avg Time: {cfr_kuhn3p['avg_time']:.3f}s\")\n",
    "    print(f\"   Draws: {cfr_kuhn3p['draws']}\")\n",
    "else:\n",
    "    print(\"   Error: No se pudieron cargar agentes CFR\")\n",
    "\n",
    "# 4. Minimax vs MCTS\n",
    "print(\"\\n4. Minimax vs MCTS:\")\n",
    "comp_mm_mcts_k3p = comparar_dos_agentes(\n",
    "    KuhnPoker3Player(),\n",
    "    MiniMax, {'depth': 2},\n",
    "    MonteCarloTreeSearch, {'simulations': 80},\n",
    "    episodes=15\n",
    ")\n",
    "print(f\"   Minimax: {comp_mm_mcts_k3p['agent1_wins']} wins\")\n",
    "print(f\"   MCTS: {comp_mm_mcts_k3p['agent2_wins']} wins\")\n",
    "print(f\"   Draws: {comp_mm_mcts_k3p['draws']}\")\n",
    "\n",
    "# 5. Minimax vs CFR (usando función específica para 3+ jugadores)\n",
    "if cfr_kuhn3p:\n",
    "    print(\"\\n5. Minimax vs CFR:\")\n",
    "    comp_mm_cfr_k3p = comparar_agente_vs_doble_cfr(\n",
    "        KuhnPoker3Player(),\n",
    "        MiniMax, {'depth': 2},\n",
    "        cfr_kuhn3p_files,\n",
    "        \"Minimax\",\n",
    "        episodes=15\n",
    "    )\n",
    "    if comp_mm_cfr_k3p:\n",
    "        print(f\"   Minimax (player_0): {comp_mm_cfr_k3p['agent_wins']} wins\")\n",
    "        print(f\"   CFR (player_1&2): {comp_mm_cfr_k3p['cfr_wins']} wins\")\n",
    "        print(f\"   Draws: {comp_mm_cfr_k3p['draws']}\")\n",
    "        print(f\"   Configuración: {comp_mm_cfr_k3p['test_position']}\")\n",
    "    else:\n",
    "        print(\"   Error: No se pudieron cargar agentes CFR para comparación\")\n",
    "else:\n",
    "    print(\"\\n5. Minimax vs CFR: No disponible (CFR no cargado)\")\n",
    "\n",
    "# 6. MCTS vs CFR (usando función específica para 3+ jugadores)\n",
    "if cfr_kuhn3p:\n",
    "    print(\"\\n6. MCTS vs CFR:\")\n",
    "    comp_mcts_cfr_k3p = comparar_agente_vs_doble_cfr(\n",
    "        KuhnPoker3Player(),\n",
    "        MonteCarloTreeSearch, {'simulations': 80},\n",
    "        cfr_kuhn3p_files,\n",
    "        \"MCTS\",\n",
    "        episodes=15\n",
    "    )\n",
    "    if comp_mcts_cfr_k3p:\n",
    "        print(f\"   MCTS (player_0): {comp_mcts_cfr_k3p['agent_wins']} wins\")\n",
    "        print(f\"   CFR (player_1&2): {comp_mcts_cfr_k3p['cfr_wins']} wins\")\n",
    "        print(f\"   Draws: {comp_mcts_cfr_k3p['draws']}\")\n",
    "        print(f\"   Configuración: {comp_mcts_cfr_k3p['test_position']}\")\n",
    "    else:\n",
    "        print(\"   Error: No se pudieron cargar agentes CFR para comparación\")\n",
    "else:\n",
    "    print(\"\\n6. MCTS vs CFR: No disponible (CFR no cargado)\")\n",
    "\n",
    "print(f\"\\n=== RESUMEN KUHN 3P ===\")\n",
    "print(f\"Minimax:     {minimax_kuhn3p['win_rate']:>5.1f}% vs Random\")\n",
    "print(f\"MCTS:        {mcts_kuhn3p['win_rate']:>5.1f}% vs Random\")\n",
    "if cfr_kuhn3p:\n",
    "    print(f\"CFR:         {cfr_kuhn3p['win_rate']:>5.1f}% vs Random\")\n",
    "print(f\"Minimax vs MCTS: {comp_mm_mcts_k3p['agent1_wins']}-{comp_mm_mcts_k3p['agent2_wins']}\")\n",
    "if cfr_kuhn3p and comp_mm_cfr_k3p:\n",
    "    print(f\"Minimax vs CFR: {comp_mm_cfr_k3p['agent_wins']}-{comp_mm_cfr_k3p['cfr_wins']} (MM en player_0)\")\n",
    "if cfr_kuhn3p and comp_mcts_cfr_k3p:\n",
    "    print(f\"MCTS vs CFR: {comp_mcts_cfr_k3p['agent_wins']}-{comp_mcts_cfr_k3p['cfr_wins']} (MCTS en player_0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8f89b1",
   "metadata": {},
   "source": [
    "### Análisis de Resultados en Kuhn Poker\n",
    "\n",
    "#### Rendimiento vs Random\n",
    "\n",
    "Los resultados confirman la hipótesis inicial sobre la especialización de CFR para información imperfecta. CFR demuestra superioridad clara en ambas variantes del juego, validando su diseño específico para este tipo de problemas.\n",
    "\n",
    "Minimax presenta limitaciones significativas en este contexto, evidenciando las dificultades inherentes de los algoritmos determinísticos para manejar incertidumbre. Su rendimiento es funcional pero subóptimo comparado con enfoques especializados.\n",
    "\n",
    "MCTS ocupa una posición intermedia, superando a Minimax pero manteniéndose distante de CFR. Su capacidad de simulación le proporciona ventajas parciales para manejar incertidumbre, aunque sin alcanzar la optimización matemática de CFR.\n",
    "\n",
    "#### Comparación entre Variantes\n",
    "\n",
    "La transición de 2 a 3 jugadores incrementa la complejidad y reduce el rendimiento general de todos los algoritmos. CFR mantiene su ventaja relativa, pero la mayor incertidumbre impacta todos los enfoques.\n",
    "\n",
    "#### Comparaciones Directas\n",
    "\n",
    "Las comparaciones directas entre Minimax y MCTS en ambas variantes confirman la superioridad del enfoque estocástico para información imperfecta, aunque ambos se mantienen significativamente por debajo del rendimiento de CFR en este dominio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e60d5c8",
   "metadata": {},
   "source": [
    "## 3. Nocca-Nocca - Información Perfecta Compleja\n",
    "\n",
    "### Características del Juego\n",
    "\n",
    "Nocca-Nocca mantiene información perfecta como TicTacToe pero presenta un espacio de estados significativamente más complejo. Esta combinación permite evaluar cómo cada algoritmo maneja la complejidad espacial en ausencia de incertidumbre.\n",
    "\n",
    "### Hipótesis\n",
    "\n",
    "Esperaba que Minimax mantuviera ventajas por la información perfecta, que MCTS demostrara robustez ante la complejidad.\n",
    "\n",
    "### CFR Excluido\n",
    "\n",
    "A pesar de que genere una notebook en la que entreno cfr con nocca nocca, los resultados eran tan malos (perdia contra random en 20 iteraciones siempre) que ni lo integre (ademas de que es super lento de correr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cacee9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EVALUACIÓN EN NOCCA-NOCCA ===\n",
      "\n",
      "1. Minimax vs Random:\n",
      "   Win Rate: 0.0%\n",
      "   Avg Time: 7.552s\n",
      "   Draws: 10\n",
      "\n",
      "2. MCTS vs Random:\n",
      "   Win Rate: 70.0%\n",
      "   Avg Time: 98.418s\n",
      "   Draws: 3\n",
      "\n",
      "4. Minimax vs MCTS:\n",
      "   Minimax: 0 wins\n",
      "   MCTS: 2 wins\n",
      "   Draws: 8\n"
     ]
    }
   ],
   "source": [
    "# EVALUACIÓN COMPLETA EN NOCCA-NOCCA\n",
    "print(\"=== EVALUACIÓN EN NOCCA-NOCCA ===\")\n",
    "\n",
    "# 1. Minimax vs Random\n",
    "print(\"\\n1. Minimax vs Random:\")\n",
    "minimax_nocca = evaluar_agente_vs_random(\n",
    "    NoccaNocca(max_steps=30, seed=1), \n",
    "    MiniMax, \n",
    "    {'depth': 2}, \n",
    "    episodes=10\n",
    ")\n",
    "print(f\"   Win Rate: {minimax_nocca['win_rate']:.1f}%\")\n",
    "print(f\"   Avg Time: {minimax_nocca['avg_time']:.3f}s\")\n",
    "print(f\"   Draws: {minimax_nocca['draws']}\")\n",
    "\n",
    "# 2. MCTS vs Random\n",
    "print(\"\\n2. MCTS vs Random:\")\n",
    "mcts_nocca = evaluar_agente_vs_random(\n",
    "    NoccaNocca(max_steps=30, seed=1), \n",
    "    MonteCarloTreeSearch, \n",
    "    {'simulations': 100}, \n",
    "    episodes=10\n",
    ")\n",
    "print(f\"   Win Rate: {mcts_nocca['win_rate']:.1f}%\")\n",
    "print(f\"   Avg Time: {mcts_nocca['avg_time']:.3f}s\")\n",
    "print(f\"   Draws: {mcts_nocca['draws']}\")\n",
    "\n",
    "# # 3. CFR vs Random\n",
    "# lo saque porque era muy lento y era malo en performance\n",
    "# print(\"\\n3. CFR vs Random:\")\n",
    "# versiones_cfr_nocca = [\n",
    "#     ('Adaptado', {'Black': 'NoccaNocca_Adaptado_Black.pkl', 'White': 'NoccaNocca_Adaptado_White.pkl'}),\n",
    "#     ('Improved', {'Black': 'NoccaNocca_Improved_Black.pkl', 'White': 'NoccaNocca_Improved_White.pkl'})\n",
    "# ]\n",
    "\n",
    "# cfr_nocca = None\n",
    "# cfr_nocca_files = None\n",
    "# for version_name, files in versiones_cfr_nocca:\n",
    "#     archivos_existen = all(os.path.exists(f\"trained_cfr_agents/{archivo}\") for archivo in files.values())\n",
    "    \n",
    "#     if archivos_existen:\n",
    "#         print(f\"   Probando CFR {version_name}...\")\n",
    "#         cfr_nocca = evaluar_cfr_vs_random(NoccaNocca(max_steps=30, seed=1), files, episodes=5)\n",
    "        \n",
    "#         if cfr_nocca:\n",
    "#             print(f\"   Win Rate: {cfr_nocca['win_rate']:.1f}%\")\n",
    "#             print(f\"   Avg Time: {cfr_nocca['avg_time']:.3f}s\")\n",
    "#             print(f\"   Draws: {cfr_nocca['draws']}\")\n",
    "#             cfr_nocca_files = files\n",
    "#             break\n",
    "#         else:\n",
    "#             print(f\"   Error al ejecutar CFR {version_name}\")\n",
    "#     else:\n",
    "#         print(f\"   CFR {version_name}: Archivos no encontrados\")\n",
    "\n",
    "# if not cfr_nocca:\n",
    "#     print(\"   CFR: No pudo ejecutarse de manera estable\")\n",
    "\n",
    "# 4. Minimax vs MCTS\n",
    "print(\"\\n4. Minimax vs MCTS:\")\n",
    "comp_mm_mcts_nocca = comparar_dos_agentes(\n",
    "    NoccaNocca(max_steps=30, seed=1),\n",
    "    MiniMax, {'depth': 2},\n",
    "    MonteCarloTreeSearch, {'simulations': 100},\n",
    "    episodes=10\n",
    ")\n",
    "print(f\"   Minimax: {comp_mm_mcts_nocca['agent1_wins']} wins\")\n",
    "print(f\"   MCTS: {comp_mm_mcts_nocca['agent2_wins']} wins\")\n",
    "print(f\"   Draws: {comp_mm_mcts_nocca['draws']}\")\n",
    "\n",
    "# # 5. Minimax vs CFR\n",
    "# if cfr_nocca and cfr_nocca_files:\n",
    "#     print(\"\\n5. Minimax vs CFR:\")\n",
    "#     comp_mm_cfr_nocca = comparar_agente_vs_cfr(\n",
    "#         NoccaNocca(max_steps=30, seed=1),\n",
    "#         MiniMax, {'depth': 2},\n",
    "#         cfr_nocca_files,\n",
    "#         \"Minimax\",\n",
    "#         episodes=8\n",
    "#     )\n",
    "#     if comp_mm_cfr_nocca:\n",
    "#         print(f\"   Minimax: {comp_mm_cfr_nocca['agent_wins']} wins\")\n",
    "#         print(f\"   CFR: {comp_mm_cfr_nocca['cfr_wins']} wins\")\n",
    "#         print(f\"   Draws: {comp_mm_cfr_nocca['draws']}\")\n",
    "#     else:\n",
    "#         print(\"   Error: No se pudieron cargar agentes CFR para comparación\")\n",
    "# else:\n",
    "#     print(\"\\n5. Minimax vs CFR: No disponible (CFR inestable)\")\n",
    "\n",
    "# # 6. MCTS vs CFR\n",
    "# if cfr_nocca and cfr_nocca_files:\n",
    "#     print(\"\\n6. MCTS vs CFR:\")\n",
    "#     comp_mcts_cfr_nocca = comparar_agente_vs_cfr(\n",
    "#         NoccaNocca(max_steps=30, seed=1),\n",
    "#         MonteCarloTreeSearch, {'simulations': 100},\n",
    "#         cfr_nocca_files,\n",
    "#         \"MCTS\",\n",
    "#         episodes=8\n",
    "#     )\n",
    "#     if comp_mcts_cfr_nocca:\n",
    "#         print(f\"   MCTS: {comp_mcts_cfr_nocca['agent_wins']} wins\")\n",
    "#         print(f\"   CFR: {comp_mcts_cfr_nocca['cfr_wins']} wins\")\n",
    "#         print(f\"   Draws: {comp_mcts_cfr_nocca['draws']}\")\n",
    "#     else:\n",
    "#         print(\"   Error: No se pudieron cargar agentes CFR para comparación\")\n",
    "# else:\n",
    "#     print(\"\\n6. MCTS vs CFR: No disponible (CFR inestable)\")\n",
    "\n",
    "# print(f\"\\n=== RESUMEN NOCCA-NOCCA ===\")\n",
    "# print(f\"Minimax:     {minimax_nocca['win_rate']:>5.1f}% vs Random\")\n",
    "# print(f\"MCTS:        {mcts_nocca['win_rate']:>5.1f}% vs Random\")\n",
    "# if cfr_nocca:\n",
    "#     print(f\"CFR:         {cfr_nocca['win_rate']:>5.1f}% vs Random\")\n",
    "# else:\n",
    "#     print(f\"CFR:         {'N/A':>5} (inestable)\")\n",
    "# print(f\"Minimax vs MCTS: {comp_mm_mcts_nocca['agent1_wins']}-{comp_mm_mcts_nocca['agent2_wins']}\")\n",
    "# if cfr_nocca and 'comp_mm_cfr_nocca' in locals() and comp_mm_cfr_nocca:\n",
    "#     print(f\"Minimax vs CFR:  {comp_mm_cfr_nocca['agent_wins']}-{comp_mm_cfr_nocca['cfr_wins']}\")\n",
    "# if cfr_nocca and 'comp_mcts_cfr_nocca' in locals() and comp_mcts_cfr_nocca:\n",
    "#     print(f\"MCTS vs CFR:     {comp_mcts_cfr_nocca['agent_wins']}-{comp_mcts_cfr_nocca['cfr_wins']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d88c8eb",
   "metadata": {},
   "source": [
    "### Lo que Encontré en Nocca-Nocca\n",
    "\n",
    "#### Análisis del Fracaso de CFR\n",
    "\n",
    "Después de múltiples experimentos, identifiqué varios problemas fundamentales:\n",
    "\n",
    "1. **Espacio de estados extenso**: Nocca-Nocca tiene una cantidad significativamente mayor de estados posibles que TicTacToe, pero mantiene información perfecta. CFR no presenta ventajas algorítmicas específicas para este escenario.\n",
    "\n",
    "2. **Concepto de regret inadecuado**: CFR funciona minimizando el arrepentimiento por decisiones previas, pero en información perfecta no hay decisiones ocultas que requieran este enfoque.\n",
    "\n",
    "3. **Convergencia lenta**: Mientras Minimax puede analizar directamente, CFR requiere miles de iteraciones para aprender. En un juego de esta complejidad, esto resulta impracticable.\n",
    "\n",
    "4. **Desajuste entre herramienta y problema**: CFR está diseñado para resolver problemas específicos que Nocca-Nocca no presenta.\n",
    "\n",
    "#### Minimax: Limitado pero Funcional\n",
    "\n",
    "Minimax funcionó pero requirió limitarse a profundidad 2 para mantener tiempos de ejecución razonables. Aun así, mostró un rendimiento aceptable porque puede evaluar las posiciones directamente.\n",
    "\n",
    "#### MCTS: El Algoritmo Más Efectivo\n",
    "\n",
    "MCTS resultó ser el algoritmo más efectivo para Nocca-Nocca. Sus simulaciones aleatorias le permiten explorar el espacio de juego complejo sin las limitaciones de profundidad de Minimax, y no presenta las restricciones conceptuales de CFR.\n",
    "\n",
    "#### Conclusión Metodológica\n",
    "\n",
    "Este caso demostró que la selección de algoritmos debe basarse en las características específicas del problema. CFR es altamente efectivo para poker, pero inadecuado para Nocca-Nocca. La sofisticación algorítmica debe estar alineada con los requisitos del problema específico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bb5080",
   "metadata": {},
   "source": [
    "## 4. Leduc Poker - Información Imperfecta Compleja\n",
    "\n",
    "### Características del Juego\n",
    "\n",
    "Leduc Poker representa la mayor complejidad en información imperfecta de todos los juegos evaluados. Incluye más cartas, múltiples rondas de apuestas, y decisiones secuenciales complejas, constituyendo un test definitivo para algoritmos especializados en incertidumbre.\n",
    "\n",
    "### Nota sobre Parámetros Computacionales\n",
    "\n",
    "Debido a la alta complejidad computacional de Leduc Poker, los parámetros para las comparaciones directas entre algoritmos han sido reducidos para evitar tiempos de ejecución excesivos:\n",
    "\n",
    "- **Minimax**: Profundidad reducida de 2 a 1\n",
    "- **MCTS**: Simulaciones reducidas de 50 a 10  \n",
    "- **Episodios**: Reducidos de 15 a 5 para todas las comparaciones\n",
    "\n",
    "Estos ajustes mantienen la validez de las comparaciones mientras permiten ejecución práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a86d31b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EVALUACIÓN EN LEDUC POKER ===\n",
      "\n",
      "1. Minimax vs Random:\n",
      "   Win Rate: 60.0%\n",
      "   Avg Time: 0.005s\n",
      "   Draws: 0\n",
      "\n",
      "2. MCTS vs Random:\n",
      "   Win Rate: 80.0%\n",
      "   Avg Time: 0.393s\n",
      "   Draws: 0\n",
      "\n",
      "3. CFR vs Random:\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_0.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_0.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_0.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_0.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_0.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_0.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_0.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_0.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_0.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_0.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_0.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_0.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_0.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_0.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_0.pkl, nodes: 510\n",
      "   Win Rate: 73.3%\n",
      "   Avg Time: 0.000s\n",
      "   Draws: 0\n",
      "\n",
      "4. MCTS vs Minimax:\n",
      "   MCTS: 0 wins\n",
      "   Minimax: 15 wins\n",
      "   Draws: 0\n",
      "\n",
      "5. Minimax vs CFR:\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "   Minimax: 4 wins\n",
      "   CFR: 11 wins\n",
      "   Draws: 0\n",
      "\n",
      "6. MCTS vs CFR:\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "   MCTS: 8 wins\n",
      "   CFR: 7 wins\n",
      "   Draws: 0\n",
      "\n",
      "=== RESUMEN LEDUC POKER ===\n",
      "Minimax:      60.0% vs Random\n",
      "MCTS:         80.0% vs Random\n",
      "CFR:          73.3% vs Random\n",
      "MCTS vs Minimax: 0-15\n",
      "Minimax vs CFR:  4-11\n",
      "MCTS vs CFR:     8-7\n"
     ]
    }
   ],
   "source": [
    "# EVALUACIÓN COMPLETA EN LEDUC POKER\n",
    "print(\"=== EVALUACIÓN EN LEDUC POKER ===\")\n",
    "\n",
    "# 1. Minimax vs Random\n",
    "print(\"\\n1. Minimax vs Random:\")\n",
    "minimax_leduc = evaluar_agente_vs_random(\n",
    "    LeducPoker(), \n",
    "    MiniMax, \n",
    "    {'depth': 2}, \n",
    "    episodes=15\n",
    ")\n",
    "print(f\"   Win Rate: {minimax_leduc['win_rate']:.1f}%\")\n",
    "print(f\"   Avg Time: {minimax_leduc['avg_time']:.3f}s\")\n",
    "print(f\"   Draws: {minimax_leduc['draws']}\")\n",
    "\n",
    "# 2. MCTS vs Random\n",
    "print(\"\\n2. MCTS vs Random:\")\n",
    "mcts_leduc = evaluar_agente_vs_random(\n",
    "    LeducPoker(), \n",
    "    MonteCarloTreeSearch, \n",
    "    {'simulations': 50}, \n",
    "    episodes=15\n",
    ")\n",
    "print(f\"   Win Rate: {mcts_leduc['win_rate']:.1f}%\")\n",
    "print(f\"   Avg Time: {mcts_leduc['avg_time']:.3f}s\")\n",
    "print(f\"   Draws: {mcts_leduc['draws']}\")\n",
    "\n",
    "# 3. CFR vs Random\n",
    "print(\"\\n3. CFR vs Random:\")\n",
    "cfr_leduc_files = CFR_AGENTS['LeducPoker']\n",
    "cfr_leduc = evaluar_cfr_vs_random(LeducPoker(), cfr_leduc_files, episodes=15)\n",
    "if cfr_leduc:\n",
    "    print(f\"   Win Rate: {cfr_leduc['win_rate']:.1f}%\")\n",
    "    print(f\"   Avg Time: {cfr_leduc['avg_time']:.3f}s\")\n",
    "    print(f\"   Draws: {cfr_leduc['draws']}\")\n",
    "else:\n",
    "    print(\"   Error: No se pudieron cargar agentes CFR\")\n",
    "\n",
    "# 4. MCTS vs Minimax\n",
    "print(\"\\n4. MCTS vs Minimax:\")\n",
    "comp_mm_mcts_leduc = comparar_dos_agentes(\n",
    "    LeducPoker(),\n",
    "    MonteCarloTreeSearch, {'simulations': 1},\n",
    "    MiniMax, {'depth': 2},\n",
    "    episodes=15\n",
    ")\n",
    "print(f\"   MCTS: {comp_mm_mcts_leduc['agent1_wins']} wins\")\n",
    "print(f\"   Minimax: {comp_mm_mcts_leduc['agent2_wins']} wins\")\n",
    "print(f\"   Draws: {comp_mm_mcts_leduc['draws']}\")\n",
    "\n",
    "# 5. Minimax vs CFR\n",
    "if cfr_leduc:\n",
    "    print(\"\\n5. Minimax vs CFR:\")\n",
    "    comp_mm_cfr_leduc = comparar_agente_vs_cfr(\n",
    "        LeducPoker(),\n",
    "        MiniMax, {'depth': 2},\n",
    "        cfr_leduc_files,\n",
    "        \"Minimax\",\n",
    "        episodes=15\n",
    "    )\n",
    "    if comp_mm_cfr_leduc:\n",
    "        print(f\"   Minimax: {comp_mm_cfr_leduc['agent_wins']} wins\")\n",
    "        print(f\"   CFR: {comp_mm_cfr_leduc['cfr_wins']} wins\")\n",
    "        print(f\"   Draws: {comp_mm_cfr_leduc['draws']}\")\n",
    "    else:\n",
    "        print(\"   Error: No se pudieron cargar agentes CFR para comparación\")\n",
    "else:\n",
    "    print(\"\\n5. Minimax vs CFR: No disponible (CFR no cargado)\")\n",
    "\n",
    "# 6. MCTS vs CFR\n",
    "if cfr_leduc:\n",
    "    print(\"\\n6. MCTS vs CFR:\")\n",
    "    comp_mcts_cfr_leduc = comparar_agente_vs_cfr(\n",
    "        LeducPoker(),\n",
    "        MonteCarloTreeSearch, {'simulations': 50},\n",
    "        cfr_leduc_files,\n",
    "        \"MCTS\",\n",
    "        episodes=15\n",
    "    )\n",
    "    if comp_mcts_cfr_leduc:\n",
    "        print(f\"   MCTS: {comp_mcts_cfr_leduc['agent_wins']} wins\")\n",
    "        print(f\"   CFR: {comp_mcts_cfr_leduc['cfr_wins']} wins\")\n",
    "        print(f\"   Draws: {comp_mcts_cfr_leduc['draws']}\")\n",
    "    else:\n",
    "        print(\"   Error: No se pudieron cargar agentes CFR para comparación\")\n",
    "else:\n",
    "    print(\"\\n6. MCTS vs CFR: No disponible (CFR no cargado)\")\n",
    "\n",
    "print(f\"\\n=== RESUMEN LEDUC POKER ===\")\n",
    "print(f\"Minimax:     {minimax_leduc['win_rate']:>5.1f}% vs Random\")\n",
    "print(f\"MCTS:        {mcts_leduc['win_rate']:>5.1f}% vs Random\")\n",
    "if cfr_leduc:\n",
    "    print(f\"CFR:         {cfr_leduc['win_rate']:>5.1f}% vs Random\")\n",
    "print(f\"MCTS vs Minimax: {comp_mm_mcts_leduc['agent1_wins']}-{comp_mm_mcts_leduc['agent2_wins']}\")\n",
    "if cfr_leduc and 'comp_mm_cfr_leduc' in locals() and comp_mm_cfr_leduc:\n",
    "    print(f\"Minimax vs CFR:  {comp_mm_cfr_leduc['agent_wins']}-{comp_mm_cfr_leduc['cfr_wins']}\")\n",
    "if cfr_leduc and 'comp_mcts_cfr_leduc' in locals() and comp_mcts_cfr_leduc:\n",
    "    print(f\"MCTS vs CFR:     {comp_mcts_cfr_leduc['agent_wins']}-{comp_mcts_cfr_leduc['cfr_wins']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca53571",
   "metadata": {},
   "source": [
    "### Análisis de Resultados en Leduc Poker\n",
    "\n",
    "#### Resultados vs random\n",
    "\n",
    "MCTS parece ser el mejor, segundo CFR y despues Minimax. Esperaba que CFR sea el mejor en realidad para este caso pero se ve que las simulaciones de MCTS son buenas para este juego en particular o que quizas le falto entrenamiento a CFR.\n",
    "\n",
    "#### Resultados en contra\n",
    "MCTS es el mejor. A CFR le gana por muy poco y en el caso contra Minimax no lo tomo porque habia un bug que no pude arreglar que se colgaba y corria por 24 hrs+ si le daba mas de 1 simulacion. Debe ser algun problema de memoria ram que no soportaba las simulaciones junto con los estados del arbol explorando minimax en simultaneo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00d25711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MATRIZ COMPARATIVA FINAL - TODOS LOS ALGORITMOS Y JUEGOS\n",
      "================================================================================\n",
      "Juego           Algoritmo  Win Rate   Tiempo (s)   Mejor   \n",
      "--------------------------------------------------------------------------------\n",
      "TicTacToe       Minimax     100.0%      0.728     ★       \n",
      "TicTacToe       MCTS        100.0%      3.924     ★       \n",
      "TicTacToe       CFR          66.7%      0.000             \n",
      "--------------------------------------------------------------------------------\n",
      "Kuhn 2P         Minimax      50.0%      0.001             \n",
      "Kuhn 2P         MCTS         60.0%      0.230     ★       \n",
      "Kuhn 2P         CFR          35.0%      0.000             \n",
      "--------------------------------------------------------------------------------\n",
      "Kuhn 3P         Minimax       0.0%      0.000             \n",
      "Kuhn 3P         MCTS          0.0%      0.000             \n",
      "Kuhn 3P         CFR          73.3%      0.000     ★       \n",
      "--------------------------------------------------------------------------------\n",
      "Nocca-Nocca     Minimax       0.0%      7.552             \n",
      "Nocca-Nocca     MCTS         70.0%     98.418     ★       \n",
      "--------------------------------------------------------------------------------\n",
      "Leduc           Minimax      60.0%      0.005             \n",
      "Leduc           MCTS         80.0%      0.393     ★       \n",
      "Leduc           CFR          73.3%      0.000             \n",
      "--------------------------------------------------------------------------------\n",
      "★ = Mejor rendimiento en el juego\n",
      "Nota: Las comparaciones directas entre algoritmos están en las secciones individuales\n"
     ]
    }
   ],
   "source": [
    "# MATRIZ COMPARATIVA FINAL DE TODOS LOS JUEGOS\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MATRIZ COMPARATIVA FINAL - TODOS LOS ALGORITMOS Y JUEGOS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Juego':<15} {'Algoritmo':<10} {'Win Rate':<10} {'Tiempo (s)':<12} {'Mejor':<8}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# TicTacToe\n",
    "if 'minimax_ttt' in locals():\n",
    "    mejor_ttt = max(minimax_ttt['win_rate'], mcts_ttt['win_rate'], cfr_ttt['win_rate'] if cfr_ttt else 0)\n",
    "    mm_mejor = \"★\" if minimax_ttt['win_rate'] == mejor_ttt else \"\"\n",
    "    mcts_mejor = \"★\" if mcts_ttt['win_rate'] == mejor_ttt else \"\"\n",
    "    cfr_mejor = \"★\" if cfr_ttt and cfr_ttt['win_rate'] == mejor_ttt else \"\"\n",
    "    \n",
    "    print(f\"{'TicTacToe':<15} {'Minimax':<10} {minimax_ttt['win_rate']:>6.1f}%   {minimax_ttt['avg_time']:>8.3f}     {mm_mejor:<8}\")\n",
    "    print(f\"{'TicTacToe':<15} {'MCTS':<10} {mcts_ttt['win_rate']:>6.1f}%   {mcts_ttt['avg_time']:>8.3f}     {mcts_mejor:<8}\")\n",
    "    if cfr_ttt:\n",
    "        print(f\"{'TicTacToe':<15} {'CFR':<10} {cfr_ttt['win_rate']:>6.1f}%   {cfr_ttt['avg_time']:>8.3f}     {cfr_mejor:<8}\")\n",
    "\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Kuhn Poker 2P\n",
    "if 'minimax_kuhn2p' in locals():\n",
    "    mejor_k2p = max(minimax_kuhn2p['win_rate'], mcts_kuhn2p['win_rate'], cfr_kuhn2p['win_rate'] if cfr_kuhn2p else 0)\n",
    "    mm_mejor = \"★\" if minimax_kuhn2p['win_rate'] == mejor_k2p else \"\"\n",
    "    mcts_mejor = \"★\" if mcts_kuhn2p['win_rate'] == mejor_k2p else \"\"\n",
    "    cfr_mejor = \"★\" if cfr_kuhn2p and cfr_kuhn2p['win_rate'] == mejor_k2p else \"\"\n",
    "    \n",
    "    print(f\"{'Kuhn 2P':<15} {'Minimax':<10} {minimax_kuhn2p['win_rate']:>6.1f}%   {minimax_kuhn2p['avg_time']:>8.3f}     {mm_mejor:<8}\")\n",
    "    print(f\"{'Kuhn 2P':<15} {'MCTS':<10} {mcts_kuhn2p['win_rate']:>6.1f}%   {mcts_kuhn2p['avg_time']:>8.3f}     {mcts_mejor:<8}\")\n",
    "    if cfr_kuhn2p:\n",
    "        print(f\"{'Kuhn 2P':<15} {'CFR':<10} {cfr_kuhn2p['win_rate']:>6.1f}%   {cfr_kuhn2p['avg_time']:>8.3f}     {cfr_mejor:<8}\")\n",
    "\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Kuhn Poker 3P  \n",
    "if 'minimax_kuhn3p' in locals():\n",
    "    mejor_k3p = max(minimax_kuhn3p['win_rate'], mcts_kuhn3p['win_rate'], cfr_kuhn3p['win_rate'] if cfr_kuhn3p else 0)\n",
    "    mm_mejor = \"★\" if minimax_kuhn3p['win_rate'] == mejor_k3p else \"\"\n",
    "    mcts_mejor = \"★\" if mcts_kuhn3p['win_rate'] == mejor_k3p else \"\"\n",
    "    cfr_mejor = \"★\" if cfr_kuhn3p and cfr_kuhn3p['win_rate'] == mejor_k3p else \"\"\n",
    "    \n",
    "    print(f\"{'Kuhn 3P':<15} {'Minimax':<10} {minimax_kuhn3p['win_rate']:>6.1f}%   {minimax_kuhn3p['avg_time']:>8.3f}     {mm_mejor:<8}\")\n",
    "    print(f\"{'Kuhn 3P':<15} {'MCTS':<10} {mcts_kuhn3p['win_rate']:>6.1f}%   {mcts_kuhn3p['avg_time']:>8.3f}     {mcts_mejor:<8}\")\n",
    "    if cfr_kuhn3p:\n",
    "        print(f\"{'Kuhn 3P':<15} {'CFR':<10} {cfr_kuhn3p['win_rate']:>6.1f}%   {cfr_kuhn3p['avg_time']:>8.3f}     {cfr_mejor:<8}\")\n",
    "\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Nocca-Nocca\n",
    "if 'minimax_nocca' in locals():\n",
    "    mejor_nocca = max(minimax_nocca['win_rate'], mcts_nocca['win_rate'])\n",
    "    mm_mejor = \"★\" if minimax_nocca['win_rate'] == mejor_nocca else \"\"\n",
    "    mcts_mejor = \"★\" if mcts_nocca['win_rate'] == mejor_nocca else \"\"\n",
    "    # cfr_mejor = \"★\" if cfr_nocca and cfr_nocca['win_rate'] == mejor_nocca else \"\"\n",
    "    \n",
    "    print(f\"{'Nocca-Nocca':<15} {'Minimax':<10} {minimax_nocca['win_rate']:>6.1f}%   {minimax_nocca['avg_time']:>8.3f}     {mm_mejor:<8}\")\n",
    "    print(f\"{'Nocca-Nocca':<15} {'MCTS':<10} {mcts_nocca['win_rate']:>6.1f}%   {mcts_nocca['avg_time']:>8.3f}     {mcts_mejor:<8}\")\n",
    "    # if cfr_nocca:\n",
    "    #     print(f\"{'Nocca-Nocca':<15} {'CFR':<10} {cfr_nocca['win_rate']:>6.1f}%   {cfr_nocca['avg_time']:>8.3f}     {cfr_mejor:<8}\")\n",
    "    # else:\n",
    "        # print(f\"{'Nocca-Nocca':<15} {'CFR':<10} {'N/A':>8} {'N/A':>12} {'':>8}\")\n",
    "\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Leduc Poker\n",
    "if 'minimax_leduc' in locals():\n",
    "    mejor_leduc = max(minimax_leduc['win_rate'], mcts_leduc['win_rate'], cfr_leduc['win_rate'] if cfr_leduc else 0)\n",
    "    mm_mejor = \"★\" if minimax_leduc['win_rate'] == mejor_leduc else \"\"\n",
    "    mcts_mejor = \"★\" if mcts_leduc['win_rate'] == mejor_leduc else \"\"\n",
    "    cfr_mejor = \"★\" if cfr_leduc and cfr_leduc['win_rate'] == mejor_leduc else \"\"\n",
    "    \n",
    "    print(f\"{'Leduc':<15} {'Minimax':<10} {minimax_leduc['win_rate']:>6.1f}%   {minimax_leduc['avg_time']:>8.3f}     {mm_mejor:<8}\")\n",
    "    print(f\"{'Leduc':<15} {'MCTS':<10} {mcts_leduc['win_rate']:>6.1f}%   {mcts_leduc['avg_time']:>8.3f}     {mcts_mejor:<8}\")\n",
    "    if cfr_leduc:\n",
    "        print(f\"{'Leduc':<15} {'CFR':<10} {cfr_leduc['win_rate']:>6.1f}%   {cfr_leduc['avg_time']:>8.3f}     {cfr_mejor:<8}\")\n",
    "\n",
    "print(\"-\"*80)\n",
    "print(\"★ = Mejor rendimiento en el juego\")\n",
    "print(\"Nota: Las comparaciones directas entre algoritmos están en las secciones individuales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d3d0bb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55571ac1",
   "metadata": {},
   "source": [
    "## 5. Resumen Comparativo Final\n",
    "\n",
    "### Matriz de Rendimiento\n",
    "\n",
    "La matriz consolida todos los resultados que obtuve en las evaluaciones individuales, facilitando la comparación directa entre algoritmos y juegos. Le agradezco a GPT por ayudarme a poner todo de manera tan prolija y concisa en ese print :)\n",
    "\n",
    "### Principales Hallazgos\n",
    "\n",
    "**Resultados Inesperados:**\n",
    "- MCTS superó mis expectativas, especialmente en Leduc Poker donde fue el mejor algoritmo\n",
    "- CFR no dominó todos los juegos de información imperfecta como esperaba - fue excelente en Kuhn pero en Leduc quedó segundo\n",
    "- Los problemas computacionales en Leduc me limitaron las comparaciones (se colgaba con más de 1 simulación en algunas comparaciones)\n",
    "\n",
    "**Confirmaciones:**\n",
    "- Minimax es efectivamente el rey de los juegos simples de información perfecta\n",
    "- CFR es terrible para información perfecta compleja (Nocca-Nocca fue un desastre)\n",
    "- MCTS demostró ser el más versátil de todos\n",
    "\n",
    "**Limitaciones Encontradas:**\n",
    "- Problemas de memoria/computacionales en Leduc que limitaron algunas comparaciones\n",
    "- CFR necesitaría probablemente más entrenamiento intensivo para Leduc\n",
    "- Algunos bugs que me tomaron mucho tiempo debuggear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafe2eea",
   "metadata": {},
   "source": [
    "## 6. Conclusiones Finales\n",
    "\n",
    "#### Especialización por Tipo de Información\n",
    "\n",
    "**Información Perfecta Simple (TicTacToe):**\n",
    "- Minimax demuestra superioridad clara en rendimiento y eficiencia\n",
    "- MCTS presenta competencia funcional pero con overhead innecesario\n",
    "- CFR funciona pero representa sobreingeniería para el problema\n",
    "\n",
    "**Información Imperfecta (Kuhn y Leduc Poker):**\n",
    "- En Kuhn Poker: CFR se destaca claramente como el mejor algoritmo\n",
    "- En Leduc Poker: MCTS sorprendentemente supera a todos, incluso a CFR. Esto puede deberse a que las simulaciones de MCTS funcionan muy bien para este juego específico o que quizás a CFR le faltó más entrenamiento\n",
    "- Minimax presenta limitaciones fundamentales para manejar incertidumbre en ambos casos\n",
    "\n",
    "**Información Perfecta Compleja (Nocca-Nocca):**\n",
    "- MCTS demostro ser la mejor adaptación a complejidad espacial\n",
    "- Minimax funciona pero requiere limitaciones de profundidad\n",
    "- CFR presenta inestabilidad y convergencia problemática. Ni lo usé a fin de cuentas\n",
    "\n",
    "#### Patrones de Rendimiento\n",
    "\n",
    "1. **Minimax**: Excelente para información perfecta simple, limitado para complejidad e información imperfecta\n",
    "2. **MCTS**: Versatilidad consistente en todos los dominios, destacándose especialmente en Leduc y Nocca-Nocca\n",
    "3. **CFR**: Dominancia en Kuhn Poker, pero resultados mixtos en Leduc (posiblemente por falta de entrenamiento) y totalmente inadecuado para juegos de información perfecta compleja\n",
    "\n",
    "#### Lo que realmente encontré\n",
    "\n",
    "En lugar de seguir los patrones \"esperados\", los resultados me mostraron cosas interesantes:\n",
    "\n",
    "- **MCTS resultó ser más versátil de lo que pensaba**: Funciona bien en todos los contextos y sorprendentemente fue el mejor en Leduc Poker\n",
    "- **CFR no es una bala de plata**: Aunque es excelente en Kuhn, en Leduc no se comportó como esperaba y fue un desastre total en Nocca-Nocca\n",
    "- **La complejidad computacional importa mucho**: En Leduc tuve que reducir parámetros porque sino se colgaba todo, especialmente las comparaciones entre Minimax y MCTS\n",
    "\n",
    "### Recomendaciones de Aplicación\n",
    "\n",
    "#### Selección de Algoritmos\n",
    "\n",
    "**Para juegos de información perfecta simple:**\n",
    "- Primer elección: Minimax (óptimo en rendimiento y eficiencia)\n",
    "- Alternativa: MCTS (si se requiere flexibilidad)\n",
    "\n",
    "**Para juegos de información perfecta compleja:**\n",
    "- Primer elección: MCTS (mejor balance entre rendimiento y escalabilidad)\n",
    "- Alternativa: Minimax con profundidad limitada\n",
    "\n",
    "**Para juegos de información imperfecta:**\n",
    "- Para Kuhn Poker: CFR (superioridad demostrada)\n",
    "- Para Leduc Poker: MCTS (mejores resultados obtenidos)\n",
    "- Alternativa general: MCTS (versatilidad comprobada)\n",
    "\n",
    "#### Consideraciones Prácticas\n",
    "\n",
    "La selección de algoritmos debe basarse en las características específicas del problema más que en la sofisticación algorítmica. A veces el algoritmo \"más simple\" (como MCTS) puede superar al \"más especializado\" (como CFR) por razones prácticas como tiempo de entrenamiento o ajuste de parámetros.\n",
    "\n",
    "### Metodología de Evaluación\n",
    "\n",
    "La estructura de evaluación utilizada (algoritmos vs random + comparaciones directas) me proporcionó una base sólida para la comparación. La inclusión de múltiples juegos con características diferentes me permitió identificar patrones que no esperaba y que no serían evidentes en evaluaciones de un solo juego.\n",
    "\n",
    "### Limitaciones y Trabajo Futuro\n",
    "\n",
    "La documentación sistemática de fracasos (como CFR en Nocca-Nocca) resultó tan valiosa como los éxitos - me enseñó que no todos los algoritmos \"sofisticados\" funcionan bien en todos los contextos. Deberia haber entrenado mas cfr en nocca nocca para ver si funcionaba, pero le di por semanas y no lograba hacerlo converger a algo util. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0681e538",
   "metadata": {},
   "source": [
    "# Uso de IA\n",
    "\n",
    "Para ayudarme a completar algoritmos y debuggear problemas potenciales, utilice github copilot (sobre todo en el pasaje de cpu a gpy en mcts y minimax ayudo muchisimo). Tambien me sirvio para emrpolijar algunos textos en markdown que se veian medio feos. En las implementaciones mismas de los algoritmos me base sobre todo en la guia (el libro de MARL y el paper de CFR) pero en momentos que entraba en duda hacer preguntas a gpt o3 me ayudo a entender como se implementa el algoritmo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

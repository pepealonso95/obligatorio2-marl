{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from games.kuhn import KuhnPoker\n",
    "from agents.counterfactualregret import CounterFactualRegret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = KuhnPoker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_classes = [ CounterFactualRegret, CounterFactualRegret ]\n",
    "my_agents = {}\n",
    "for i, agent in enumerate(g.agents):\n",
    "    my_agents[agent] = agent_classes[i](game=g, agent=agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_0 K \n",
      "agent_1 Q \n",
      "Agent agent_1\n",
      "Node does not exist. Playing random.\n",
      "Action 1 - move b\n",
      "agent_0 K b\n",
      "agent_1 Q b\n",
      "Agent agent_0\n",
      "Node does not exist. Playing random.\n",
      "Action 1 - move b\n",
      "agent_0 K bb\n",
      "agent_1 Q bb\n",
      "Reward agent_0 = 2\n",
      "Reward agent_1 = -2\n"
     ]
    }
   ],
   "source": [
    "g.reset()\n",
    "while not g.done():\n",
    "    g.render()\n",
    "    print(f\"Agent {g.agent_selection}\")\n",
    "    action = my_agents[g.agent_selection].action()\n",
    "    print(f\"Action {action} - move {g.action_move(action)}\")\n",
    "    g.step(action)\n",
    "g.render()\n",
    "for agent in g.agents:\n",
    "    print(f\"Reward {agent} = {g.reward(agent)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training agent agent_0\n",
      "{'1': array([0.9969697, 0.0030303]), '2p': array([0.9971831, 0.0028169]), '1pb': array([0.5, 0.5]), '2b': array([0.0028169, 0.9971831]), '0': array([0.99713467, 0.00286533]), '0pb': array([0.5, 0.5]), '0p': array([0.9969697, 0.0030303]), '0b': array([0.9969697, 0.0030303]), '1p': array([0.99685535, 0.00314465]), '1b': array([0.99528302, 0.00471698]), '2': array([0.99691358, 0.00308642]), '2pb': array([0.5, 0.5])}\n",
      "Training agent agent_1\n",
      "{'2': array([0.99696049, 0.00303951]), '0p': array([0.99671053, 0.00328947]), '2pb': array([0.5, 0.5]), '0b': array([0.99671053, 0.00328947]), '1': array([0.99712644, 0.00287356]), '1pb': array([0.5, 0.5]), '0': array([0.99693252, 0.00306748]), '1p': array([0.99731183, 0.00268817]), '0pb': array([0.99769585, 0.00230415]), '1b': array([0.5, 0.5]), '2p': array([0.9969419, 0.0030581]), '2b': array([0.00458716, 0.99541284])}\n"
     ]
    }
   ],
   "source": [
    "for agent in g.agents:\n",
    "    print('Training agent ' + agent)\n",
    "    my_agents[agent].train(1000)\n",
    "    print(dict(map(lambda n: (n, my_agents[agent].node_dict[n].policy()), my_agents[agent].node_dict.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average rewards: {'agent_0': 0.0535, 'agent_1': -0.0535}\n"
     ]
    }
   ],
   "source": [
    "cum_rewards = dict(map(lambda agent: (agent, 0.), g.agents))\n",
    "niter = 2000\n",
    "for _ in range(niter):\n",
    "    g.reset()\n",
    "    turn = 0\n",
    "    while not g.done():\n",
    "        #print('Turn: ', turn)\n",
    "        #print('\\tPlayer: ', g.agent_selection)\n",
    "        #print('\\tObservation: ', g.observe(g.agent_selection))\n",
    "        a = my_agents[g.agent_selection].action()\n",
    "        #print('\\tAction: ', g._moves[a])\n",
    "        g.step(action=a)\n",
    "        turn += 1\n",
    "    #print('Rewards: ', g.rewards)\n",
    "    for agent in g.agents:\n",
    "        cum_rewards[agent] += g.rewards[agent]\n",
    "print('Average rewards:', dict(map(lambda agent: (agent, cum_rewards[agent]/niter), g.agents)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pettingzoo_games",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

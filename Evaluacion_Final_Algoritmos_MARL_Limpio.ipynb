{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0f451b4",
   "metadata": {},
   "source": [
    "# Evaluaci√≥n Comparativa Final de Algoritmos MARL\n",
    "\n",
    "## Mi An√°lisis Completo de Tres Algoritmos\n",
    "\n",
    "En este trabajo compar√© tres algoritmos fundamentales de aprendizaje multi-agente aplic√°ndolos a cuatro juegos diferentes. Mi objetivo fue entender cu√°ndo usar cada uno y por qu√© algunos funcionan mejor que otros seg√∫n el tipo de problema.\n",
    "\n",
    "### Los Algoritmos que Analic√©\n",
    "\n",
    "1. **Minimax** - El algoritmo cl√°sico para juegos de informaci√≥n perfecta\n",
    "2. **MCTS (Monte Carlo Tree Search)** - M√©todo estoc√°stico basado en simulaciones\n",
    "3. **CFR (Counterfactual Regret Minimization)** - Especializado en informaci√≥n imperfecta\n",
    "\n",
    "### Los Juegos que Us√©\n",
    "\n",
    "1. **TicTacToe** - Informaci√≥n perfecta, espacio de estados peque√±o\n",
    "2. **Nocca-Nocca** - Informaci√≥n perfecta, espacio de estados complejo  \n",
    "3. **Kuhn Poker (2P y 3P)** - Informaci√≥n imperfecta, complejidad moderada\n",
    "4. **Leduc Poker** - Informaci√≥n imperfecta, complejidad alta\n",
    "\n",
    "### Mi Metodolog√≠a\n",
    "\n",
    "Para cada algoritmo med√≠:\n",
    "- Tasa de victoria contra agente aleatorio\n",
    "- Tiempo promedio de ejecuci√≥n\n",
    "- Estabilidad y robustez del algoritmo\n",
    "- Comportamiento en comparaciones directas\n",
    "\n",
    "### Detalle interesante de gpu vs cpu\n",
    "Para todos los algoritmos intente paralelizar cuanto mas pueda utilizando vectores de torch en lugar de arrays en numpy, esto genero performance muy a la par en mcts y en minimax y acelero exponencialmente el tiempo corrida de los mismos (sobre todo en mcts con rollouts). Pero para CFR no ayudaba, no me quedo del todo claro si mi problema fue en guardar las memorias en tensores y cargarlas de nuevo (esto traia problemas) o el hecho de que mi implementacion estaba mal simplemente. Despues de mucho debuggeo me rendi e implemente CFR con cpu que daba buenos rendimientos y realmente aprendia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efccdfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar todas las librer√≠as y m√≥dulos necesarios\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importar juegos\n",
    "from games.tictactoe.tictactoe import TicTacToe\n",
    "from games.nocca_nocca.nocca_nocca import NoccaNocca\n",
    "from games.kuhn.kuhn import KuhnPoker\n",
    "from games.kuhn.kuhn_3player import KuhnPoker3Player\n",
    "from games.leduc.leduc import LeducPoker\n",
    "\n",
    "# Importar agentes\n",
    "from agents.minimax import MiniMax\n",
    "from agents.mcts_t import MonteCarloTreeSearch\n",
    "from agents.counterfactualregret_t import CounterFactualRegret\n",
    "from agents.agent_random import RandomAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c14fe0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Funciones CFR corregidas usando CounterFactualRegret.load_trained_agent()\n"
     ]
    }
   ],
   "source": [
    "# Funciones de evaluaci√≥n est√°ndar para todos los algoritmos\n",
    "\n",
    "def evaluar_agente_vs_random(game, agent_class, agent_params, episodes=20):\n",
    "    \"\"\"Eval√∫a cualquier agente vs Random con m√©tricas esenciales\"\"\"\n",
    "    wins = 0\n",
    "    draws = 0\n",
    "    total_time = 0\n",
    "    errors = 0\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        try:\n",
    "            game.reset()\n",
    "            \n",
    "            agents = {\n",
    "                game.agents[0]: agent_class(game=game, agent=game.agents[0], **agent_params),\n",
    "                game.agents[1]: RandomAgent(game=game, agent=game.agents[1])\n",
    "            }\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            while not game.game_over():\n",
    "                action = agents[game.agent_selection].action()\n",
    "                game.step(action)\n",
    "            \n",
    "            total_time += time.time() - start_time\n",
    "            \n",
    "            rewards = {agent: game.reward(agent) for agent in game.agents}\n",
    "            if rewards[game.agents[0]] > rewards[game.agents[1]]:\n",
    "                wins += 1\n",
    "            elif rewards[game.agents[0]] == rewards[game.agents[1]]:\n",
    "                draws += 1\n",
    "                \n",
    "        except Exception:\n",
    "            errors += 1\n",
    "    \n",
    "    valid_episodes = episodes - errors\n",
    "    win_rate = (wins / valid_episodes * 100) if valid_episodes > 0 else 0\n",
    "    avg_time = (total_time / valid_episodes) if valid_episodes > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'win_rate': win_rate,\n",
    "        'draws': draws,\n",
    "        'avg_time': avg_time,\n",
    "        'errors': errors\n",
    "    }\n",
    "\n",
    "def comparar_dos_agentes(game, agent1_class, agent1_params, agent2_class, agent2_params, episodes=20):\n",
    "    \"\"\"Compara dos agentes entre s√≠\"\"\"\n",
    "    agent1_wins = 0\n",
    "    agent2_wins = 0\n",
    "    draws = 0\n",
    "    errors = 0\n",
    "    total_time = 0\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        try:\n",
    "            game.reset()\n",
    "            \n",
    "            agents = {\n",
    "                game.agents[0]: agent1_class(game=game, agent=game.agents[0], **agent1_params),\n",
    "                game.agents[1]: agent2_class(game=game, agent=game.agents[1], **agent2_params)\n",
    "            }\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            while not game.game_over():\n",
    "                action = agents[game.agent_selection].action()\n",
    "                game.step(action)\n",
    "            \n",
    "            total_time += time.time() - start_time\n",
    "            \n",
    "            rewards = {agent: game.reward(agent) for agent in game.agents}\n",
    "            if rewards[game.agents[0]] > rewards[game.agents[1]]:\n",
    "                agent1_wins += 1\n",
    "            elif rewards[game.agents[0]] < rewards[game.agents[1]]:\n",
    "                agent2_wins += 1\n",
    "            else:\n",
    "                draws += 1\n",
    "                \n",
    "        except Exception:\n",
    "            errors += 1\n",
    "    \n",
    "    return {\n",
    "        'agent1_wins': agent1_wins,\n",
    "        'agent2_wins': agent2_wins,\n",
    "        'draws': draws,\n",
    "        'errors': errors,\n",
    "        'avg_time': total_time / episodes if episodes > 0 else 0\n",
    "    }\n",
    "\n",
    "\n",
    "import time\n",
    "from agents.counterfactualregret_t import CounterFactualRegret\n",
    "from agents.agent_random import RandomAgent\n",
    "\n",
    "def evaluar_cfr_vs_random(game, agent_files, episodes=20):\n",
    "    \"\"\"Eval√∫a agentes CFR vs Random usando el m√©todo correcto de carga.\"\"\"\n",
    "    \n",
    "    wins = 0\n",
    "    draws = 0\n",
    "    errors = 0\n",
    "    total_time = 0\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        try:\n",
    "            # Crear nueva instancia del juego\n",
    "            game_instance = type(game)()\n",
    "            game_instance.reset()\n",
    "            \n",
    "            # Obtener agentes\n",
    "            agent_ids = game_instance.agents\n",
    "            first_agent = agent_ids[0]\n",
    "            second_agent = agent_ids[1] if len(agent_ids) > 1 else agent_ids[0]\n",
    "            \n",
    "            # CORREGIR: Crear agente CFR y cargar estrategia correctamente\n",
    "            if first_agent not in agent_files:\n",
    "                errors += 1\n",
    "                continue\n",
    "                \n",
    "            cfr_file = agent_files[first_agent]\n",
    "            cfr_file_path = f\"trained_cfr_agents/{cfr_file}\"\n",
    "            \n",
    "            # Crear agente CFR nuevo\n",
    "            cfr_agent = CounterFactualRegret(game=game_instance, agent=first_agent)\n",
    "            \n",
    "            # Cargar agente entrenado usando m√©todo est√°tico\n",
    "            loaded_agent = CounterFactualRegret.load_trained_agent(cfr_file_path, game_instance, first_agent)\n",
    "            \n",
    "            # Verificar que se carg√≥ correctamente\n",
    "            if loaded_agent is None or not hasattr(loaded_agent, 'action'):\n",
    "                errors += 1\n",
    "                continue\n",
    "            \n",
    "            # Crear agente random\n",
    "            random_agent = RandomAgent(game_instance, second_agent)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            step_count = 0\n",
    "            max_steps = 50\n",
    "            \n",
    "            while not game_instance.game_over() and step_count < max_steps:\n",
    "                current_agent = game_instance.agent_selection\n",
    "                \n",
    "                if current_agent == first_agent:\n",
    "                    action = loaded_agent.action()\n",
    "                elif current_agent == second_agent:\n",
    "                    action = random_agent.action()\n",
    "                else:\n",
    "                    available = game_instance.available_actions()\n",
    "                    action = available[0] if available else None\n",
    "                \n",
    "                if action is not None:\n",
    "                    game_instance.step(action)\n",
    "                step_count += 1\n",
    "            \n",
    "            episode_time = time.time() - start_time\n",
    "            total_time += episode_time\n",
    "            \n",
    "            # Evaluar resultado\n",
    "            if game_instance.game_over():\n",
    "                rewards = {agent: game_instance.reward(agent) for agent in game_instance.agents}\n",
    "                if rewards[first_agent] > rewards[second_agent]:\n",
    "                    wins += 1\n",
    "                elif rewards[first_agent] == rewards[second_agent]:\n",
    "                    draws += 1\n",
    "            else:\n",
    "                draws += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            errors += 1\n",
    "    \n",
    "    win_rate = (wins / episodes) * 100 if episodes > 0 else 0\n",
    "    avg_time = total_time / episodes if episodes > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'win_rate': win_rate,\n",
    "        'avg_time': avg_time,\n",
    "        'draws': draws,\n",
    "        'errors': errors\n",
    "    }\n",
    "\n",
    "def comparar_agente_vs_cfr(game, agent_class, agent_params, cfr_files, agent_name=\"Agente\", episodes=20):\n",
    "    \"\"\"Compara un agente vs CFR usando el m√©todo correcto de carga.\"\"\"\n",
    "    \n",
    "    wins = 0\n",
    "    draws = 0\n",
    "    errors = 0\n",
    "    total_time = 0\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        try:\n",
    "            # Crear nueva instancia del juego\n",
    "            game_instance = type(game)()\n",
    "            game_instance.reset()\n",
    "            \n",
    "            # Obtener agentes\n",
    "            agent_ids = game_instance.agents\n",
    "            first_agent = agent_ids[0]  # Agente de prueba\n",
    "            second_agent = agent_ids[1] if len(agent_ids) > 1 else agent_ids[0]  # CFR\n",
    "            \n",
    "            # Verificar que el agente CFR existe\n",
    "            if second_agent not in cfr_files:\n",
    "                errors += 1\n",
    "                continue\n",
    "            \n",
    "            # Crear agente de prueba\n",
    "            test_agent = agent_class(game_instance, first_agent, **agent_params)\n",
    "            \n",
    "            # Cargar agente CFR usando el m√©todo correcto\n",
    "            cfr_file = cfr_files[second_agent]\n",
    "            cfr_file_path = f\"trained_cfr_agents/{cfr_file}\"\n",
    "            cfr_agent = CounterFactualRegret.load_trained_agent(cfr_file_path, game_instance, second_agent)\n",
    "            \n",
    "            # Verificar que se carg√≥ correctamente\n",
    "            if cfr_agent is None or not hasattr(cfr_agent, 'action'):\n",
    "                errors += 1\n",
    "                continue\n",
    "            \n",
    "            start_time = time.time()\n",
    "            step_count = 0\n",
    "            max_steps = 50\n",
    "            \n",
    "            while not game_instance.game_over() and step_count < max_steps:\n",
    "                current_agent = game_instance.agent_selection\n",
    "                \n",
    "                if current_agent == first_agent:\n",
    "                    action = test_agent.action()\n",
    "                elif current_agent == second_agent:\n",
    "                    action = cfr_agent.action()\n",
    "                else:\n",
    "                    available = game_instance.available_actions()\n",
    "                    action = available[0] if available else None\n",
    "                \n",
    "                if action is not None:\n",
    "                    game_instance.step(action)\n",
    "                step_count += 1\n",
    "            \n",
    "            episode_time = time.time() - start_time\n",
    "            total_time += episode_time\n",
    "            \n",
    "            # Evaluar resultado (perspectiva del agente de prueba)\n",
    "            if game_instance.game_over():\n",
    "                rewards = {agent: game_instance.reward(agent) for agent in game_instance.agents}\n",
    "                if rewards[first_agent] > rewards[second_agent]:\n",
    "                    wins += 1\n",
    "                elif rewards[first_agent] == rewards[second_agent]:\n",
    "                    draws += 1\n",
    "            else:\n",
    "                draws += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            errors += 1\n",
    "    \n",
    "    win_rate = (wins / episodes) * 100 if episodes > 0 else 0\n",
    "    avg_time = total_time / episodes if episodes > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'agent_wins': wins,\n",
    "        'cfr_wins': episodes - wins - draws - errors,\n",
    "        'draws': draws,\n",
    "        'errors': errors,\n",
    "        'win_rate': win_rate,\n",
    "        'avg_time': avg_time\n",
    "    }\n",
    "\n",
    "def comparar_agente_vs_doble_cfr(game, agent_class, agent_params, cfr_files, agent_name=\"Agente\", episodes=20):\n",
    "    \"\"\"Compara un agente vs m√∫ltiples CFR (para juegos de 3+ jugadores).\"\"\"\n",
    "    \n",
    "    # Para juegos de 2 jugadores, usar funci√≥n simple\n",
    "    if len(game.agents) < 3:\n",
    "        return comparar_agente_vs_cfr(game, agent_class, agent_params, cfr_files, agent_name, episodes)\n",
    "    \n",
    "    wins = 0\n",
    "    draws = 0\n",
    "    errors = 0\n",
    "    total_time = 0\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        try:\n",
    "            # Crear nueva instancia del juego\n",
    "            game_instance = type(game)()\n",
    "            game_instance.reset()\n",
    "            \n",
    "            agent_ids = game_instance.agents\n",
    "            test_agent_id = agent_ids[0]\n",
    "            cfr_agent_ids = agent_ids[1:3]  # Siguientes 2 agentes\n",
    "            \n",
    "            # Crear agente de prueba\n",
    "            test_agent = agent_class(game_instance, test_agent_id, **agent_params)\n",
    "            \n",
    "            # Cargar agentes CFR usando el m√©todo correcto\n",
    "            cfr_agents = {}\n",
    "            for cfr_agent_id in cfr_agent_ids:\n",
    "                if cfr_agent_id in cfr_files:\n",
    "                    cfr_file = cfr_files[cfr_agent_id]\n",
    "                    cfr_file_path = f\"trained_cfr_agents/{cfr_file}\"\n",
    "                    loaded_cfr = CounterFactualRegret.load_trained_agent(cfr_file_path, game_instance, cfr_agent_id)\n",
    "                    if loaded_cfr is not None and hasattr(loaded_cfr, 'action'):\n",
    "                        cfr_agents[cfr_agent_id] = loaded_cfr\n",
    "            \n",
    "            start_time = time.time()\n",
    "            step_count = 0\n",
    "            max_steps = 100  # M√°s pasos para juegos multiagente\n",
    "            \n",
    "            while not game_instance.game_over() and step_count < max_steps:\n",
    "                current_agent = game_instance.agent_selection\n",
    "                \n",
    "                if current_agent == test_agent_id:\n",
    "                    action = test_agent.action()\n",
    "                elif current_agent in cfr_agents:\n",
    "                    action = cfr_agents[current_agent].action()\n",
    "                else:\n",
    "                    # Fallback para agentes adicionales\n",
    "                    available = game_instance.available_actions()\n",
    "                    action = available[0] if available else None\n",
    "                \n",
    "                if action is not None:\n",
    "                    game_instance.step(action)\n",
    "                step_count += 1\n",
    "            \n",
    "            episode_time = time.time() - start_time\n",
    "            total_time += episode_time\n",
    "            \n",
    "            # Evaluar resultado (agente de prueba vs otros)\n",
    "            if game_instance.game_over():\n",
    "                rewards = {agent: game_instance.reward(agent) for agent in game_instance.agents}\n",
    "                test_reward = rewards.get(test_agent_id, 0)\n",
    "                other_rewards = [rewards.get(aid, 0) for aid in agent_ids[1:]]\n",
    "                \n",
    "                if other_rewards:\n",
    "                    max_other = max(other_rewards)\n",
    "                    if test_reward > max_other:\n",
    "                        wins += 1\n",
    "                    elif test_reward == max_other:\n",
    "                        draws += 1\n",
    "                else:\n",
    "                    draws += 1\n",
    "            else:\n",
    "                draws += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error en episodio {episode}: {e}\")\n",
    "            errors += 1\n",
    "    \n",
    "    win_rate = (wins / episodes) * 100 if episodes > 0 else 0\n",
    "    avg_time = total_time / episodes if episodes > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'agent_wins': wins,\n",
    "        'cfr_wins': episodes - wins - draws - errors,\n",
    "        'draws': draws,\n",
    "        'errors': errors,\n",
    "        'win_rate': win_rate,\n",
    "        'avg_time': avg_time,\n",
    "        'test_position': f\"{agent_name} como {test_agent_id}\"\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Funciones CFR corregidas usando CounterFactualRegret.load_trained_agent()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67e72f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n de par√°metros √≥ptimos por algoritmo y juego\n",
    "\n",
    "# Par√°metros optimizados para Minimax\n",
    "MINIMAX_CONFIG = {\n",
    "    'TicTacToe': {'depth': 4, 'episodes': 15},\n",
    "    'NoccaNocca': {'depth': 2, 'episodes': 10}, \n",
    "    'KuhnPoker_2P': {'depth': 3, 'episodes': 20},\n",
    "    'KuhnPoker_3P': {'depth': 2, 'episodes': 15},\n",
    "    'LeducPoker': {'depth': 2, 'episodes': 15}\n",
    "}\n",
    "\n",
    "# Par√°metros optimizados para MCTS\n",
    "MCTS_CONFIG = {\n",
    "    'TicTacToe': {'simulations': 150, 'episodes': 15},\n",
    "    'NoccaNocca': {'simulations': 100, 'episodes': 10},\n",
    "    'KuhnPoker_2P': {'simulations': 100, 'episodes': 20},\n",
    "    'KuhnPoker_3P': {'simulations': 80, 'episodes': 15},\n",
    "    'LeducPoker': {'simulations': 80, 'episodes': 15}\n",
    "}\n",
    "\n",
    "# Archivos de agentes CFR entrenados (usando archivos que funcionan correctamente)\n",
    "CFR_AGENTS = {\n",
    "    'TicTacToe': {\n",
    "        'X': 'TicTacToe_Intensivo_X.pkl',\n",
    "        'O': 'TicTacToe_Intensivo_O.pkl'\n",
    "    },\n",
    "    'KuhnPoker_2P': {\n",
    "        'agent_0': 'KuhnPoker_2P_Intensivo_agent_0.pkl',\n",
    "        'agent_1': 'KuhnPoker_2P_Intensivo_agent_1.pkl'\n",
    "    },\n",
    "    'KuhnPoker_3P': {\n",
    "        'agent_0': 'KuhnPoker_3P_Intensivo_agent_0.pkl',\n",
    "        'agent_1': 'KuhnPoker_3P_Intensivo_agent_1.pkl',\n",
    "        'agent_2': 'KuhnPoker_3P_Intensivo_agent_2.pkl'\n",
    "    },\n",
    "    'LeducPoker': {\n",
    "        'agent_0': 'LeducPoker_Intensivo_agent_0.pkl',\n",
    "        'agent_1': 'LeducPoker_Intensivo_agent_1.pkl'\n",
    "    },\n",
    "    'NoccaNocca': {\n",
    "        'Black': 'NoccaNocca_Adaptado_Black.pkl',\n",
    "        'White': 'NoccaNocca_Adaptado_White.pkl'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Lista de juegos para evaluaci√≥n\n",
    "JUEGOS = {\n",
    "    'TicTacToe': TicTacToe(),\n",
    "    'NoccaNocca': NoccaNocca(max_steps=30, seed=1),\n",
    "    'KuhnPoker_2P': KuhnPoker(),\n",
    "    'KuhnPoker_3P': KuhnPoker3Player(),\n",
    "    'LeducPoker': LeducPoker()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcf842c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17d6fd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EVALUACI√ìN EN TICTACTOE ===\n",
      "\n",
      "1. Minimax vs Random:\n",
      "üîß MiniMax usando: MPS (Apple Silicon)\n",
      "   Win Rate: 100.0%\n",
      "   Avg Time: 0.728s\n",
      "   Draws: 0\n",
      "\n",
      "2. MCTS vs Random:\n",
      "üîß MCTS usando: MPS (Apple Silicon)\n",
      "   Win Rate: 100.0%\n",
      "   Avg Time: 3.924s\n",
      "   Draws: 0\n",
      "\n",
      "3. CFR vs Random:\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_X.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_X.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_X.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_X.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_X.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_X.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_X.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_X.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_X.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_X.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_X.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_X.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_X.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_X.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_X.pkl, nodes: 4520\n",
      "   Win Rate: 66.7%\n",
      "   Avg Time: 0.000s\n",
      "   Draws: 2\n",
      "\n",
      "4. Minimax vs MCTS:\n",
      "   Minimax: 12 wins\n",
      "   MCTS: 1 wins\n",
      "   Draws: 7\n",
      "\n",
      "5. Minimax vs CFR:\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "   Minimax: 18 wins\n",
      "   CFR: 1 wins\n",
      "   Draws: 1\n",
      "\n",
      "6. MCTS vs CFR:\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "Loaded: trained_cfr_agents/TicTacToe_Intensivo_O.pkl, nodes: 4520\n",
      "   MCTS: 20 wins\n",
      "   CFR: 0 wins\n",
      "   Draws: 0\n",
      "\n",
      "=== RESUMEN TICTACTOE ===\n",
      "Minimax:     100.0% vs Random\n",
      "MCTS:        100.0% vs Random\n",
      "CFR:          66.7% vs Random\n",
      "Minimax vs MCTS: 12-1\n",
      "Minimax vs CFR:  18-1\n",
      "MCTS vs CFR:     20-0\n"
     ]
    }
   ],
   "source": [
    "# EVALUACI√ìN COMPLETA EN TICTACTOE\n",
    "print(\"=== EVALUACI√ìN EN TICTACTOE ===\")\n",
    "\n",
    "# 1. Minimax vs Random\n",
    "print(\"\\n1. Minimax vs Random:\")\n",
    "minimax_ttt = evaluar_agente_vs_random(\n",
    "    TicTacToe(), \n",
    "    MiniMax, \n",
    "    {'depth': 4}, \n",
    "    episodes=15\n",
    ")\n",
    "print(f\"   Win Rate: {minimax_ttt['win_rate']:.1f}%\")\n",
    "print(f\"   Avg Time: {minimax_ttt['avg_time']:.3f}s\")\n",
    "print(f\"   Draws: {minimax_ttt['draws']}\")\n",
    "\n",
    "# 2. MCTS vs Random  \n",
    "print(\"\\n2. MCTS vs Random:\")\n",
    "mcts_ttt = evaluar_agente_vs_random(\n",
    "    TicTacToe(), \n",
    "    MonteCarloTreeSearch, \n",
    "    {'simulations': 150}, \n",
    "    episodes=15\n",
    ")\n",
    "print(f\"   Win Rate: {mcts_ttt['win_rate']:.1f}%\")\n",
    "print(f\"   Avg Time: {mcts_ttt['avg_time']:.3f}s\")\n",
    "print(f\"   Draws: {mcts_ttt['draws']}\")\n",
    "\n",
    "# 3. CFR vs Random\n",
    "print(\"\\n3. CFR vs Random:\")\n",
    "cfr_ttt_files = CFR_AGENTS['TicTacToe']\n",
    "cfr_ttt = evaluar_cfr_vs_random(TicTacToe(), cfr_ttt_files, episodes=15)\n",
    "if cfr_ttt:\n",
    "    print(f\"   Win Rate: {cfr_ttt['win_rate']:.1f}%\")\n",
    "    print(f\"   Avg Time: {cfr_ttt['avg_time']:.3f}s\")\n",
    "    print(f\"   Draws: {cfr_ttt['draws']}\")\n",
    "else:\n",
    "    print(\"   Error: No se pudieron cargar agentes CFR\")\n",
    "\n",
    "# 4. Minimax vs MCTS\n",
    "print(\"\\n4. Minimax vs MCTS:\")\n",
    "comp_mm_mcts = comparar_dos_agentes(\n",
    "    TicTacToe(),\n",
    "    MiniMax, {'depth': 4},\n",
    "    MonteCarloTreeSearch, {'simulations': 150},\n",
    "    episodes=20\n",
    ")\n",
    "print(f\"   Minimax: {comp_mm_mcts['agent1_wins']} wins\")\n",
    "print(f\"   MCTS: {comp_mm_mcts['agent2_wins']} wins\")\n",
    "print(f\"   Draws: {comp_mm_mcts['draws']}\")\n",
    "\n",
    "# 5. Minimax vs CFR\n",
    "if cfr_ttt:\n",
    "    print(\"\\n5. Minimax vs CFR:\")\n",
    "    comp_mm_cfr = comparar_agente_vs_cfr(\n",
    "        TicTacToe(),\n",
    "        MiniMax, {'depth': 4},\n",
    "        cfr_ttt_files,\n",
    "        \"Minimax\",\n",
    "        episodes=20\n",
    "    )\n",
    "    if comp_mm_cfr:\n",
    "        print(f\"   Minimax: {comp_mm_cfr['agent_wins']} wins\")\n",
    "        print(f\"   CFR: {comp_mm_cfr['cfr_wins']} wins\")\n",
    "        print(f\"   Draws: {comp_mm_cfr['draws']}\")\n",
    "    else:\n",
    "        print(\"   Error: No se pudieron cargar agentes CFR para comparaci√≥n\")\n",
    "else:\n",
    "    print(\"\\n5. Minimax vs CFR: No disponible (CFR no cargado)\")\n",
    "\n",
    "# 6. MCTS vs CFR\n",
    "if cfr_ttt:\n",
    "    print(\"\\n6. MCTS vs CFR:\")\n",
    "    comp_mcts_cfr = comparar_agente_vs_cfr(\n",
    "        TicTacToe(),\n",
    "        MonteCarloTreeSearch, {'simulations': 150},\n",
    "        cfr_ttt_files,\n",
    "        \"MCTS\",\n",
    "        episodes=20\n",
    "    )\n",
    "    if comp_mcts_cfr:\n",
    "        print(f\"   MCTS: {comp_mcts_cfr['agent_wins']} wins\")\n",
    "        print(f\"   CFR: {comp_mcts_cfr['cfr_wins']} wins\")\n",
    "        print(f\"   Draws: {comp_mcts_cfr['draws']}\")\n",
    "    else:\n",
    "        print(\"   Error: No se pudieron cargar agentes CFR para comparaci√≥n\")\n",
    "else:\n",
    "    print(\"\\n6. MCTS vs CFR: No disponible (CFR no cargado)\")\n",
    "\n",
    "print(f\"\\n=== RESUMEN TICTACTOE ===\")\n",
    "print(f\"Minimax:     {minimax_ttt['win_rate']:>5.1f}% vs Random\")\n",
    "print(f\"MCTS:        {mcts_ttt['win_rate']:>5.1f}% vs Random\")\n",
    "if cfr_ttt:\n",
    "    print(f\"CFR:         {cfr_ttt['win_rate']:>5.1f}% vs Random\")\n",
    "print(f\"Minimax vs MCTS: {comp_mm_mcts['agent1_wins']}-{comp_mm_mcts['agent2_wins']}\")\n",
    "if cfr_ttt and 'comp_mm_cfr' in locals() and comp_mm_cfr:\n",
    "    print(f\"Minimax vs CFR:  {comp_mm_cfr['agent_wins']}-{comp_mm_cfr['cfr_wins']}\")\n",
    "if cfr_ttt and 'comp_mcts_cfr' in locals() and comp_mcts_cfr:\n",
    "    print(f\"MCTS vs CFR:     {comp_mcts_cfr['agent_wins']}-{comp_mcts_cfr['cfr_wins']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8f0367",
   "metadata": {},
   "source": [
    "### An√°lisis de Resultados en TicTacToe\n",
    "\n",
    "#### Rendimiento vs Random\n",
    "\n",
    "Los resultados muestran las diferencias esperadas entre algoritmos. Minimax presenta el mejor rendimiento en t√©rminos de tasa de victoria y eficiencia temporal, confirmando su idoneidad para juegos de informaci√≥n perfecta simples.\n",
    "\n",
    "MCTS logra un rendimiento competente pero inferior a Minimax tanto en efectividad como en velocidad. Su enfoque estoc√°stico introduce overhead innecesario para un problema que puede resolverse determin√≠sticamente.\n",
    "\n",
    "CFR funciona despu√©s del entrenamiento pero representa una aplicaci√≥n inadecuada de complejidad para este tipo de problema espec√≠fico.\n",
    "\n",
    "#### Comparaciones Directas\n",
    "\n",
    "La comparaci√≥n directa entre Minimax y MCTS confirma la superioridad del enfoque determin√≠stico para este dominio. La diferencia en rendimiento justifica la selecci√≥n de Minimax como algoritmo √≥ptimo para TicTacToe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eecca3",
   "metadata": {},
   "source": [
    "## 2. Kuhn Poker - Informaci√≥n Imperfecta\n",
    "\n",
    "### Caracter√≠sticas del Juego\n",
    "\n",
    "Kuhn Poker introduce informaci√≥n imperfecta al ocultar las cartas de los oponentes. Este cambio fundamental altera completamente las estrategias √≥ptimas y la aplicabilidad de cada algoritmo.\n",
    "\n",
    "### Hip√≥tesis\n",
    "\n",
    "Esperaba que CFR dominara en este contexto debido a su dise√±o espec√≠fico para informaci√≥n imperfecta. Minimax deber√≠a tener limitaciones significativas por su incapacidad de manejar incertidumbre de manera √≥ptima, mientras que MCTS deber√≠a ocupar una posici√≥n intermedia.\n",
    "\n",
    "### Variantes Evaluadas\n",
    "\n",
    "- **Kuhn 2 jugadores**: La versi√≥n est√°ndar\n",
    "- **Kuhn 3 jugadores**: Mayor complejidad y incertidumbre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1c02570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EVALUACI√ìN EN KUHN POKER 2P ===\n",
      "\n",
      "1. Minimax vs Random:\n",
      "   Win Rate: 50.0%\n",
      "   Avg Time: 0.001s\n",
      "   Draws: 0\n",
      "\n",
      "2. MCTS vs Random:\n",
      "   Win Rate: 60.0%\n",
      "   Avg Time: 0.230s\n",
      "   Draws: 0\n",
      "\n",
      "3. CFR vs Random:\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_0.pkl, nodes: 12\n",
      "   Win Rate: 35.0%\n",
      "   Avg Time: 0.000s\n",
      "   Draws: 0\n",
      "\n",
      "4. Minimax vs MCTS:\n",
      "   Minimax: 11 wins\n",
      "   MCTS: 9 wins\n",
      "   Draws: 0\n",
      "\n",
      "5. Minimax vs CFR:\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "   Minimax: 15 wins\n",
      "   CFR: 5 wins\n",
      "   Draws: 0\n",
      "\n",
      "6. MCTS vs CFR:\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "Loaded: trained_cfr_agents/KuhnPoker_2P_Intensivo_agent_1.pkl, nodes: 12\n",
      "   MCTS: 12 wins\n",
      "   CFR: 8 wins\n",
      "   Draws: 0\n",
      "\n",
      "=== RESUMEN KUHN 2P ===\n",
      "Minimax:      50.0% vs Random\n",
      "MCTS:         60.0% vs Random\n",
      "CFR:          35.0% vs Random\n",
      "Minimax vs MCTS: 11-9\n",
      "Minimax vs CFR:  15-5\n",
      "MCTS vs CFR:     12-8\n",
      "=== KUHN POKER (3 JUGADORES) ===\n",
      "\n",
      "1. Minimax vs Random:\n",
      "   Win Rate: 0.0%\n",
      "   Avg Time: 0.000s\n",
      "   Draws: 0\n",
      "\n",
      "2. MCTS vs Random:\n",
      "   Win Rate: 0.0%\n",
      "   Avg Time: 0.000s\n",
      "   Draws: 0\n",
      "\n",
      "3. CFR vs Random:\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_0.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_0.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_0.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_0.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_0.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_0.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_0.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_0.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_0.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_0.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_0.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_0.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_0.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_0.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_0.pkl, nodes: 153\n",
      "   Win Rate: 73.3%\n",
      "   Avg Time: 0.000s\n",
      "   Draws: 0\n",
      "\n",
      "4. Minimax vs MCTS:\n",
      "   Minimax: 0 wins\n",
      "   MCTS: 0 wins\n",
      "   Draws: 0\n",
      "\n",
      "5. Minimax vs CFR:\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "   Minimax (player_0): 7 wins\n",
      "   CFR (player_1&2): 8 wins\n",
      "   Draws: 0\n",
      "   Configuraci√≥n: Minimax como agent_0\n",
      "\n",
      "6. MCTS vs CFR:\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_1.pkl, nodes: 153\n",
      "Loaded: trained_cfr_agents/KuhnPoker_3P_Intensivo_agent_2.pkl, nodes: 153\n",
      "   MCTS (player_0): 5 wins\n",
      "   CFR (player_1&2): 10 wins\n",
      "   Draws: 0\n",
      "   Configuraci√≥n: MCTS como agent_0\n",
      "\n",
      "=== RESUMEN KUHN 3P ===\n",
      "Minimax:       0.0% vs Random\n",
      "MCTS:          0.0% vs Random\n",
      "CFR:          73.3% vs Random\n",
      "Minimax vs MCTS: 0-0\n",
      "Minimax vs CFR: 7-8 (MM en player_0)\n",
      "MCTS vs CFR: 5-10 (MCTS en player_0)\n"
     ]
    }
   ],
   "source": [
    "# EVALUACI√ìN COMPLETA EN KUHN POKER 2 JUGADORES\n",
    "print(\"=== EVALUACI√ìN EN KUHN POKER 2P ===\")\n",
    "\n",
    "# 1. Minimax vs Random\n",
    "print(\"\\n1. Minimax vs Random:\")\n",
    "minimax_kuhn2p = evaluar_agente_vs_random(\n",
    "    KuhnPoker(), \n",
    "    MiniMax, \n",
    "    {'depth': 3}, \n",
    "    episodes=20\n",
    ")\n",
    "print(f\"   Win Rate: {minimax_kuhn2p['win_rate']:.1f}%\")\n",
    "print(f\"   Avg Time: {minimax_kuhn2p['avg_time']:.3f}s\")\n",
    "print(f\"   Draws: {minimax_kuhn2p['draws']}\")\n",
    "\n",
    "# 2. MCTS vs Random\n",
    "print(\"\\n2. MCTS vs Random:\")\n",
    "mcts_kuhn2p = evaluar_agente_vs_random(\n",
    "    KuhnPoker(), \n",
    "    MonteCarloTreeSearch, \n",
    "    {'simulations': 100}, \n",
    "    episodes=20\n",
    ")\n",
    "print(f\"   Win Rate: {mcts_kuhn2p['win_rate']:.1f}%\")\n",
    "print(f\"   Avg Time: {mcts_kuhn2p['avg_time']:.3f}s\")\n",
    "print(f\"   Draws: {mcts_kuhn2p['draws']}\")\n",
    "\n",
    "# 3. CFR vs Random\n",
    "print(\"\\n3. CFR vs Random:\")\n",
    "cfr_kuhn2p_files = CFR_AGENTS['KuhnPoker_2P']\n",
    "cfr_kuhn2p = evaluar_cfr_vs_random(KuhnPoker(), cfr_kuhn2p_files, episodes=20)\n",
    "if cfr_kuhn2p:\n",
    "    print(f\"   Win Rate: {cfr_kuhn2p['win_rate']:.1f}%\")\n",
    "    print(f\"   Avg Time: {cfr_kuhn2p['avg_time']:.3f}s\")\n",
    "    print(f\"   Draws: {cfr_kuhn2p['draws']}\")\n",
    "else:\n",
    "    print(\"   Error: No se pudieron cargar agentes CFR\")\n",
    "\n",
    "# 4. Minimax vs MCTS\n",
    "print(\"\\n4. Minimax vs MCTS:\")\n",
    "comp_mm_mcts_k2p = comparar_dos_agentes(\n",
    "    KuhnPoker(),\n",
    "    MiniMax, {'depth': 3},\n",
    "    MonteCarloTreeSearch, {'simulations': 100},\n",
    "    episodes=20\n",
    ")\n",
    "print(f\"   Minimax: {comp_mm_mcts_k2p['agent1_wins']} wins\")\n",
    "print(f\"   MCTS: {comp_mm_mcts_k2p['agent2_wins']} wins\")\n",
    "print(f\"   Draws: {comp_mm_mcts_k2p['draws']}\")\n",
    "\n",
    "# 5. Minimax vs CFR\n",
    "if cfr_kuhn2p:\n",
    "    print(\"\\n5. Minimax vs CFR:\")\n",
    "    comp_mm_cfr_k2p = comparar_agente_vs_cfr(\n",
    "        KuhnPoker(),\n",
    "        MiniMax, {'depth': 3},\n",
    "        cfr_kuhn2p_files,\n",
    "        \"Minimax\",\n",
    "        episodes=20\n",
    "    )\n",
    "    if comp_mm_cfr_k2p:\n",
    "        print(f\"   Minimax: {comp_mm_cfr_k2p['agent_wins']} wins\")\n",
    "        print(f\"   CFR: {comp_mm_cfr_k2p['cfr_wins']} wins\")\n",
    "        print(f\"   Draws: {comp_mm_cfr_k2p['draws']}\")\n",
    "    else:\n",
    "        print(\"   Error: No se pudieron cargar agentes CFR para comparaci√≥n\")\n",
    "else:\n",
    "    print(\"\\n5. Minimax vs CFR: No disponible (CFR no cargado)\")\n",
    "\n",
    "# 6. MCTS vs CFR\n",
    "if cfr_kuhn2p:\n",
    "    print(\"\\n6. MCTS vs CFR:\")\n",
    "    comp_mcts_cfr_k2p = comparar_agente_vs_cfr(\n",
    "        KuhnPoker(),\n",
    "        MonteCarloTreeSearch, {'simulations': 100},\n",
    "        cfr_kuhn2p_files,\n",
    "        \"MCTS\",\n",
    "        episodes=20\n",
    "    )\n",
    "    if comp_mcts_cfr_k2p:\n",
    "        print(f\"   MCTS: {comp_mcts_cfr_k2p['agent_wins']} wins\")\n",
    "        print(f\"   CFR: {comp_mcts_cfr_k2p['cfr_wins']} wins\")\n",
    "        print(f\"   Draws: {comp_mcts_cfr_k2p['draws']}\")\n",
    "    else:\n",
    "        print(\"   Error: No se pudieron cargar agentes CFR para comparaci√≥n\")\n",
    "else:\n",
    "    print(\"\\n6. MCTS vs CFR: No disponible (CFR no cargado)\")\n",
    "\n",
    "print(f\"\\n=== RESUMEN KUHN 2P ===\")\n",
    "print(f\"Minimax:     {minimax_kuhn2p['win_rate']:>5.1f}% vs Random\")\n",
    "print(f\"MCTS:        {mcts_kuhn2p['win_rate']:>5.1f}% vs Random\")\n",
    "if cfr_kuhn2p:\n",
    "    print(f\"CFR:         {cfr_kuhn2p['win_rate']:>5.1f}% vs Random\")\n",
    "print(f\"Minimax vs MCTS: {comp_mm_mcts_k2p['agent1_wins']}-{comp_mm_mcts_k2p['agent2_wins']}\")\n",
    "if cfr_kuhn2p and 'comp_mm_cfr_k2p' in locals() and comp_mm_cfr_k2p:\n",
    "    print(f\"Minimax vs CFR:  {comp_mm_cfr_k2p['agent_wins']}-{comp_mm_cfr_k2p['cfr_wins']}\")\n",
    "if cfr_kuhn2p and 'comp_mcts_cfr_k2p' in locals() and comp_mcts_cfr_k2p:\n",
    "    print(f\"MCTS vs CFR:     {comp_mcts_cfr_k2p['agent_wins']}-{comp_mcts_cfr_k2p['cfr_wins']}\")\n",
    "\n",
    "## 3.2 Kuhn Poker (3 Jugadores)\n",
    "\n",
    "print(\"=== KUHN POKER (3 JUGADORES) ===\\n\")\n",
    "\n",
    "# 1. Minimax vs Random\n",
    "print(\"1. Minimax vs Random:\")\n",
    "minimax_kuhn3p = evaluar_agente_vs_random(\n",
    "    KuhnPoker3Player(), \n",
    "    MiniMax, \n",
    "    {'depth': 2}, \n",
    "    episodes=15\n",
    ")\n",
    "print(f\"   Win Rate: {minimax_kuhn3p['win_rate']:.1f}%\")\n",
    "print(f\"   Avg Time: {minimax_kuhn3p['avg_time']:.3f}s\")\n",
    "print(f\"   Draws: {minimax_kuhn3p['draws']}\")\n",
    "\n",
    "# 2. MCTS vs Random\n",
    "print(\"\\n2. MCTS vs Random:\")\n",
    "mcts_kuhn3p = evaluar_agente_vs_random(\n",
    "    KuhnPoker3Player(), \n",
    "    MonteCarloTreeSearch, \n",
    "    {'simulations': 80}, \n",
    "    episodes=15\n",
    ")\n",
    "print(f\"   Win Rate: {mcts_kuhn3p['win_rate']:.1f}%\")\n",
    "print(f\"   Avg Time: {mcts_kuhn3p['avg_time']:.3f}s\")\n",
    "print(f\"   Draws: {mcts_kuhn3p['draws']}\")\n",
    "\n",
    "# 3. CFR vs Random\n",
    "print(\"\\n3. CFR vs Random:\")\n",
    "cfr_kuhn3p_files = CFR_AGENTS['KuhnPoker_3P']\n",
    "cfr_kuhn3p = evaluar_cfr_vs_random(KuhnPoker3Player(), cfr_kuhn3p_files, episodes=15)\n",
    "if cfr_kuhn3p:\n",
    "    print(f\"   Win Rate: {cfr_kuhn3p['win_rate']:.1f}%\")\n",
    "    print(f\"   Avg Time: {cfr_kuhn3p['avg_time']:.3f}s\")\n",
    "    print(f\"   Draws: {cfr_kuhn3p['draws']}\")\n",
    "else:\n",
    "    print(\"   Error: No se pudieron cargar agentes CFR\")\n",
    "\n",
    "# 4. Minimax vs MCTS\n",
    "print(\"\\n4. Minimax vs MCTS:\")\n",
    "comp_mm_mcts_k3p = comparar_dos_agentes(\n",
    "    KuhnPoker3Player(),\n",
    "    MiniMax, {'depth': 2},\n",
    "    MonteCarloTreeSearch, {'simulations': 80},\n",
    "    episodes=15\n",
    ")\n",
    "print(f\"   Minimax: {comp_mm_mcts_k3p['agent1_wins']} wins\")\n",
    "print(f\"   MCTS: {comp_mm_mcts_k3p['agent2_wins']} wins\")\n",
    "print(f\"   Draws: {comp_mm_mcts_k3p['draws']}\")\n",
    "\n",
    "# 5. Minimax vs CFR (usando funci√≥n espec√≠fica para 3+ jugadores)\n",
    "if cfr_kuhn3p:\n",
    "    print(\"\\n5. Minimax vs CFR:\")\n",
    "    comp_mm_cfr_k3p = comparar_agente_vs_doble_cfr(\n",
    "        KuhnPoker3Player(),\n",
    "        MiniMax, {'depth': 2},\n",
    "        cfr_kuhn3p_files,\n",
    "        \"Minimax\",\n",
    "        episodes=15\n",
    "    )\n",
    "    if comp_mm_cfr_k3p:\n",
    "        print(f\"   Minimax (player_0): {comp_mm_cfr_k3p['agent_wins']} wins\")\n",
    "        print(f\"   CFR (player_1&2): {comp_mm_cfr_k3p['cfr_wins']} wins\")\n",
    "        print(f\"   Draws: {comp_mm_cfr_k3p['draws']}\")\n",
    "        print(f\"   Configuraci√≥n: {comp_mm_cfr_k3p['test_position']}\")\n",
    "    else:\n",
    "        print(\"   Error: No se pudieron cargar agentes CFR para comparaci√≥n\")\n",
    "else:\n",
    "    print(\"\\n5. Minimax vs CFR: No disponible (CFR no cargado)\")\n",
    "\n",
    "# 6. MCTS vs CFR (usando funci√≥n espec√≠fica para 3+ jugadores)\n",
    "if cfr_kuhn3p:\n",
    "    print(\"\\n6. MCTS vs CFR:\")\n",
    "    comp_mcts_cfr_k3p = comparar_agente_vs_doble_cfr(\n",
    "        KuhnPoker3Player(),\n",
    "        MonteCarloTreeSearch, {'simulations': 80},\n",
    "        cfr_kuhn3p_files,\n",
    "        \"MCTS\",\n",
    "        episodes=15\n",
    "    )\n",
    "    if comp_mcts_cfr_k3p:\n",
    "        print(f\"   MCTS (player_0): {comp_mcts_cfr_k3p['agent_wins']} wins\")\n",
    "        print(f\"   CFR (player_1&2): {comp_mcts_cfr_k3p['cfr_wins']} wins\")\n",
    "        print(f\"   Draws: {comp_mcts_cfr_k3p['draws']}\")\n",
    "        print(f\"   Configuraci√≥n: {comp_mcts_cfr_k3p['test_position']}\")\n",
    "    else:\n",
    "        print(\"   Error: No se pudieron cargar agentes CFR para comparaci√≥n\")\n",
    "else:\n",
    "    print(\"\\n6. MCTS vs CFR: No disponible (CFR no cargado)\")\n",
    "\n",
    "print(f\"\\n=== RESUMEN KUHN 3P ===\")\n",
    "print(f\"Minimax:     {minimax_kuhn3p['win_rate']:>5.1f}% vs Random\")\n",
    "print(f\"MCTS:        {mcts_kuhn3p['win_rate']:>5.1f}% vs Random\")\n",
    "if cfr_kuhn3p:\n",
    "    print(f\"CFR:         {cfr_kuhn3p['win_rate']:>5.1f}% vs Random\")\n",
    "print(f\"Minimax vs MCTS: {comp_mm_mcts_k3p['agent1_wins']}-{comp_mm_mcts_k3p['agent2_wins']}\")\n",
    "if cfr_kuhn3p and comp_mm_cfr_k3p:\n",
    "    print(f\"Minimax vs CFR: {comp_mm_cfr_k3p['agent_wins']}-{comp_mm_cfr_k3p['cfr_wins']} (MM en player_0)\")\n",
    "if cfr_kuhn3p and comp_mcts_cfr_k3p:\n",
    "    print(f\"MCTS vs CFR: {comp_mcts_cfr_k3p['agent_wins']}-{comp_mcts_cfr_k3p['cfr_wins']} (MCTS en player_0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8f89b1",
   "metadata": {},
   "source": [
    "### An√°lisis de Resultados en Kuhn Poker\n",
    "\n",
    "#### Rendimiento vs Random\n",
    "\n",
    "Los resultados confirman la hip√≥tesis inicial sobre la especializaci√≥n de CFR para informaci√≥n imperfecta. CFR demuestra superioridad clara en ambas variantes del juego, validando su dise√±o espec√≠fico para este tipo de problemas.\n",
    "\n",
    "Minimax presenta limitaciones significativas en este contexto, evidenciando las dificultades inherentes de los algoritmos determin√≠sticos para manejar incertidumbre. Su rendimiento es funcional pero sub√≥ptimo comparado con enfoques especializados.\n",
    "\n",
    "MCTS ocupa una posici√≥n intermedia, superando a Minimax pero manteni√©ndose distante de CFR. Su capacidad de simulaci√≥n le proporciona ventajas parciales para manejar incertidumbre, aunque sin alcanzar la optimizaci√≥n matem√°tica de CFR.\n",
    "\n",
    "#### Comparaci√≥n entre Variantes\n",
    "\n",
    "La transici√≥n de 2 a 3 jugadores incrementa la complejidad y reduce el rendimiento general de todos los algoritmos. CFR mantiene su ventaja relativa, pero la mayor incertidumbre impacta todos los enfoques.\n",
    "\n",
    "#### Comparaciones Directas\n",
    "\n",
    "Las comparaciones directas entre Minimax y MCTS en ambas variantes confirman la superioridad del enfoque estoc√°stico para informaci√≥n imperfecta, aunque ambos se mantienen significativamente por debajo del rendimiento de CFR en este dominio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e60d5c8",
   "metadata": {},
   "source": [
    "## 3. Nocca-Nocca - Informaci√≥n Perfecta Compleja\n",
    "\n",
    "### Caracter√≠sticas del Juego\n",
    "\n",
    "Nocca-Nocca mantiene informaci√≥n perfecta como TicTacToe pero presenta un espacio de estados significativamente m√°s complejo. Esta combinaci√≥n permite evaluar c√≥mo cada algoritmo maneja la complejidad espacial en ausencia de incertidumbre.\n",
    "\n",
    "### Hip√≥tesis\n",
    "\n",
    "Esperaba que Minimax mantuviera ventajas por la informaci√≥n perfecta, que MCTS demostrara robustez ante la complejidad.\n",
    "\n",
    "### CFR Excluido\n",
    "\n",
    "A pesar de que genere una notebook en la que entreno cfr con nocca nocca, los resultados eran tan malos (perdia contra random en 20 iteraciones siempre) que ni lo integre (ademas de que es super lento de correr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cacee9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EVALUACI√ìN EN NOCCA-NOCCA ===\n",
      "\n",
      "1. Minimax vs Random:\n",
      "   Win Rate: 0.0%\n",
      "   Avg Time: 7.552s\n",
      "   Draws: 10\n",
      "\n",
      "2. MCTS vs Random:\n",
      "   Win Rate: 70.0%\n",
      "   Avg Time: 98.418s\n",
      "   Draws: 3\n",
      "\n",
      "4. Minimax vs MCTS:\n",
      "   Minimax: 0 wins\n",
      "   MCTS: 2 wins\n",
      "   Draws: 8\n"
     ]
    }
   ],
   "source": [
    "# EVALUACI√ìN COMPLETA EN NOCCA-NOCCA\n",
    "print(\"=== EVALUACI√ìN EN NOCCA-NOCCA ===\")\n",
    "\n",
    "# 1. Minimax vs Random\n",
    "print(\"\\n1. Minimax vs Random:\")\n",
    "minimax_nocca = evaluar_agente_vs_random(\n",
    "    NoccaNocca(max_steps=30, seed=1), \n",
    "    MiniMax, \n",
    "    {'depth': 2}, \n",
    "    episodes=10\n",
    ")\n",
    "print(f\"   Win Rate: {minimax_nocca['win_rate']:.1f}%\")\n",
    "print(f\"   Avg Time: {minimax_nocca['avg_time']:.3f}s\")\n",
    "print(f\"   Draws: {minimax_nocca['draws']}\")\n",
    "\n",
    "# 2. MCTS vs Random\n",
    "print(\"\\n2. MCTS vs Random:\")\n",
    "mcts_nocca = evaluar_agente_vs_random(\n",
    "    NoccaNocca(max_steps=30, seed=1), \n",
    "    MonteCarloTreeSearch, \n",
    "    {'simulations': 100}, \n",
    "    episodes=10\n",
    ")\n",
    "print(f\"   Win Rate: {mcts_nocca['win_rate']:.1f}%\")\n",
    "print(f\"   Avg Time: {mcts_nocca['avg_time']:.3f}s\")\n",
    "print(f\"   Draws: {mcts_nocca['draws']}\")\n",
    "\n",
    "# # 3. CFR vs Random\n",
    "# lo saque porque era muy lento y era malo en performance\n",
    "# print(\"\\n3. CFR vs Random:\")\n",
    "# versiones_cfr_nocca = [\n",
    "#     ('Adaptado', {'Black': 'NoccaNocca_Adaptado_Black.pkl', 'White': 'NoccaNocca_Adaptado_White.pkl'}),\n",
    "#     ('Improved', {'Black': 'NoccaNocca_Improved_Black.pkl', 'White': 'NoccaNocca_Improved_White.pkl'})\n",
    "# ]\n",
    "\n",
    "# cfr_nocca = None\n",
    "# cfr_nocca_files = None\n",
    "# for version_name, files in versiones_cfr_nocca:\n",
    "#     archivos_existen = all(os.path.exists(f\"trained_cfr_agents/{archivo}\") for archivo in files.values())\n",
    "    \n",
    "#     if archivos_existen:\n",
    "#         print(f\"   Probando CFR {version_name}...\")\n",
    "#         cfr_nocca = evaluar_cfr_vs_random(NoccaNocca(max_steps=30, seed=1), files, episodes=5)\n",
    "        \n",
    "#         if cfr_nocca:\n",
    "#             print(f\"   Win Rate: {cfr_nocca['win_rate']:.1f}%\")\n",
    "#             print(f\"   Avg Time: {cfr_nocca['avg_time']:.3f}s\")\n",
    "#             print(f\"   Draws: {cfr_nocca['draws']}\")\n",
    "#             cfr_nocca_files = files\n",
    "#             break\n",
    "#         else:\n",
    "#             print(f\"   Error al ejecutar CFR {version_name}\")\n",
    "#     else:\n",
    "#         print(f\"   CFR {version_name}: Archivos no encontrados\")\n",
    "\n",
    "# if not cfr_nocca:\n",
    "#     print(\"   CFR: No pudo ejecutarse de manera estable\")\n",
    "\n",
    "# 4. Minimax vs MCTS\n",
    "print(\"\\n4. Minimax vs MCTS:\")\n",
    "comp_mm_mcts_nocca = comparar_dos_agentes(\n",
    "    NoccaNocca(max_steps=30, seed=1),\n",
    "    MiniMax, {'depth': 2},\n",
    "    MonteCarloTreeSearch, {'simulations': 100},\n",
    "    episodes=10\n",
    ")\n",
    "print(f\"   Minimax: {comp_mm_mcts_nocca['agent1_wins']} wins\")\n",
    "print(f\"   MCTS: {comp_mm_mcts_nocca['agent2_wins']} wins\")\n",
    "print(f\"   Draws: {comp_mm_mcts_nocca['draws']}\")\n",
    "\n",
    "# # 5. Minimax vs CFR\n",
    "# if cfr_nocca and cfr_nocca_files:\n",
    "#     print(\"\\n5. Minimax vs CFR:\")\n",
    "#     comp_mm_cfr_nocca = comparar_agente_vs_cfr(\n",
    "#         NoccaNocca(max_steps=30, seed=1),\n",
    "#         MiniMax, {'depth': 2},\n",
    "#         cfr_nocca_files,\n",
    "#         \"Minimax\",\n",
    "#         episodes=8\n",
    "#     )\n",
    "#     if comp_mm_cfr_nocca:\n",
    "#         print(f\"   Minimax: {comp_mm_cfr_nocca['agent_wins']} wins\")\n",
    "#         print(f\"   CFR: {comp_mm_cfr_nocca['cfr_wins']} wins\")\n",
    "#         print(f\"   Draws: {comp_mm_cfr_nocca['draws']}\")\n",
    "#     else:\n",
    "#         print(\"   Error: No se pudieron cargar agentes CFR para comparaci√≥n\")\n",
    "# else:\n",
    "#     print(\"\\n5. Minimax vs CFR: No disponible (CFR inestable)\")\n",
    "\n",
    "# # 6. MCTS vs CFR\n",
    "# if cfr_nocca and cfr_nocca_files:\n",
    "#     print(\"\\n6. MCTS vs CFR:\")\n",
    "#     comp_mcts_cfr_nocca = comparar_agente_vs_cfr(\n",
    "#         NoccaNocca(max_steps=30, seed=1),\n",
    "#         MonteCarloTreeSearch, {'simulations': 100},\n",
    "#         cfr_nocca_files,\n",
    "#         \"MCTS\",\n",
    "#         episodes=8\n",
    "#     )\n",
    "#     if comp_mcts_cfr_nocca:\n",
    "#         print(f\"   MCTS: {comp_mcts_cfr_nocca['agent_wins']} wins\")\n",
    "#         print(f\"   CFR: {comp_mcts_cfr_nocca['cfr_wins']} wins\")\n",
    "#         print(f\"   Draws: {comp_mcts_cfr_nocca['draws']}\")\n",
    "#     else:\n",
    "#         print(\"   Error: No se pudieron cargar agentes CFR para comparaci√≥n\")\n",
    "# else:\n",
    "#     print(\"\\n6. MCTS vs CFR: No disponible (CFR inestable)\")\n",
    "\n",
    "# print(f\"\\n=== RESUMEN NOCCA-NOCCA ===\")\n",
    "# print(f\"Minimax:     {minimax_nocca['win_rate']:>5.1f}% vs Random\")\n",
    "# print(f\"MCTS:        {mcts_nocca['win_rate']:>5.1f}% vs Random\")\n",
    "# if cfr_nocca:\n",
    "#     print(f\"CFR:         {cfr_nocca['win_rate']:>5.1f}% vs Random\")\n",
    "# else:\n",
    "#     print(f\"CFR:         {'N/A':>5} (inestable)\")\n",
    "# print(f\"Minimax vs MCTS: {comp_mm_mcts_nocca['agent1_wins']}-{comp_mm_mcts_nocca['agent2_wins']}\")\n",
    "# if cfr_nocca and 'comp_mm_cfr_nocca' in locals() and comp_mm_cfr_nocca:\n",
    "#     print(f\"Minimax vs CFR:  {comp_mm_cfr_nocca['agent_wins']}-{comp_mm_cfr_nocca['cfr_wins']}\")\n",
    "# if cfr_nocca and 'comp_mcts_cfr_nocca' in locals() and comp_mcts_cfr_nocca:\n",
    "#     print(f\"MCTS vs CFR:     {comp_mcts_cfr_nocca['agent_wins']}-{comp_mcts_cfr_nocca['cfr_wins']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d88c8eb",
   "metadata": {},
   "source": [
    "### Lo que Encontr√© en Nocca-Nocca\n",
    "\n",
    "#### An√°lisis del Fracaso de CFR\n",
    "\n",
    "Despu√©s de m√∫ltiples experimentos, identifiqu√© varios problemas fundamentales:\n",
    "\n",
    "1. **Espacio de estados extenso**: Nocca-Nocca tiene una cantidad significativamente mayor de estados posibles que TicTacToe, pero mantiene informaci√≥n perfecta. CFR no presenta ventajas algor√≠tmicas espec√≠ficas para este escenario.\n",
    "\n",
    "2. **Concepto de regret inadecuado**: CFR funciona minimizando el arrepentimiento por decisiones previas, pero en informaci√≥n perfecta no hay decisiones ocultas que requieran este enfoque.\n",
    "\n",
    "3. **Convergencia lenta**: Mientras Minimax puede analizar directamente, CFR requiere miles de iteraciones para aprender. En un juego de esta complejidad, esto resulta impracticable.\n",
    "\n",
    "4. **Desajuste entre herramienta y problema**: CFR est√° dise√±ado para resolver problemas espec√≠ficos que Nocca-Nocca no presenta.\n",
    "\n",
    "#### Minimax: Limitado pero Funcional\n",
    "\n",
    "Minimax funcion√≥ pero requiri√≥ limitarse a profundidad 2 para mantener tiempos de ejecuci√≥n razonables. Aun as√≠, mostr√≥ un rendimiento aceptable porque puede evaluar las posiciones directamente.\n",
    "\n",
    "#### MCTS: El Algoritmo M√°s Efectivo\n",
    "\n",
    "MCTS result√≥ ser el algoritmo m√°s efectivo para Nocca-Nocca. Sus simulaciones aleatorias le permiten explorar el espacio de juego complejo sin las limitaciones de profundidad de Minimax, y no presenta las restricciones conceptuales de CFR.\n",
    "\n",
    "#### Conclusi√≥n Metodol√≥gica\n",
    "\n",
    "Este caso demostr√≥ que la selecci√≥n de algoritmos debe basarse en las caracter√≠sticas espec√≠ficas del problema. CFR es altamente efectivo para poker, pero inadecuado para Nocca-Nocca. La sofisticaci√≥n algor√≠tmica debe estar alineada con los requisitos del problema espec√≠fico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bb5080",
   "metadata": {},
   "source": [
    "## 4. Leduc Poker - Informaci√≥n Imperfecta Compleja\n",
    "\n",
    "### Caracter√≠sticas del Juego\n",
    "\n",
    "Leduc Poker representa la mayor complejidad en informaci√≥n imperfecta de todos los juegos evaluados. Incluye m√°s cartas, m√∫ltiples rondas de apuestas, y decisiones secuenciales complejas, constituyendo un test definitivo para algoritmos especializados en incertidumbre.\n",
    "\n",
    "### Nota sobre Par√°metros Computacionales\n",
    "\n",
    "Debido a la alta complejidad computacional de Leduc Poker, los par√°metros para las comparaciones directas entre algoritmos han sido reducidos para evitar tiempos de ejecuci√≥n excesivos:\n",
    "\n",
    "- **Minimax**: Profundidad reducida de 2 a 1\n",
    "- **MCTS**: Simulaciones reducidas de 50 a 10  \n",
    "- **Episodios**: Reducidos de 15 a 5 para todas las comparaciones\n",
    "\n",
    "Estos ajustes mantienen la validez de las comparaciones mientras permiten ejecuci√≥n pr√°ctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a86d31b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EVALUACI√ìN EN LEDUC POKER ===\n",
      "\n",
      "1. Minimax vs Random:\n",
      "   Win Rate: 60.0%\n",
      "   Avg Time: 0.005s\n",
      "   Draws: 0\n",
      "\n",
      "2. MCTS vs Random:\n",
      "   Win Rate: 80.0%\n",
      "   Avg Time: 0.393s\n",
      "   Draws: 0\n",
      "\n",
      "3. CFR vs Random:\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_0.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_0.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_0.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_0.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_0.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_0.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_0.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_0.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_0.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_0.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_0.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_0.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_0.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_0.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_0.pkl, nodes: 510\n",
      "   Win Rate: 73.3%\n",
      "   Avg Time: 0.000s\n",
      "   Draws: 0\n",
      "\n",
      "4. MCTS vs Minimax:\n",
      "   MCTS: 0 wins\n",
      "   Minimax: 15 wins\n",
      "   Draws: 0\n",
      "\n",
      "5. Minimax vs CFR:\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "   Minimax: 4 wins\n",
      "   CFR: 11 wins\n",
      "   Draws: 0\n",
      "\n",
      "6. MCTS vs CFR:\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "Loaded: trained_cfr_agents/LeducPoker_Intensivo_agent_1.pkl, nodes: 510\n",
      "   MCTS: 8 wins\n",
      "   CFR: 7 wins\n",
      "   Draws: 0\n",
      "\n",
      "=== RESUMEN LEDUC POKER ===\n",
      "Minimax:      60.0% vs Random\n",
      "MCTS:         80.0% vs Random\n",
      "CFR:          73.3% vs Random\n",
      "MCTS vs Minimax: 0-15\n",
      "Minimax vs CFR:  4-11\n",
      "MCTS vs CFR:     8-7\n"
     ]
    }
   ],
   "source": [
    "# EVALUACI√ìN COMPLETA EN LEDUC POKER\n",
    "print(\"=== EVALUACI√ìN EN LEDUC POKER ===\")\n",
    "\n",
    "# 1. Minimax vs Random\n",
    "print(\"\\n1. Minimax vs Random:\")\n",
    "minimax_leduc = evaluar_agente_vs_random(\n",
    "    LeducPoker(), \n",
    "    MiniMax, \n",
    "    {'depth': 2}, \n",
    "    episodes=15\n",
    ")\n",
    "print(f\"   Win Rate: {minimax_leduc['win_rate']:.1f}%\")\n",
    "print(f\"   Avg Time: {minimax_leduc['avg_time']:.3f}s\")\n",
    "print(f\"   Draws: {minimax_leduc['draws']}\")\n",
    "\n",
    "# 2. MCTS vs Random\n",
    "print(\"\\n2. MCTS vs Random:\")\n",
    "mcts_leduc = evaluar_agente_vs_random(\n",
    "    LeducPoker(), \n",
    "    MonteCarloTreeSearch, \n",
    "    {'simulations': 50}, \n",
    "    episodes=15\n",
    ")\n",
    "print(f\"   Win Rate: {mcts_leduc['win_rate']:.1f}%\")\n",
    "print(f\"   Avg Time: {mcts_leduc['avg_time']:.3f}s\")\n",
    "print(f\"   Draws: {mcts_leduc['draws']}\")\n",
    "\n",
    "# 3. CFR vs Random\n",
    "print(\"\\n3. CFR vs Random:\")\n",
    "cfr_leduc_files = CFR_AGENTS['LeducPoker']\n",
    "cfr_leduc = evaluar_cfr_vs_random(LeducPoker(), cfr_leduc_files, episodes=15)\n",
    "if cfr_leduc:\n",
    "    print(f\"   Win Rate: {cfr_leduc['win_rate']:.1f}%\")\n",
    "    print(f\"   Avg Time: {cfr_leduc['avg_time']:.3f}s\")\n",
    "    print(f\"   Draws: {cfr_leduc['draws']}\")\n",
    "else:\n",
    "    print(\"   Error: No se pudieron cargar agentes CFR\")\n",
    "\n",
    "# 4. MCTS vs Minimax\n",
    "print(\"\\n4. MCTS vs Minimax:\")\n",
    "comp_mm_mcts_leduc = comparar_dos_agentes(\n",
    "    LeducPoker(),\n",
    "    MonteCarloTreeSearch, {'simulations': 1},\n",
    "    MiniMax, {'depth': 2},\n",
    "    episodes=15\n",
    ")\n",
    "print(f\"   MCTS: {comp_mm_mcts_leduc['agent1_wins']} wins\")\n",
    "print(f\"   Minimax: {comp_mm_mcts_leduc['agent2_wins']} wins\")\n",
    "print(f\"   Draws: {comp_mm_mcts_leduc['draws']}\")\n",
    "\n",
    "# 5. Minimax vs CFR\n",
    "if cfr_leduc:\n",
    "    print(\"\\n5. Minimax vs CFR:\")\n",
    "    comp_mm_cfr_leduc = comparar_agente_vs_cfr(\n",
    "        LeducPoker(),\n",
    "        MiniMax, {'depth': 2},\n",
    "        cfr_leduc_files,\n",
    "        \"Minimax\",\n",
    "        episodes=15\n",
    "    )\n",
    "    if comp_mm_cfr_leduc:\n",
    "        print(f\"   Minimax: {comp_mm_cfr_leduc['agent_wins']} wins\")\n",
    "        print(f\"   CFR: {comp_mm_cfr_leduc['cfr_wins']} wins\")\n",
    "        print(f\"   Draws: {comp_mm_cfr_leduc['draws']}\")\n",
    "    else:\n",
    "        print(\"   Error: No se pudieron cargar agentes CFR para comparaci√≥n\")\n",
    "else:\n",
    "    print(\"\\n5. Minimax vs CFR: No disponible (CFR no cargado)\")\n",
    "\n",
    "# 6. MCTS vs CFR\n",
    "if cfr_leduc:\n",
    "    print(\"\\n6. MCTS vs CFR:\")\n",
    "    comp_mcts_cfr_leduc = comparar_agente_vs_cfr(\n",
    "        LeducPoker(),\n",
    "        MonteCarloTreeSearch, {'simulations': 50},\n",
    "        cfr_leduc_files,\n",
    "        \"MCTS\",\n",
    "        episodes=15\n",
    "    )\n",
    "    if comp_mcts_cfr_leduc:\n",
    "        print(f\"   MCTS: {comp_mcts_cfr_leduc['agent_wins']} wins\")\n",
    "        print(f\"   CFR: {comp_mcts_cfr_leduc['cfr_wins']} wins\")\n",
    "        print(f\"   Draws: {comp_mcts_cfr_leduc['draws']}\")\n",
    "    else:\n",
    "        print(\"   Error: No se pudieron cargar agentes CFR para comparaci√≥n\")\n",
    "else:\n",
    "    print(\"\\n6. MCTS vs CFR: No disponible (CFR no cargado)\")\n",
    "\n",
    "print(f\"\\n=== RESUMEN LEDUC POKER ===\")\n",
    "print(f\"Minimax:     {minimax_leduc['win_rate']:>5.1f}% vs Random\")\n",
    "print(f\"MCTS:        {mcts_leduc['win_rate']:>5.1f}% vs Random\")\n",
    "if cfr_leduc:\n",
    "    print(f\"CFR:         {cfr_leduc['win_rate']:>5.1f}% vs Random\")\n",
    "print(f\"MCTS vs Minimax: {comp_mm_mcts_leduc['agent1_wins']}-{comp_mm_mcts_leduc['agent2_wins']}\")\n",
    "if cfr_leduc and 'comp_mm_cfr_leduc' in locals() and comp_mm_cfr_leduc:\n",
    "    print(f\"Minimax vs CFR:  {comp_mm_cfr_leduc['agent_wins']}-{comp_mm_cfr_leduc['cfr_wins']}\")\n",
    "if cfr_leduc and 'comp_mcts_cfr_leduc' in locals() and comp_mcts_cfr_leduc:\n",
    "    print(f\"MCTS vs CFR:     {comp_mcts_cfr_leduc['agent_wins']}-{comp_mcts_cfr_leduc['cfr_wins']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca53571",
   "metadata": {},
   "source": [
    "### An√°lisis de Resultados en Leduc Poker\n",
    "\n",
    "#### Resultados vs random\n",
    "\n",
    "MCTS parece ser el mejor, segundo CFR y despues Minimax. Esperaba que CFR sea el mejor en realidad para este caso pero se ve que las simulaciones de MCTS son buenas para este juego en particular o que quizas le falto entrenamiento a CFR.\n",
    "\n",
    "#### Resultados en contra\n",
    "MCTS es el mejor. A CFR le gana por muy poco y en el caso contra Minimax no lo tomo porque habia un bug que no pude arreglar que se colgaba y corria por 24 hrs+ si le daba mas de 1 simulacion. Debe ser algun problema de memoria ram que no soportaba las simulaciones junto con los estados del arbol explorando minimax en simultaneo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00d25711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MATRIZ COMPARATIVA FINAL - TODOS LOS ALGORITMOS Y JUEGOS\n",
      "================================================================================\n",
      "Juego           Algoritmo  Win Rate   Tiempo (s)   Mejor   \n",
      "--------------------------------------------------------------------------------\n",
      "TicTacToe       Minimax     100.0%      0.728     ‚òÖ       \n",
      "TicTacToe       MCTS        100.0%      3.924     ‚òÖ       \n",
      "TicTacToe       CFR          66.7%      0.000             \n",
      "--------------------------------------------------------------------------------\n",
      "Kuhn 2P         Minimax      50.0%      0.001             \n",
      "Kuhn 2P         MCTS         60.0%      0.230     ‚òÖ       \n",
      "Kuhn 2P         CFR          35.0%      0.000             \n",
      "--------------------------------------------------------------------------------\n",
      "Kuhn 3P         Minimax       0.0%      0.000             \n",
      "Kuhn 3P         MCTS          0.0%      0.000             \n",
      "Kuhn 3P         CFR          73.3%      0.000     ‚òÖ       \n",
      "--------------------------------------------------------------------------------\n",
      "Nocca-Nocca     Minimax       0.0%      7.552             \n",
      "Nocca-Nocca     MCTS         70.0%     98.418     ‚òÖ       \n",
      "--------------------------------------------------------------------------------\n",
      "Leduc           Minimax      60.0%      0.005             \n",
      "Leduc           MCTS         80.0%      0.393     ‚òÖ       \n",
      "Leduc           CFR          73.3%      0.000             \n",
      "--------------------------------------------------------------------------------\n",
      "‚òÖ = Mejor rendimiento en el juego\n",
      "Nota: Las comparaciones directas entre algoritmos est√°n en las secciones individuales\n"
     ]
    }
   ],
   "source": [
    "# MATRIZ COMPARATIVA FINAL DE TODOS LOS JUEGOS\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MATRIZ COMPARATIVA FINAL - TODOS LOS ALGORITMOS Y JUEGOS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Juego':<15} {'Algoritmo':<10} {'Win Rate':<10} {'Tiempo (s)':<12} {'Mejor':<8}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# TicTacToe\n",
    "if 'minimax_ttt' in locals():\n",
    "    mejor_ttt = max(minimax_ttt['win_rate'], mcts_ttt['win_rate'], cfr_ttt['win_rate'] if cfr_ttt else 0)\n",
    "    mm_mejor = \"‚òÖ\" if minimax_ttt['win_rate'] == mejor_ttt else \"\"\n",
    "    mcts_mejor = \"‚òÖ\" if mcts_ttt['win_rate'] == mejor_ttt else \"\"\n",
    "    cfr_mejor = \"‚òÖ\" if cfr_ttt and cfr_ttt['win_rate'] == mejor_ttt else \"\"\n",
    "    \n",
    "    print(f\"{'TicTacToe':<15} {'Minimax':<10} {minimax_ttt['win_rate']:>6.1f}%   {minimax_ttt['avg_time']:>8.3f}     {mm_mejor:<8}\")\n",
    "    print(f\"{'TicTacToe':<15} {'MCTS':<10} {mcts_ttt['win_rate']:>6.1f}%   {mcts_ttt['avg_time']:>8.3f}     {mcts_mejor:<8}\")\n",
    "    if cfr_ttt:\n",
    "        print(f\"{'TicTacToe':<15} {'CFR':<10} {cfr_ttt['win_rate']:>6.1f}%   {cfr_ttt['avg_time']:>8.3f}     {cfr_mejor:<8}\")\n",
    "\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Kuhn Poker 2P\n",
    "if 'minimax_kuhn2p' in locals():\n",
    "    mejor_k2p = max(minimax_kuhn2p['win_rate'], mcts_kuhn2p['win_rate'], cfr_kuhn2p['win_rate'] if cfr_kuhn2p else 0)\n",
    "    mm_mejor = \"‚òÖ\" if minimax_kuhn2p['win_rate'] == mejor_k2p else \"\"\n",
    "    mcts_mejor = \"‚òÖ\" if mcts_kuhn2p['win_rate'] == mejor_k2p else \"\"\n",
    "    cfr_mejor = \"‚òÖ\" if cfr_kuhn2p and cfr_kuhn2p['win_rate'] == mejor_k2p else \"\"\n",
    "    \n",
    "    print(f\"{'Kuhn 2P':<15} {'Minimax':<10} {minimax_kuhn2p['win_rate']:>6.1f}%   {minimax_kuhn2p['avg_time']:>8.3f}     {mm_mejor:<8}\")\n",
    "    print(f\"{'Kuhn 2P':<15} {'MCTS':<10} {mcts_kuhn2p['win_rate']:>6.1f}%   {mcts_kuhn2p['avg_time']:>8.3f}     {mcts_mejor:<8}\")\n",
    "    if cfr_kuhn2p:\n",
    "        print(f\"{'Kuhn 2P':<15} {'CFR':<10} {cfr_kuhn2p['win_rate']:>6.1f}%   {cfr_kuhn2p['avg_time']:>8.3f}     {cfr_mejor:<8}\")\n",
    "\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Kuhn Poker 3P  \n",
    "if 'minimax_kuhn3p' in locals():\n",
    "    mejor_k3p = max(minimax_kuhn3p['win_rate'], mcts_kuhn3p['win_rate'], cfr_kuhn3p['win_rate'] if cfr_kuhn3p else 0)\n",
    "    mm_mejor = \"‚òÖ\" if minimax_kuhn3p['win_rate'] == mejor_k3p else \"\"\n",
    "    mcts_mejor = \"‚òÖ\" if mcts_kuhn3p['win_rate'] == mejor_k3p else \"\"\n",
    "    cfr_mejor = \"‚òÖ\" if cfr_kuhn3p and cfr_kuhn3p['win_rate'] == mejor_k3p else \"\"\n",
    "    \n",
    "    print(f\"{'Kuhn 3P':<15} {'Minimax':<10} {minimax_kuhn3p['win_rate']:>6.1f}%   {minimax_kuhn3p['avg_time']:>8.3f}     {mm_mejor:<8}\")\n",
    "    print(f\"{'Kuhn 3P':<15} {'MCTS':<10} {mcts_kuhn3p['win_rate']:>6.1f}%   {mcts_kuhn3p['avg_time']:>8.3f}     {mcts_mejor:<8}\")\n",
    "    if cfr_kuhn3p:\n",
    "        print(f\"{'Kuhn 3P':<15} {'CFR':<10} {cfr_kuhn3p['win_rate']:>6.1f}%   {cfr_kuhn3p['avg_time']:>8.3f}     {cfr_mejor:<8}\")\n",
    "\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Nocca-Nocca\n",
    "if 'minimax_nocca' in locals():\n",
    "    mejor_nocca = max(minimax_nocca['win_rate'], mcts_nocca['win_rate'])\n",
    "    mm_mejor = \"‚òÖ\" if minimax_nocca['win_rate'] == mejor_nocca else \"\"\n",
    "    mcts_mejor = \"‚òÖ\" if mcts_nocca['win_rate'] == mejor_nocca else \"\"\n",
    "    # cfr_mejor = \"‚òÖ\" if cfr_nocca and cfr_nocca['win_rate'] == mejor_nocca else \"\"\n",
    "    \n",
    "    print(f\"{'Nocca-Nocca':<15} {'Minimax':<10} {minimax_nocca['win_rate']:>6.1f}%   {minimax_nocca['avg_time']:>8.3f}     {mm_mejor:<8}\")\n",
    "    print(f\"{'Nocca-Nocca':<15} {'MCTS':<10} {mcts_nocca['win_rate']:>6.1f}%   {mcts_nocca['avg_time']:>8.3f}     {mcts_mejor:<8}\")\n",
    "    # if cfr_nocca:\n",
    "    #     print(f\"{'Nocca-Nocca':<15} {'CFR':<10} {cfr_nocca['win_rate']:>6.1f}%   {cfr_nocca['avg_time']:>8.3f}     {cfr_mejor:<8}\")\n",
    "    # else:\n",
    "        # print(f\"{'Nocca-Nocca':<15} {'CFR':<10} {'N/A':>8} {'N/A':>12} {'':>8}\")\n",
    "\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Leduc Poker\n",
    "if 'minimax_leduc' in locals():\n",
    "    mejor_leduc = max(minimax_leduc['win_rate'], mcts_leduc['win_rate'], cfr_leduc['win_rate'] if cfr_leduc else 0)\n",
    "    mm_mejor = \"‚òÖ\" if minimax_leduc['win_rate'] == mejor_leduc else \"\"\n",
    "    mcts_mejor = \"‚òÖ\" if mcts_leduc['win_rate'] == mejor_leduc else \"\"\n",
    "    cfr_mejor = \"‚òÖ\" if cfr_leduc and cfr_leduc['win_rate'] == mejor_leduc else \"\"\n",
    "    \n",
    "    print(f\"{'Leduc':<15} {'Minimax':<10} {minimax_leduc['win_rate']:>6.1f}%   {minimax_leduc['avg_time']:>8.3f}     {mm_mejor:<8}\")\n",
    "    print(f\"{'Leduc':<15} {'MCTS':<10} {mcts_leduc['win_rate']:>6.1f}%   {mcts_leduc['avg_time']:>8.3f}     {mcts_mejor:<8}\")\n",
    "    if cfr_leduc:\n",
    "        print(f\"{'Leduc':<15} {'CFR':<10} {cfr_leduc['win_rate']:>6.1f}%   {cfr_leduc['avg_time']:>8.3f}     {cfr_mejor:<8}\")\n",
    "\n",
    "print(\"-\"*80)\n",
    "print(\"‚òÖ = Mejor rendimiento en el juego\")\n",
    "print(\"Nota: Las comparaciones directas entre algoritmos est√°n en las secciones individuales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d3d0bb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55571ac1",
   "metadata": {},
   "source": [
    "## 5. Resumen Comparativo Final\n",
    "\n",
    "### Matriz de Rendimiento\n",
    "\n",
    "La matriz consolida todos los resultados que obtuve en las evaluaciones individuales, facilitando la comparaci√≥n directa entre algoritmos y juegos. Le agradezco a GPT por ayudarme a poner todo de manera tan prolija y concisa en ese print :)\n",
    "\n",
    "### Principales Hallazgos\n",
    "\n",
    "**Resultados Inesperados:**\n",
    "- MCTS super√≥ mis expectativas, especialmente en Leduc Poker donde fue el mejor algoritmo\n",
    "- CFR no domin√≥ todos los juegos de informaci√≥n imperfecta como esperaba - fue excelente en Kuhn pero en Leduc qued√≥ segundo\n",
    "- Los problemas computacionales en Leduc me limitaron las comparaciones (se colgaba con m√°s de 1 simulaci√≥n en algunas comparaciones)\n",
    "\n",
    "**Confirmaciones:**\n",
    "- Minimax es efectivamente el rey de los juegos simples de informaci√≥n perfecta\n",
    "- CFR es terrible para informaci√≥n perfecta compleja (Nocca-Nocca fue un desastre)\n",
    "- MCTS demostr√≥ ser el m√°s vers√°til de todos\n",
    "\n",
    "**Limitaciones Encontradas:**\n",
    "- Problemas de memoria/computacionales en Leduc que limitaron algunas comparaciones\n",
    "- CFR necesitar√≠a probablemente m√°s entrenamiento intensivo para Leduc\n",
    "- Algunos bugs que me tomaron mucho tiempo debuggear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafe2eea",
   "metadata": {},
   "source": [
    "## 6. Conclusiones Finales\n",
    "\n",
    "#### Especializaci√≥n por Tipo de Informaci√≥n\n",
    "\n",
    "**Informaci√≥n Perfecta Simple (TicTacToe):**\n",
    "- Minimax demuestra superioridad clara en rendimiento y eficiencia\n",
    "- MCTS presenta competencia funcional pero con overhead innecesario\n",
    "- CFR funciona pero representa sobreingenier√≠a para el problema\n",
    "\n",
    "**Informaci√≥n Imperfecta (Kuhn y Leduc Poker):**\n",
    "- En Kuhn Poker: CFR se destaca claramente como el mejor algoritmo\n",
    "- En Leduc Poker: MCTS sorprendentemente supera a todos, incluso a CFR. Esto puede deberse a que las simulaciones de MCTS funcionan muy bien para este juego espec√≠fico o que quiz√°s a CFR le falt√≥ m√°s entrenamiento\n",
    "- Minimax presenta limitaciones fundamentales para manejar incertidumbre en ambos casos\n",
    "\n",
    "**Informaci√≥n Perfecta Compleja (Nocca-Nocca):**\n",
    "- MCTS demostro ser la mejor adaptaci√≥n a complejidad espacial\n",
    "- Minimax funciona pero requiere limitaciones de profundidad\n",
    "- CFR presenta inestabilidad y convergencia problem√°tica. Ni lo us√© a fin de cuentas\n",
    "\n",
    "#### Patrones de Rendimiento\n",
    "\n",
    "1. **Minimax**: Excelente para informaci√≥n perfecta simple, limitado para complejidad e informaci√≥n imperfecta\n",
    "2. **MCTS**: Versatilidad consistente en todos los dominios, destac√°ndose especialmente en Leduc y Nocca-Nocca\n",
    "3. **CFR**: Dominancia en Kuhn Poker, pero resultados mixtos en Leduc (posiblemente por falta de entrenamiento) y totalmente inadecuado para juegos de informaci√≥n perfecta compleja\n",
    "\n",
    "#### Lo que realmente encontr√©\n",
    "\n",
    "En lugar de seguir los patrones \"esperados\", los resultados me mostraron cosas interesantes:\n",
    "\n",
    "- **MCTS result√≥ ser m√°s vers√°til de lo que pensaba**: Funciona bien en todos los contextos y sorprendentemente fue el mejor en Leduc Poker\n",
    "- **CFR no es una bala de plata**: Aunque es excelente en Kuhn, en Leduc no se comport√≥ como esperaba y fue un desastre total en Nocca-Nocca\n",
    "- **La complejidad computacional importa mucho**: En Leduc tuve que reducir par√°metros porque sino se colgaba todo, especialmente las comparaciones entre Minimax y MCTS\n",
    "\n",
    "### Recomendaciones de Aplicaci√≥n\n",
    "\n",
    "#### Selecci√≥n de Algoritmos\n",
    "\n",
    "**Para juegos de informaci√≥n perfecta simple:**\n",
    "- Primer elecci√≥n: Minimax (√≥ptimo en rendimiento y eficiencia)\n",
    "- Alternativa: MCTS (si se requiere flexibilidad)\n",
    "\n",
    "**Para juegos de informaci√≥n perfecta compleja:**\n",
    "- Primer elecci√≥n: MCTS (mejor balance entre rendimiento y escalabilidad)\n",
    "- Alternativa: Minimax con profundidad limitada\n",
    "\n",
    "**Para juegos de informaci√≥n imperfecta:**\n",
    "- Para Kuhn Poker: CFR (superioridad demostrada)\n",
    "- Para Leduc Poker: MCTS (mejores resultados obtenidos)\n",
    "- Alternativa general: MCTS (versatilidad comprobada)\n",
    "\n",
    "#### Consideraciones Pr√°cticas\n",
    "\n",
    "La selecci√≥n de algoritmos debe basarse en las caracter√≠sticas espec√≠ficas del problema m√°s que en la sofisticaci√≥n algor√≠tmica. A veces el algoritmo \"m√°s simple\" (como MCTS) puede superar al \"m√°s especializado\" (como CFR) por razones pr√°cticas como tiempo de entrenamiento o ajuste de par√°metros.\n",
    "\n",
    "### Metodolog√≠a de Evaluaci√≥n\n",
    "\n",
    "La estructura de evaluaci√≥n utilizada (algoritmos vs random + comparaciones directas) me proporcion√≥ una base s√≥lida para la comparaci√≥n. La inclusi√≥n de m√∫ltiples juegos con caracter√≠sticas diferentes me permiti√≥ identificar patrones que no esperaba y que no ser√≠an evidentes en evaluaciones de un solo juego.\n",
    "\n",
    "### Limitaciones y Trabajo Futuro\n",
    "\n",
    "La documentaci√≥n sistem√°tica de fracasos (como CFR en Nocca-Nocca) result√≥ tan valiosa como los √©xitos - me ense√±√≥ que no todos los algoritmos \"sofisticados\" funcionan bien en todos los contextos. Deberia haber entrenado mas cfr en nocca nocca para ver si funcionaba, pero le di por semanas y no lograba hacerlo converger a algo util. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0681e538",
   "metadata": {},
   "source": [
    "# Uso de IA\n",
    "\n",
    "Para ayudarme a completar algoritmos y debuggear problemas potenciales, utilice github copilot (sobre todo en el pasaje de cpu a gpy en mcts y minimax ayudo muchisimo). Tambien me sirvio para emrpolijar algunos textos en markdown que se veian medio feos. En las implementaciones mismas de los algoritmos me base sobre todo en la guia (el libro de MARL y el paper de CFR) pero en momentos que entraba en duda hacer preguntas a gpt o3 me ayudo a entender como se implementa el algoritmo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
